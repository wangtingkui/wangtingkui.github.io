[{"categories":[""],"content":"背景 前几天碰到了一个特殊的问题，线上一个路径拼接的异常，大概是下面这个样子\n路径 /path/xxx?id= 需要拼接一个id的参数，原先的使用方式是 fmt.Sprintf(\u0026quot;/path/xxx?id=%s\u0026quot;, struct{ Id string }{Id: \u0026quot;123\u0026quot;}.Id), 一切运转正常，但是某次需求里同事将 Id 字段的类型换成了 int，结果导致输出的路径变成了 /path/xxx?id=%!s(int=123)\n一时之间也感觉比较奇怪，所以读下源码分析下\n分析 直接上源码\n1func Printf(format string, a ...interface{}) (n int, err error) { 2return Fprintf(os.Stdout, format, a...) 3} 45func Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error) { 6// 新建一个 printer 7p := newPrinter() 8// 执行输出，我们核心的分析路径 9p.doPrintf(format, a) 10// 输出到 writer 11n, err = w.Write(p.buf) 12// 释放对象到对象池 13p.free() 14return 15} 1617// 到这里我们需要先看下 p 的结构 `*pp` 类型 18type pp struct { 19buf buffer 2021// arg holds the current item, as an interface{}. 22arg interface{} 2324// value is used instead of arg for reflect values. 25value reflect.Value 2627// fmt is used to format basic items such as integers or strings. 28fmt fmt 2930// reordered records whether the format string used argument reordering. 31reordered bool 32// goodArgNum records whether the most recent reordering directive was valid. 33goodArgNum bool 34// panicking is set by catchPanic to avoid infinite panic, recover, panic, ... recursion. 35panicking bool 36// erroring is set when printing an error string to guard against calling handleMethods. 37erroring bool 38// wrapErrs is set when the format string may contain a %w verb. 39wrapErrs bool 40// wrappedErr records the target of the %w verb. 41wrappedErr error 42} 4344// 直接看 doPrintf 方法 45func (p *pp) doPrintf(format string, a []interface{}) { 46end := len(format) 47argNum := 0 // we process one argument per non-trivial format 48afterIndex := false // previous item in format was an index like [3]. 49p.reordered = false 50formatLoop: 51// 逐字符遍历，每个循环去处理一个动词（%d， %v 这种） 52for i := 0; i \u0026lt; end; { 53p.goodArgNum = true 54// 开始的字符位置 55lasti := i 56// 所有的格式化字符都是以 `%` 开始的，所以这里逐字符查找 `%` 57for i \u0026lt; end \u0026amp;\u0026amp; format[i] != \u0026#39;%\u0026#39; { 58i++ 59} 60// 跳出循环，要么是找到了 `%`，要么是到了原来字符串的结尾 61// 判断是不是有原始的字符串需要输出（也就是 `%` 前面的原始信息） 62if i \u0026gt; lasti { 63p.buf.writeString(format[lasti:i]) 64} 65// 如果是因为遍历完字符串跳出的，处理也就结束了 66if i \u0026gt;= end { 67// done processing format string 68break 69} 7071// Process one verb 72// 让 i 索引指向动词的位置 73i++ 7475// Do we have flags? 76// 初始化 flags，避免上个动词带来的影响 77p.fmt.clearflags() 78simpleFormat: 79for ; i \u0026lt; end; i++ { 80// 把动词复制给 c 81c := format[i] 82// 判断是不是修饰符（比如 %+v，%0d 这种格式化方式，在真正的动词前面允许添加一些修饰行为） 83switch c { 84case \u0026#39;#\u0026#39;: 85p.fmt.sharp = true 86case \u0026#39;0\u0026#39;: 87p.fmt.zero = !p.fmt.minus // Only allow zero padding to the left. 88case \u0026#39;+\u0026#39;: 89p.fmt.plus = true 90case \u0026#39;-\u0026#39;: 91p.fmt.minus = true 92p.fmt.zero = false // Do not pad with zeros to the right. 93case \u0026#39; \u0026#39;: 94p.fmt.space = true 95default: 96// Fast path for common case of ascii lower case simple verbs 97// without precision or width or argument indices. 98if \u0026#39;a\u0026#39; \u0026lt;= c \u0026amp;\u0026amp; c \u0026lt;= \u0026#39;z\u0026#39; \u0026amp;\u0026amp; argNum \u0026lt; len(a) { 99if c == \u0026#39;v\u0026#39; { 100// Go syntax 101p.fmt.sharpV = p.fmt.sharp 102p.fmt.sharp = false 103// Struct-field syntax 104p.fmt.plusV = p.fmt.plus 105p.fmt.plus = false 106} 107// 开始处理字符 108p.printArg(a[argNum], rune(c)) 109argNum++ 110i++ 111continue formatLoop 112} 113// Format is more complex than simple flags and a verb or is malformed. 114// 更复杂的格式化动词或者不正确的格式直接就往下走了，这里我们不关注 115break simpleFormat 116} 117} 118119... 120} 121122func (p *pp) printArg(arg interface{}, verb rune) { 123p.arg = arg 124p.value = reflect.Value{} 125126// nil 的特殊处理 127if arg == nil { 128switch verb { 129case \u0026#39;T\u0026#39;, \u0026#39;v\u0026#39;: 130p.fmt.padString(nilAngleString) 131default: 132p.badVerb(verb) 133} 134return 135} 136137// 打印类型和打印指针的特殊处理 138// Special processing considerations. 139// %T (the value\u0026#39;s type) and %p (its address) are special; we always do them first. 140switch verb { 141case \u0026#39;T\u0026#39;: 142p.fmt.fmtS(reflect.TypeOf(arg).String()) 143return 144case \u0026#39;p\u0026#39;: 145p.fmtPointer(reflect.ValueOf(arg), \u0026#39;p\u0026#39;) 146return 147} 148149// Some types can be done without reflection. 150// 简单类型通过断言进行输出 151switch f := arg.(type) { 152case bool: 153p.fmtBool(f, verb) 154case float32: 155p.fmtFloat(float64(f), 32, verb) 156case float64: 157p.fmtFloat(f, 64, verb) 158case complex64: 159p.fmtComplex(complex128(f), 64, verb) 160case complex128: 161p.fmtComplex(f, 128, verb) 162case int: 163// 这里是我们的目标分支 164p.fmtInteger(uint64(f), signed, verb) 165case int8: 166p.fmtInteger(uint64(f), signed, verb) 167case int16: 168p.fmtInteger(uint64(f), signed, verb) 169case int32: 170p.fmtInteger(uint64(f), signed, verb) 171case int64: 172p.fmtInteger(uint64(f), signed, verb) 173case uint: 174p.fmtInteger(uint64(f), unsigned, verb) 175case uint8: 176p.fmtInteger(uint64(f), unsigned, verb) 177case uint16: 178p.fmtInteger(uint64(f), unsigned, verb) 179case uint32: 180p.fmtInteger(uint64(f), unsigned, verb) 181case uint64: 182p.fmtInteger(f, unsigned, verb) 183case uintptr: 184p.fmtInteger(uint64(f), unsigned, verb) 185case string: 186p.fmtString(f, verb) 187case []byte: 188p.fmtBytes(f, verb, \u0026#34;[]byte\u0026#34;) 189case reflect.Value: 190// Handle extractable values with special methods 191// since printValue does not handle them at depth 0. 192if f.IsValid() \u0026amp;\u0026amp; f.CanInterface() { 193p.arg = f.Interface() 194if p.handleMethods(verb) { 195return 196} 197} 198p.printValue(f, verb, 0) 199default: 200// If the type is not simple, it might have methods. 201if !p.handleMethods(verb) { 202// Need to use reflection, since the type had no 203// interface methods that could be used for formatting. 204p.printValue(reflect.ValueOf(f), verb, 0) 205} 206} 207} 208209// 可以看到，这个方法是认为使用者传递的动词是和实际参数的类型匹配的，如果不匹配，将走默认分支，使用 badVerb 处理 210func (p *pp) fmtInteger(v uint64, isSigned bool, verb rune) { 211switch verb { 212case \u0026#39;v\u0026#39;: 213if p.fmt.sharpV \u0026amp;\u0026amp; !isSigned { 214p.fmt0x64(v, true) 215} else { 216p.fmt.fmtInteger(v, 10, isSigned, verb, ldigits) 217} 218case \u0026#39;d\u0026#39;: 219p.fmt.fmtInteger(v, 10, isSigned, verb, ldigits) 220case \u0026#39;b\u0026#39;: 221p.fmt.fmtInteger(v, 2, isSigned, verb, ldigits) 222case \u0026#39;o\u0026#39;, \u0026#39;O\u0026#39;: 223p.fmt.fmtInteger(v, 8, isSigned, verb, ldigits) 224case \u0026#39;x\u0026#39;: 225p.fmt.fmtInteger(v, 16, isSigned, verb, ldigits) 226case \u0026#39;X\u0026#39;: 227p.fmt.fmtInteger(v, 16, isSigned, verb, udigits) 228case \u0026#39;c\u0026#39;: 229p.fmt.fmtC(v) 230case \u0026#39;q\u0026#39;: 231p.fmt.fmtQc(v) 232case \u0026#39;U\u0026#39;: 233p.fmt.fmtUnicode(v) 234default: 235p.badVerb(verb) 236} 237} 238239// 这里输出的就是我们看到的异常情况了 240func (p *pp) badVerb(verb rune) { 241p.erroring = true 242p.buf.writeString(percentBangString) 243p.buf.writeRune(verb) 244p.buf.writeByte(\u0026#39;(\u0026#39;) 245switch { 246case p.arg != nil: 247p.buf.writeString(reflect.TypeOf(p.arg).String()) 248p.buf.writeByte(\u0026#39;=\u0026#39;) 249p.printArg(p.arg, \u0026#39;v\u0026#39;) 250case p.value.IsValid(): 251p.buf.writeString(p.value.Type().String()) 252p.buf.writeByte(\u0026#39;=\u0026#39;) 253p.printValue(p.value, \u0026#39;v\u0026#39;, 0) 254default: 255p.buf.writeString(nilAngleString) 256} 257p.buf.writeByte(\u0026#39;)\u0026#39;) 258p.erroring = false 259} 总结 在 go 中，使用 fmt 包进行格式化输出的时候，go 的实现是倾向于动词和实际参数的类型是匹配的，如果实际使用的时候不匹配，那么会使用 badVerb 进行处理，往往输出的字符串不是我们期望的字符串\n","date":"2022-12-03","img":"","permalink":"https://wangtingkui.space/posts/go/%E8%AE%B0%E4%B8%80%E6%AC%A1fmt.printf%E7%9A%84%E9%97%AE%E9%A2%98/","series":[""],"tags":[""],"title":"记一次fmt.Printf的问题"},{"categories":["go三方库使用和源码分析"],"content":"使用viper的时候看到了这个库，觉得在项目中还是有很多使用场景的，所以拿来说一说\nmapsturcture 干什么用的 根据其官网 的说明，mapstructure是用来进行通用的map和特定的结构体之间互相装换的，比如将下面的变量a转换成变量b\n1var a = map[string]interface{}{ 2\u0026#34;Name\u0026#34;: \u0026#34;bob\u0026#34;, 3\u0026#34;Age\u0026#34;: 18, 4} 56type Person struct { 7Name string 8Age int 9} 1011var b Person 1213e := mapstructure.Decode(a, \u0026amp;b) 14if e != nil { 15panic(e) 16} 1718fmt.Printf(\u0026#34;%#v\\n\u0026#34;, b) 1920// 输出 21// main.Person{Name:\u0026#34;bob\u0026#34;, Age:18} 为什么需要 mapsturcture 通过上面的简单演示，有些同学可能并不能很快的联想到这个库的使用场景，通常我们一般都是直接预定义好对应的结构体，然后decode就好了，比如下面的代码\n1var encodedStr = `{\u0026#34;name\u0026#34;: \u0026#34;bob\u0026#34;, \u0026#34;age\u0026#34;: 18}` 2type Person struct { 3Name string `json:\u0026#34;name\u0026#34;` 4Age int `json:\u0026#34;age\u0026#34;` 5} 6var p Person 7e := json.Unmarshal([]byte(encodedStr), \u0026amp;p) 8if e != nil { 9panic(e) 10} 11fmt.Printf(\u0026#34;%#v\\n\u0026#34;, p) 1213// 输出 14// main.Person{Name:\u0026#34;bob\u0026#34;, Age:18} 但是，也有很多场景，我们往往在读取其中一个字段之前，不知道其他字段的具体结构，比如有一个消息队列，消息队列中的消息要根据type 字段区分不同的结构使用， 如果不使用这个类库，那我们大概率的编码方式会是，先读取type字段，然后根据type字段的类型二次解码不同的结构，代码如下：\n1var msgs = []string{ 2`{\u0026#34;type\u0026#34;: \u0026#34;person\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;bob\u0026#34;, \u0026#34;Age\u0026#34;: 18}`, 3`{\u0026#34;type\u0026#34;: \u0026#34;animal\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;wangwang\u0026#34;}`, 4} 56type T struct { 7Type string `json:\u0026#34;type\u0026#34;` 8} 910type Person struct { 11Name string `json:\u0026#34;name\u0026#34;` 12Age int `json:\u0026#34;age\u0026#34;` 13} 1415type Animal struct { 16Nickname string `json:\u0026#34;nickname\u0026#34;` 17} 1819for _, s := range msgs { 20t := T{} 21if e := json.Unmarshal([]byte(s), \u0026amp;t); e != nil { 22panic(e) 23} else { 24switch t.Type { 25case \u0026#34;person\u0026#34;: 26p := Person{} 27_ = json.Unmarshal([]byte(s), \u0026amp;p) 28fmt.Printf(\u0026#34;%#v\\n\u0026#34;, p) 29case \u0026#34;animal\u0026#34;: 30p := Animal{} 31_ = json.Unmarshal([]byte(s), \u0026amp;p) 32fmt.Printf(\u0026#34;%#v\\n\u0026#34;, p) 33default: 34panic(\u0026#34;not support\u0026#34;) 35} 36} 37} 如果使用了mapstructure，则可以先解析为通用的map，然后将通用的map装换成特定的结构体，代码如下\n1var msgs = []string{ 2`{\u0026#34;type\u0026#34;: \u0026#34;person\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;bob\u0026#34;, \u0026#34;Age\u0026#34;: 18}`, 3`{\u0026#34;type\u0026#34;: \u0026#34;animal\u0026#34;, \u0026#34;nickname\u0026#34;: \u0026#34;wangwang\u0026#34;}`, 4} 56type Person struct { 7Name string `json:\u0026#34;name\u0026#34;` 8Age int `json:\u0026#34;age\u0026#34;` 9} 1011type Animal struct { 12Nickname string `json:\u0026#34;nickname\u0026#34;` 13} 1415for _, s := range msgs { 16t := map[string]interface{}{} 17if e := json.Unmarshal([]byte(s), \u0026amp;t); e != nil { 18panic(e) 19} else { 20switch t[\u0026#34;type\u0026#34;].(string) { 21case \u0026#34;person\u0026#34;: 22p := Person{} 23_ = mapstructure.Decode(t, \u0026amp;p) 24fmt.Printf(\u0026#34;%#v\\n\u0026#34;, p) 25case \u0026#34;animal\u0026#34;: 26p := Animal{} 27_ = mapstructure.Decode(t, \u0026amp;p) 28fmt.Printf(\u0026#34;%#v\\n\u0026#34;, p) 29default: 30panic(\u0026#34;not support\u0026#34;) 31} 32} 33} 3435// 输出 36//main.Person{Name:\u0026#34;bob\u0026#34;, Age:18} 37//main.Animal{Nickname:\u0026#34;wangwang\u0026#34;} 使用 demo 上面已经有简单的使用方式，更详细的使用说明可以参考 godoc 源码分析 老样子，我们还是只分析主流程，从上面例子我们可以看到，一切都可以从mapstructure.Decode方法看起，以下面的一段代码为例\n1m := map[string]interface{}{ 2\u0026#34;Name\u0026#34;: \u0026#34;xiaok\u0026#34;, 3\u0026#34;Age\u0026#34;: 18, 4} 5type Person struct { 6Name string 7Age int 8} 9p := new(Person) 10mapstructure.Decode(m, p) 11fmt.Printf(\u0026#34;%#v\u0026#34;, p) 1// Decode takes an input structure and uses reflection to translate it to 2// the output structure. output must be a pointer to a map or struct. 3// 很简单的一个方法，创建一个配置对象，根据配置对象生成一个Decoder（典型的建造者模式） 4// 然后调用了Decoder的Decode方法 5func Decode(input interface{}, output interface{}) error { 6// decoder的配置，会涉及钩子，如何处理字段名称等等规则，这里都用默认的 7\tconfig := \u0026amp;DecoderConfig{ 8Metadata: nil, 9Result: output, 10} 1112// 生成decoder 13\tdecoder, err := NewDecoder(config) 14if err != nil { 15return err 16} 1718// 调用Decode方法 19\treturn decoder.Decode(input) 20} 继续分析 Decoder.Decode 方法\n1// Decode decodes the given raw interface to the target pointer specified 2// by the configuration. 3func (d *Decoder) Decode(input interface{}) error { 4// 关注第三个参数，取了目的要解析到的真正类型 5\t// 比如我们传递了一个 Person 类型的指针，这里取到的就是真正的 Person 的反射值 6\treturn d.decode(\u0026#34;\u0026#34;, input, reflect.ValueOf(d.config.Result).Elem()) 7} 89// 直接看 decode 的实现 10// Decodes an unknown data type into a specific reflection value. 11func (d *Decoder) decode(name string, input interface{}, outVal reflect.Value) error { 12var inputVal reflect.Value 13if input != nil { 14inputVal = reflect.ValueOf(input) 1516// We need to check here if input is a typed nil. Typed nils won\u0026#39;t 17\t// match the \u0026#34;input == nil\u0026#34; below so we check that here. 18\t// 这里主要处理 typed nil 的问题，关于 typed nil 可以参考这篇文章：https://zhuanlan.zhihu.com/p/151140497 19\tif inputVal.Kind() == reflect.Ptr \u0026amp;\u0026amp; inputVal.IsNil() { 20input = nil 21} 22} 2324// 如果输入为空，那也没有必要解什么东西了 25\t// 这里还处理了设置了 ZeroFields 的情况，我们的主线没有设置，不关注这里了 26\tif input == nil { 27// If the data is nil, then we don\u0026#39;t set anything, unless ZeroFields is set 28\t// to true. 29\tif d.config.ZeroFields { 30outVal.Set(reflect.Zero(outVal.Type())) 3132if d.config.Metadata != nil \u0026amp;\u0026amp; name != \u0026#34;\u0026#34; { 33d.config.Metadata.Keys = append(d.config.Metadata.Keys, name) 34} 35} 36return nil 37} 3839// 判断inputVal是不是合法的，比如没有分配空间之类的 40\tif !inputVal.IsValid() { 41// If the input value is invalid, then we just set the value 42\t// to be the zero value. 43\toutVal.Set(reflect.Zero(outVal.Type())) 44if d.config.Metadata != nil \u0026amp;\u0026amp; name != \u0026#34;\u0026#34; { 45d.config.Metadata.Keys = append(d.config.Metadata.Keys, name) 46} 47return nil 48} 4950// 钩子函数处理，不关注 51\tif d.config.DecodeHook != nil { 52// We have a DecodeHook, so let\u0026#39;s pre-process the input. 53\tvar err error 54input, err = DecodeHookExec(d.config.DecodeHook, inputVal, outVal) 55if err != nil { 56return fmt.Errorf(\u0026#34;error decoding \u0026#39;%s\u0026#39;: %s\u0026#34;, name, err) 57} 58} 5960var err error 61outputKind := getKind(outVal) 62addMetaKey := true 63// 获取拟输出的类型处理，从这里也可以看到，mapstructure库不仅能够处理 map 和 structure 之间的转化 64\t// 其他类型也是能够处理的，只不过我们常用的是 map 和 structure 之间的转换罢了 65\tswitch outputKind { 66case reflect.Bool: 67err = d.decodeBool(name, input, outVal) 68case reflect.Interface: 69err = d.decodeBasic(name, input, outVal) 70case reflect.String: 71err = d.decodeString(name, input, outVal) 72case reflect.Int: 73err = d.decodeInt(name, input, outVal) 74case reflect.Uint: 75err = d.decodeUint(name, input, outVal) 76case reflect.Float32: 77err = d.decodeFloat(name, input, outVal) 78case reflect.Struct: 79err = d.decodeStruct(name, input, outVal) 80case reflect.Map: 81err = d.decodeMap(name, input, outVal) 82case reflect.Ptr: 83addMetaKey, err = d.decodePtr(name, input, outVal) 84case reflect.Slice: 85err = d.decodeSlice(name, input, outVal) 86case reflect.Array: 87err = d.decodeArray(name, input, outVal) 88case reflect.Func: 89err = d.decodeFunc(name, input, outVal) 90default: 91// If we reached this point then we weren\u0026#39;t able to decode it 92\treturn fmt.Errorf(\u0026#34;%s: unsupported type: %s\u0026#34;, name, outputKind) 93} 9495// 元数据的处理 96\t// If we reached here, then we successfully decoded SOMETHING, so 97\t// mark the key as used if we\u0026#39;re tracking metainput. 98\tif addMetaKey \u0026amp;\u0026amp; d.config.Metadata != nil \u0026amp;\u0026amp; name != \u0026#34;\u0026#34; { 99d.config.Metadata.Keys = append(d.config.Metadata.Keys, name) 100} 101102return err 103} 104105// 我们选择符合例子的decodeStruct进行看吧 106func (d *Decoder) decodeStruct(name string, data interface{}, val reflect.Value) error { 107// 取源数据的直接值（也就是如果传入的是指针，取用指针指向的值） 108\tdataVal := reflect.Indirect(reflect.ValueOf(data)) 109110// If the type of the value to write to and the data match directly, 111\t// then we just set it directly instead of recursing into the structure. 112\t// 如果两者类型一样，直接赋值 113\tif dataVal.Type() == val.Type() { 114val.Set(dataVal) 115return nil 116} 117118// 根据源数据类型进行处理 119\tdataValKind := dataVal.Kind() 120switch dataValKind { 121case reflect.Map: 122// 如果源数据是 map 123\treturn d.decodeStructFromMap(name, dataVal, val) 124125case reflect.Struct: 126// 如果源数据是 struct 127\t// Not the most efficient way to do this but we can optimize later if 128\t// we want to. To convert from struct to struct we go to map first 129\t// as an intermediary. 130 131// Make a new map to hold our result 132\tmapType := reflect.TypeOf((map[string]interface{})(nil)) 133mval := reflect.MakeMap(mapType) 134135// Creating a pointer to a map so that other methods can completely 136\t// overwrite the map if need be (looking at you decodeMapFromMap). The 137\t// indirection allows the underlying map to be settable (CanSet() == true) 138\t// where as reflect.MakeMap returns an unsettable map. 139\taddrVal := reflect.New(mval.Type()) 140141reflect.Indirect(addrVal).Set(mval) 142if err := d.decodeMapFromStruct(name, dataVal, reflect.Indirect(addrVal), mval); err != nil { 143return err 144} 145146result := d.decodeStructFromMap(name, reflect.Indirect(addrVal), val) 147return result 148149default: 150return fmt.Errorf(\u0026#34;\u0026#39;%s\u0026#39; expected a map, got \u0026#39;%s\u0026#39;\u0026#34;, name, dataVal.Kind()) 151} 152} 153154// 看如何将一个 map 转成 struct 155func (d *Decoder) decodeStructFromMap(name string, dataVal, val reflect.Value) error { 156dataValType := dataVal.Type() 157if kind := dataValType.Key().Kind(); kind != reflect.String \u0026amp;\u0026amp; kind != reflect.Interface { 158return fmt.Errorf( 159\u0026#34;\u0026#39;%s\u0026#39; needs a map with string keys, has \u0026#39;%s\u0026#39; keys\u0026#34;, 160name, dataValType.Key().Kind()) 161} 162163dataValKeys := make(map[reflect.Value]struct{}) 164dataValKeysUnused := make(map[interface{}]struct{}) 165for _, dataValKey := range dataVal.MapKeys() { 166dataValKeys[dataValKey] = struct{}{} 167dataValKeysUnused[dataValKey.Interface()] = struct{}{} 168} 169170targetValKeysUnused := make(map[interface{}]struct{}) 171errors := make([]string, 0) 172173// This slice will keep track of all the structs we\u0026#39;ll be decoding. 174\t// There can be more than one struct if there are embedded structs 175\t// that are squashed. 176\tstructs := make([]reflect.Value, 1, 5) 177structs[0] = val 178179// Compile the list of all the fields that we\u0026#39;re going to be decoding 180\t// from all the structs. 181\ttype field struct { 182field reflect.StructField 183val reflect.Value 184} 185186// remainField is set to a valid field set with the \u0026#34;remain\u0026#34; tag if 187\t// we are keeping track of remaining values. 188\tvar remainField *field 189190fields := []field{} 191for len(structs) \u0026gt; 0 { 192structVal := structs[0] 193structs = structs[1:] 194195structType := structVal.Type() 196197for i := 0; i \u0026lt; structType.NumField(); i++ { 198fieldType := structType.Field(i) 199fieldVal := structVal.Field(i) 200if fieldVal.Kind() == reflect.Ptr \u0026amp;\u0026amp; fieldVal.Elem().Kind() == reflect.Struct { 201// Handle embedded struct pointers as embedded structs. 202\tfieldVal = fieldVal.Elem() 203} 204205// If \u0026#34;squash\u0026#34; is specified in the tag, we squash the field down. 206\tsquash := d.config.Squash \u0026amp;\u0026amp; fieldVal.Kind() == reflect.Struct \u0026amp;\u0026amp; fieldType.Anonymous 207remain := false 208209// We always parse the tags cause we\u0026#39;re looking for other tags too 210\ttagParts := strings.Split(fieldType.Tag.Get(d.config.TagName), \u0026#34;,\u0026#34;) 211for _, tag := range tagParts[1:] { 212if tag == \u0026#34;squash\u0026#34; { 213squash = true 214break 215} 216217if tag == \u0026#34;remain\u0026#34; { 218remain = true 219break 220} 221} 222223if squash { 224if fieldVal.Kind() != reflect.Struct { 225errors = appendErrors(errors, 226fmt.Errorf(\u0026#34;%s: unsupported type for squash: %s\u0026#34;, fieldType.Name, fieldVal.Kind())) 227} else { 228structs = append(structs, fieldVal) 229} 230continue 231} 232233// Build our field 234\tif remain { 235remainField = \u0026amp;field{fieldType, fieldVal} 236} else { 237// Normal struct field, store it away 238\tfields = append(fields, field{fieldType, fieldVal}) 239} 240} 241} 242243// for fieldType, field := range fields { 244\tfor _, f := range fields { 245field, fieldValue := f.field, f.val 246fieldName := field.Name 247248tagValue := field.Tag.Get(d.config.TagName) 249tagValue = strings.SplitN(tagValue, \u0026#34;,\u0026#34;, 2)[0] 250if tagValue != \u0026#34;\u0026#34; { 251fieldName = tagValue 252} 253254rawMapKey := reflect.ValueOf(fieldName) 255rawMapVal := dataVal.MapIndex(rawMapKey) 256if !rawMapVal.IsValid() { 257// Do a slower search by iterating over each key and 258\t// doing case-insensitive search. 259\tfor dataValKey := range dataValKeys { 260mK, ok := dataValKey.Interface().(string) 261if !ok { 262// Not a string key 263\tcontinue 264} 265266if d.config.MatchName(mK, fieldName) { 267rawMapKey = dataValKey 268rawMapVal = dataVal.MapIndex(dataValKey) 269break 270} 271} 272273if !rawMapVal.IsValid() { 274// There was no matching key in the map for the value in 275\t// the struct. Remember it for potential errors and metadata. 276\ttargetValKeysUnused[fieldName] = struct{}{} 277continue 278} 279} 280281if !fieldValue.IsValid() { 282// This should never happen 283\tpanic(\u0026#34;field is not valid\u0026#34;) 284} 285286// If we can\u0026#39;t set the field, then it is unexported or something, 287\t// and we just continue onwards. 288\tif !fieldValue.CanSet() { 289continue 290} 291292// Delete the key we\u0026#39;re using from the unused map so we stop tracking 293\tdelete(dataValKeysUnused, rawMapKey.Interface()) 294295// If the name is empty string, then we\u0026#39;re at the root, and we 296\t// don\u0026#39;t dot-join the fields. 297\tif name != \u0026#34;\u0026#34; { 298fieldName = name + \u0026#34;.\u0026#34; + fieldName 299} 300301if err := d.decode(fieldName, rawMapVal.Interface(), fieldValue); err != nil { 302errors = appendErrors(errors, err) 303} 304} 305306// If we have a \u0026#34;remain\u0026#34;-tagged field and we have unused keys then 307\t// we put the unused keys directly into the remain field. 308\tif remainField != nil \u0026amp;\u0026amp; len(dataValKeysUnused) \u0026gt; 0 { 309// Build a map of only the unused values 310\tremain := map[interface{}]interface{}{} 311for key := range dataValKeysUnused { 312remain[key] = dataVal.MapIndex(reflect.ValueOf(key)).Interface() 313} 314315// Decode it as-if we were just decoding this map onto our map. 316\tif err := d.decodeMap(name, remain, remainField.val); err != nil { 317errors = appendErrors(errors, err) 318} 319320// Set the map to nil so we have none so that the next check will 321\t// not error (ErrorUnused) 322\tdataValKeysUnused = nil 323} 324325if d.config.ErrorUnused \u0026amp;\u0026amp; len(dataValKeysUnused) \u0026gt; 0 { 326keys := make([]string, 0, len(dataValKeysUnused)) 327for rawKey := range dataValKeysUnused { 328keys = append(keys, rawKey.(string)) 329} 330sort.Strings(keys) 331332err := fmt.Errorf(\u0026#34;\u0026#39;%s\u0026#39; has invalid keys: %s\u0026#34;, name, strings.Join(keys, \u0026#34;, \u0026#34;)) 333errors = appendErrors(errors, err) 334} 335336if d.config.ErrorUnset \u0026amp;\u0026amp; len(targetValKeysUnused) \u0026gt; 0 { 337keys := make([]string, 0, len(targetValKeysUnused)) 338for rawKey := range targetValKeysUnused { 339keys = append(keys, rawKey.(string)) 340} 341sort.Strings(keys) 342343err := fmt.Errorf(\u0026#34;\u0026#39;%s\u0026#39; has unset fields: %s\u0026#34;, name, strings.Join(keys, \u0026#34;, \u0026#34;)) 344errors = appendErrors(errors, err) 345} 346347if len(errors) \u0026gt; 0 { 348return \u0026amp;Error{errors} 349} 350351// Add the unused keys to the list of unused keys if we\u0026#39;re tracking metadata 352\tif d.config.Metadata != nil { 353for rawKey := range dataValKeysUnused { 354key := rawKey.(string) 355if name != \u0026#34;\u0026#34; { 356key = name + \u0026#34;.\u0026#34; + key 357} 358359d.config.Metadata.Unused = append(d.config.Metadata.Unused, key) 360} 361for rawKey := range targetValKeysUnused { 362key := rawKey.(string) 363if name != \u0026#34;\u0026#34; { 364key = name + \u0026#34;.\u0026#34; + key 365} 366367d.config.Metadata.Unset = append(d.config.Metadata.Unset, key) 368} 369} 370371return nil 372} ","date":"2022-08-13","img":"","permalink":"https://wangtingkui.space/posts/go/mapstructure/","series":[],"tags":["go"],"title":"Mapstructure 库的使用和分析"},{"categories":[""],"content":"在批量redis操作的场景中，可以使用 pipeline 技术减少 rtt 时间对程序性能的影响，什么是pipeline可以参考这篇文章 本文将对 redis-go 中 pipeline 相关代码进行源码分析\n版本信息 版本信息  go: go version go1.16.10 darwin/amd64 go-redis/redis: v8.11.5  基本使用 go-redis 官方文档中相关文章：点击 1func main() { 2client := redis.NewClient(\u0026amp;redis.Options{ 3Addr: \u0026#34;redis:6379\u0026#34;, 4}) 56// 第一种使用方式 7\t{ 8ctx := context.Background() 9pipe := client.Pipeline() 10pipe.Set(ctx, \u0026#34;test1\u0026#34;, \u0026#34;test1value\u0026#34;, 100*time.Second) 11pipe.Get(ctx, \u0026#34;test1\u0026#34;) 12cmds, err := pipe.Exec(ctx) 13if err != nil { 14panic(err) 15} 16for _, c := range cmds { 17switch a := c.(type) { 18case *redis.StatusCmd: 19fmt.Println(a.Result()) 20case *redis.StringCmd: 21fmt.Println(a.Result()) 22default: 23fmt.Println(\u0026#34;unsupport cmd type\u0026#34;) 24} 25} 26} 2728// 第二种使用方式 29\t{ 30ctx := context.Background() 31cmds, err := client.Pipelined(ctx, func(pipeliner redis.Pipeliner) error { 32pipeliner.Set(ctx, \u0026#34;test2\u0026#34;, \u0026#34;test2value\u0026#34;, 100*time.Second) 33pipeliner.Get(ctx, \u0026#34;test2\u0026#34;) 34return nil 35}) 36if err != nil { 37panic(err) 38} 39for _, c := range cmds { 40switch a := c.(type) { 41case *redis.StatusCmd: 42fmt.Println(a.Result()) 43case *redis.StringCmd: 44fmt.Println(a.Result()) 45default: 46fmt.Println(\u0026#34;unsupport cmd type\u0026#34;) 47} 48} 49} 5051} 源码分析 由于第二种使用方式只是对第一种的简单封装，所以我们用第一种进行源码分析就好\n1// 使用 Client 的 Pipeline 方法返回一个 Pipeliner 2func (c *Client) Pipeline() Pipeliner { 3pipe := Pipeline{ 4ctx: c.ctx, 5exec: c.processPipeline, 6} 7pipe.init() 8return \u0026amp;pipe 9} 1011// 观察 Pipeliner 的结构 12// 是一个接口 13// 描述的就是redis的pipeline功能 14// 实际的实现是 Pipeline 15type Pipeliner interface { 16StatefulCmdable 17Len() int 18Do(ctx context.Context, args ...interface{}) *Cmd 19Process(ctx context.Context, cmd Cmder) error 20Close() error 21Discard() error 22Exec(ctx context.Context) ([]Cmder, error) 23} 2425// 观察Pipeline的结构 26type Pipeline struct { 27cmdable 28statefulCmdable 2930ctx context.Context 31exec pipelineExecer 3233mu sync.Mutex 34cmds []Cmder 35closed bool 36} 3738// Pipeline 中需要我们关注就是 exec 这个成员 39// pipelineExecer 是一个函数类型，定义为 func(context.Context, []Cmder) error 40// 构建过程中，exec 被赋值为 Client.processPipeline 41// 还是老套路，在外面包了层 hooks 的方法 42// 核心使用的是 c.baseClient.processPipeline 43func (c *Client) processPipeline(ctx context.Context, cmds []Cmder) error { 44return c.hooks.processPipeline(ctx, cmds, c.baseClient.processPipeline) 45} 4647// 直接看 c.baseClient.processPipeline 48func (c *baseClient) processPipeline(ctx context.Context, cmds []Cmder) error { 49return c.generalProcessPipeline(ctx, cmds, c.pipelineProcessCmds) 50} 5152// 这个方法也没啥，就是对错误进行了下处理 53func (c *baseClient) generalProcessPipeline( 54ctx context.Context, cmds []Cmder, p pipelineProcessor, 55) error { 56err := c._generalProcessPipeline(ctx, cmds, p) 57if err != nil { 58setCmdsErr(cmds, err) 59return err 60} 61return cmdsFirstErr(cmds) 62} 6364// 处理逻辑，这里和上篇文章分析的 _process 很像 65func (c *baseClient) _generalProcessPipeline( 66ctx context.Context, cmds []Cmder, p pipelineProcessor, 67) error { 68var lastErr error 69for attempt := 0; attempt \u0026lt;= c.opt.MaxRetries; attempt++ { 70// 处理重试延时 71\tif attempt \u0026gt; 0 { 72if err := internal.Sleep(ctx, c.retryBackoff(attempt)); err != nil { 73return err 74} 75} 7677var canRetry bool 78// 拿到连接，执行真正的处理方法，也就是从外面传进来的 Client.pipelineProcessCmds 方法 79\tlastErr = c.withConn(ctx, func(ctx context.Context, cn *pool.Conn) error { 80var err error 81canRetry, err = p(ctx, cn, cmds) 82return err 83}) 84if lastErr == nil || !canRetry || !shouldRetry(lastErr, true) { 85return lastErr 86} 87} 88return lastErr 89} 9091// 发送命令和读取命令的处理 92func (c *baseClient) pipelineProcessCmds( 93ctx context.Context, cn *pool.Conn, cmds []Cmder, 94) (bool, error) { 95err := cn.WithWriter(ctx, c.opt.WriteTimeout, func(wr *proto.Writer) error { 96return writeCmds(wr, cmds) 97}) 98if err != nil { 99return true, err 100} 101102err = cn.WithReader(ctx, c.opt.ReadTimeout, func(rd *proto.Reader) error { 103return pipelineReadCmds(rd, cmds) 104}) 105return true, err 106} 总结 可以发现，对 go-redis 中 pipline 的处理和正常处理一个单命令的流程很像，只不过是一次性按照协议写入多个命令和一次性读取多个回复而已\n注意事项 在源码中对pipeline有如下备注:\n1// Pay attention, that Pipeline is not a transaction, so you can get unexpected 2// results in case of big pipelines and small read/write timeouts. 3// Redis client has retransmission logic in case of timeouts, pipeline 4// can be retransmitted and commands can be executed more then once. 5// To avoid this: it is good idea to use reasonable bigger read/write timeouts 6// depends of your batch size and/or use TxPipeline. 大意是，pipeline中如果命令较多，而设置的超时时间又比较小，可能会造成执行超时，由于默认情况下，redis客户端有重试的机制，所以可能会造成命令的重复执行。可以通过设置合理的超时时间或者使用 TxPipeline 解决这种情况\nTxPipeline 的实现其实就是讲 pipeline 的执行放到了redis 事务中，关于事务的实现，有时间单独分析下其源码\n","date":"2022-04-17","img":"","permalink":"https://wangtingkui.space/posts/go/redis-go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8Bpipeline/","series":null,"tags":["go"],"title":"Redis Go源码分析之pipeline"},{"categories":[""],"content":"go-redis/redis 这个包是当下go语言操作redis比较常用的包，它支持了几乎redis的所有命令；并且对应redis不同的架构（主从/Sential/Cluster\u0026hellip;）也有良好的支持\n本片文章主要演示其简单的使用和对主流程代码进行简要分析，后续可能对高级操作（pipeline/pub-sub\u0026hellip;）进行源码分析\n版本信息  go: go version go1.16.10 darwin/amd64 go-redis/redis: v8.11.5  基本使用 go-redis提供了多种客户端的支持, 本文主要使用单实例的 redis server 作为演示\n在命令调用上，go-redis 提供了两种方式，一种是通过客户端的方法直接执行命令，类似client.Get，另外一种是通过client.Do方法，我们常用的是第一种，第二种主要是为了支持 go-redis 中未实现的命令，可以让我们直接用 redis 的协议和 server 进行交互；其实本质上第一种方式只是对第二种方式的封装，为我们提供了更方便的操作入口而已，不需要我们手动的对返回的数据进行类型的转换等操作\n1package main 23import ( 4\u0026#34;context\u0026#34; 5\u0026#34;fmt\u0026#34; 6\u0026#34;github.com/go-redis/redis/v8\u0026#34; 7\u0026#34;time\u0026#34; 8) 910func judge(v interface{}, e error) { 11if e == redis.Nil { 12fmt.Println(e) 13} else if e != nil { 14panic(e) 15} 16fmt.Println(v) 17} 1819func main() { 20client := redis.NewClient(\u0026amp;redis.Options{ 21Addr: \u0026#34;127.0.0.1:6379\u0026#34;, 22}) 2324ctx := context.Background() 25key := \u0026#34;test\u0026#34; 26value := \u0026#34;testval\u0026#34; 2728{ 29v, e := client.Do(ctx, key, value).Result() 30judge(v, e) 31} 3233{ 34v, e := client.Get(ctx, key).Result() 35judge(v, e) 36} 3738{ 39v, e := client.Set(ctx, key, value, 100*time.Second).Result() 40judge(v, e) 41} 4243{ 44v, e := client.Del(ctx, key).Result() 45judge(v, e) 46} 47} 额外知识 redis 协议 redis 协议本身是个文本协议，兼具了解析速度和可读性，可以参考这篇文章 了解一下，可以帮助我们更好的了解编码过程中为什么使用一些特殊的符号来编码数据类型，关于 redis 协议相关的编码主要集中在 internal/proto 目录下\n命令模式 命令模式是23种经典设计模式之一，go-redis就是采用了这种设计模式，将整个流程拆分成了命令的发送者，命令本身和命令的执行者三个部分，能够实现程序的解耦，方便扩展，关于命令模式的更多信息可以参考这篇文章 源码分析 我们上面也提到了，client.Get这种调用方式只是对client.Do这种方式进一步的封装，那我们就用下面一段代码来进行我们的主流程分析\n1func main() { 2client := redis.NewClient(\u0026amp;redis.Options{ 3Addr: \u0026#34;127.0.0.1:6379\u0026#34;, 4}) 56cmd := client.Do(context.Background(), \u0026#34;set\u0026#34;, \u0026#34;testkey\u0026#34;, \u0026#34;testval\u0026#34;) 7v, e := cmd.Result() 8if e != nil { 9panic(e) 10} 11fmt.Println(v) 12} redis.Options redis.Options存储了客户端操作的各种配置，比如server地址、超时时间、重试次数等等，这里没有特殊需要说明的\nredis.NewClient 1func NewClient(opt *Options) *Client { 2// 补充 redis.Options 默认值 3\topt.init() 45// 最终返回 Client 类型的指针，其实不同种类的客户端返回的都是这个类型，只不过会在 6 // 自己的 New 方法中针对 Client 做一些其他复杂的配置和操作，可以参考 FailoverClient 7\tc := Client{ 8baseClient: newBaseClient(opt, newConnPool(opt)), 9ctx: context.Background(), 10} 11c.cmdable = c.Process 1213return \u0026amp;c 14} 1516// 看下 Client 的结构 17type Client struct { 18// 链接池 19\t*baseClient 20// 这是一个函数类型，定义为 func(ctx context.Context, cmd Cmder) error 21 // 这里出现了一个 Cmder 类型，它是一个接口类型，描述的就是一个要执行的命令 22 // 说明 cmdable 这个方法的能力就是接受一个命令，并且执行他 23\tcmdable 24// 一堆钩子，可以在命令执行前后做一些自定义操作 25\thooks 26ctx context.Context 27} 2829// hooks定义 30type hooks struct { 31hooks []Hook 32} 3334// 看下cmdable是怎么初始化的 35// NewClient方法中直接将 Client.Process 方法赋给了 cmdable，看下 Client.Process 方法是怎么写的 36func (c *Client) Process(ctx context.Context, cmd Cmder) error { 37return c.hooks.process(ctx, cmd, c.baseClient.process) 38} 3940// 调用了 hooks 的process 方法 41func (hs hooks) process( 42ctx context.Context, cmd Cmder, fn func(context.Context, Cmder) error, 43) error { 44// 没有设置钩子的时候，直接执行了我们传进来的 cmdbale 类型的方法 45\tif len(hs.hooks) == 0 { 46err := fn(ctx, cmd) 47cmd.SetErr(err) 48return err 49} 5051var hookIndex int 52var retErr error 5354// 执行 BeforeProcess 钩子 55\tfor ; hookIndex \u0026lt; len(hs.hooks) \u0026amp;\u0026amp; retErr == nil; hookIndex++ { 56ctx, retErr = hs.hooks[hookIndex].BeforeProcess(ctx, cmd) 57if retErr != nil { 58cmd.SetErr(retErr) 59} 60} 6162// 前置钩子没有出错，执行传入的 cmdable 类型的方法 63\tif retErr == nil { 64retErr = fn(ctx, cmd) 65cmd.SetErr(retErr) 66} 6768// 倒序执行 AfterProcess 方法 69\tfor hookIndex--; hookIndex \u0026gt;= 0; hookIndex-- { 70if err := hs.hooks[hookIndex].AfterProcess(ctx, cmd); err != nil { 71retErr = err 72cmd.SetErr(retErr) 73} 74} 7576return retErr 77} 7879// 可以看到 hooks.process 方法执行包裹进了钩子的流程，核心的处理还是在 c.baseClient.process 80// 这里只是报过了重试机制，直接看 _process 81func (c *baseClient) process(ctx context.Context, cmd Cmder) error { 82var lastErr error 83for attempt := 0; attempt \u0026lt;= c.opt.MaxRetries; attempt++ { 84attempt := attempt 8586retry, err := c._process(ctx, cmd, attempt) 87if err == nil || !retry { 88return err 89} 9091lastErr = err 92} 93return lastErr 94} 9596func (c *baseClient) _process(ctx context.Context, cmd Cmder, attempt int) (bool, error) { 97// 重试休眠 98\tif attempt \u0026gt; 0 { 99if err := internal.Sleep(ctx, c.retryBackoff(attempt)); err != nil { 100return false, err 101} 102} 103104// ??? 我觉得这里应该是0，没找到有其他修改这个值为0的地方 105\tretryTimeout := uint32(1) 106// withConn方法主要从链接池拿到一个链接，然后指定指定的命令，核心逻辑还是下面传入的方法 107 // 传入的方法就是处理了一次命令的交互（发送命令和接收结果） 108\terr := c.withConn(ctx, func(ctx context.Context, cn *pool.Conn) error { 109// 处理发送 110\terr := cn.WithWriter(ctx, c.opt.WriteTimeout, func(wr *proto.Writer) error { 111// 通过 proto.Writer 写入命令，主要就是命令的序列化过程 112\treturn writeCmd(wr, cmd) 113}) 114if err != nil { 115return err 116} 117118// 处理接收，这里传入了一个 cmd.readReply 方法，各种不同的命令可以实现自己的 readReply 119 // 由于我们使用的是Do方法，所以这里用的是Cmd类型的readReply，本质上就是将redis server 返回的响应解析到 cmd 对象的 val 和 err 字段中 120\terr = cn.WithReader(ctx, c.cmdTimeout(cmd), cmd.readReply) 121if err != nil { 122// 如果读取发生了错误，并且没有设置超时时间 123\tif cmd.readTimeout() == nil { 124atomic.StoreUint32(\u0026amp;retryTimeout, 1) 125} 126return err 127} 128129return nil 130}) 131if err == nil { 132return false, nil 133} 134135// 是否需要重试 136\tretry := shouldRetry(err, atomic.LoadUint32(\u0026amp;retryTimeout) == 1) 137return retry, err 138} client.Do 通过上面的代码我们了解了client的初始化过程和简单的发送命令的处理过程，下面我们看下如何触发命令的发送，也就是Do方法\n1func (c *Client) Do(ctx context.Context, args ...interface{}) *Cmd { 2// 根据输入的参数，创建一个命令 3\tcmd := NewCmd(ctx, args...) 4// 执行这个命令，Process 方法的流程上面我们已经分析过了 5\t_ = c.Process(ctx, cmd) 6return cmd 7} 89// 看一下命令的构造过程 10// baseCmd 实际上是实现了 Cmder 接口类型，其他各种命令都是基于 baseCmd 组合出来的 11// 这个Do方法使用的通用的Cmd就是组合了baseCmd并添加了一个 val 成员 12type Cmd struct { 13baseCmd 1415val interface{} 16} 1718// 其实没有其他的操作 19func NewCmd(ctx context.Context, args ...interface{}) *Cmd { 20return \u0026amp;Cmd{ 21baseCmd: baseCmd{ 22ctx: ctx, 23args: args, 24}, 25} 26} 2728// 在之前 Process 的分析中，我们了解到 29// 在发送命令的过程中，会用到 Cmder.Args 方法 30// 在接收结果的过程中，会用到 Cmder.readReply 方法 31// 我们依次看一下 32 33// 通过代码我们可以发现 Cmd 类型没有实现 Args 方法，所以他用的其实是 baseCmd 中的 Args 34func (cmd *baseCmd) Args() []interface{} { 35return cmd.args 36} 3738// Cmd.readReply， 直接调用了 proto.Reader.ReadReply 39func (cmd *Cmd) readReply(rd *proto.Reader) (err error) { 40cmd.val, err = rd.ReadReply(sliceParser) 41return err 42} 4344// 既然不同的类型Cmder会实现自己的readReply，那我们看看字符串类型的怎么实现的 45// 调用的是proto.Reader.ReadString 46// 和上面的区别是这个方法里面直接就断定返回的是指定类型的数据，并且 StringCmd.val 类型从 Cmd.val 的 interface{}变成了 string 47// 少了判断性能会更高，后续用起来也会更方便 48func (cmd *StringCmd) readReply(rd *proto.Reader) (err error) { 49cmd.val, err = rd.ReadString() 50return err 51} 5253// 执行完之后，我们会通过 Cmd.Result 方法获取到执行结果 54func (cmd *Cmd) Result() (interface{}, error) { 55return cmd.val, cmd.err 56} 5758// 顺便看下 StringCmd.Result，果然重写了类型，这样我们通过 client.Get 方法执行后拿到的结果直接就是字符串了 59func (cmd *StringCmd) Result() (string, error) { 60return cmd.Val(), cmd.err 61} 总结 以上，我们简单介绍了 go-redis/go 这个包的简单使用方法和其执行流程，后续可能会针对一些高级用法分析其使用方式和源码\n","date":"2022-04-17","img":"","permalink":"https://wangtingkui.space/posts/go/redis-go%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","series":null,"tags":["go"],"title":"Go Redis源码分析（一）"},{"categories":[""],"content":"前言 最近看到了一个 go 的 goroutine池的实现，想着来学习下\n在go中有没有必要使用池化技术？ 只有一个东西是有用的时候我们才值得去学习，我们知道，在一些传统的语言中（如c/c++），使用的是操作系统的线程来达到并发编程的目的，在创建和销毁线程的时候会有比较大的开销（系统调用），使用池化技术能有效的避免频繁的创建销毁带来的开销，也能有效的对资源的申请进行一定程度的管控。所以在这类型语言的引用中，往往会使用线程池技术来达到以下的目的：\n 解决频繁申请/销毁资源和调度资源，带来的额外消耗 对资源无限申请提供抑制手段，降低引发系统资源耗尽的风险  那在go中，goroutine 是一个超轻量级的并发模型的实现，我们可以轻松的开启成千上万个 goroutine 而不必担心带来的系统消耗，所以在 go 中我们是否还有必要去实现一个 goroutine 池呢？\n我这里说下我的看法：对于小型系统，开启的goroutine甚至都不会过百的应用，完全没有必要使用池化技术，runtime 的实现完全能够 hold 住；那么哪些应用适合使用 goroutine 池呢？\n 要对海量的 goroutine 进行管理（毕竟系统的资源也是有限的，如果无节制的开启，也会oom）， 对 goroutine 的数量有一定的管控诉求，要支持动态的扩缩容 并且对资源的使用有一定的优化诉求的场景下  ants 项目源码分析 版本 1github.com/panjf2000/ants/v2 v2.4.7 23❯ go version 4go version go1.16.10 darwin/amd64 使用 demo 1func main() { 2pool, err := ants.NewPool(100) 3if err != nil { 4panic(\u0026#34;init pool err\u0026#34;) 5} 6wg := sync.WaitGroup{} 7for i := 1; i \u0026lt;= 10; i++ { 8wg.Add(1) 9pool.Submit(func() { 10fmt.Println(\u0026#34;abc\u0026#34;) 11wg.Done() 12}) 13} 14wg.Wait() 15fmt.Println(\u0026#34;done\u0026#34;) 16pool.Release() 17} 源码分析 由于该项目代码不多，结构也不复杂，大家可以自行阅读分析，也可以参考这篇文章 ","date":"2022-02-05","img":"","permalink":"https://wangtingkui.space/posts/go/ants/","series":[""],"tags":["go源码阅读"],"title":"Ants源码阅读"},{"categories":[],"content":"前言 数据库读写分离是企业级项目的基本能力，成熟的数据库类库基本都内置支持了读写分离的能力，在 gorm 中，读写分离是通过插件的方式实现的\ngorm 的插件能力 插件相关的简介可以参考官方文档 dbresolver gorm 实现了读写分离能力的插件叫做 dbresolver ，他提供了多数据库的支持，其中就包括读写分离\n源码分析 注册插件 下面这段代码是粘贴自 resolver 项目 readme\n1import ( 2\u0026#34;gorm.io/gorm\u0026#34; 3\u0026#34;gorm.io/plugin/dbresolver\u0026#34; 4\u0026#34;gorm.io/driver/mysql\u0026#34; 5) 67DB, err := gorm.Open(mysql.Open(\u0026#34;db1_dsn\u0026#34;), \u0026amp;gorm.Config{}) 89DB.Use(dbresolver.Register(dbresolver.Config{ 10// use `db2` as sources, `db3`, `db4` as replicas 11 Sources: []gorm.Dialector{mysql.Open(\u0026#34;db2_dsn\u0026#34;)}, 12Replicas: []gorm.Dialector{mysql.Open(\u0026#34;db3_dsn\u0026#34;), mysql.Open(\u0026#34;db4_dsn\u0026#34;)}, 13// sources/replicas load balancing policy 14 Policy: dbresolver.RandomPolicy{}, 15}).Register(dbresolver.Config{ 16// use `db1` as sources (DB\u0026#39;s default connection), `db5` as replicas for `User`, `Address` 17 Replicas: []gorm.Dialector{mysql.Open(\u0026#34;db5_dsn\u0026#34;)}, 18}, \u0026amp;User{}, \u0026amp;Address{}).Register(dbresolver.Config{ 19// use `db6`, `db7` as sources, `db8` as replicas for `orders`, `Product` 20 Sources: []gorm.Dialector{mysql.Open(\u0026#34;db6_dsn\u0026#34;), mysql.Open(\u0026#34;db7_dsn\u0026#34;)}, 21Replicas: []gorm.Dialector{mysql.Open(\u0026#34;db8_dsn\u0026#34;)}, 22}, \u0026#34;orders\u0026#34;, \u0026amp;Product{}, \u0026#34;secondary\u0026#34;)) 首先，我们来看下涉及的几个核心类型：\n1// 核心类，用来处理多数据库的切换功能 2type DBResolver struct { 3*gorm.DB 4configs []Config 5resolvers map[string]*resolver 6global *resolver 7prepareStmtStore map[gorm.ConnPool]*gorm.PreparedStmtDB 8compileCallbacks []func(gorm.ConnPool) error 9} 1011// DBResolver 的配置类 12// Sources 就是支持写的数据源 13// Replicas 是副本，也就是支持读的数据源 14// 从结构的定义上可以看到，读写都是支持多个的，所以需要有一定的负载均衡策略，也就是 Policy 15// datas 用来指定哪些表走这个数据源，如果不指定，默认这个配置对应就是全局的 16type Config struct { 17Sources []gorm.Dialector 18Replicas []gorm.Dialector 19Policy Policy 20datas []interface{} 21} 了解了核心的类型之后，我们看下功能是怎么运转的，先看下dbresolver.Register方法\n1// 本质上就是个快捷方法，为我们节省手动创建DBResolver对象的过程而已 2// 核心还是走的 DBResolver 实例的 Register 3func Register(config Config, datas ...interface{}) *DBResolver { 4return (\u0026amp;DBResolver{}).Register(config, datas...) 5} 看 DBResolver.Register\n1func (dr *DBResolver) Register(config Config, datas ...interface{}) *DBResolver { 2// 初始化 prepareStmtStore 3 if dr.prepareStmtStore == nil { 4dr.prepareStmtStore = map[gorm.ConnPool]*gorm.PreparedStmtDB{} 5} 67// 初始化 resolvers 8\tif dr.resolvers == nil { 9dr.resolvers = map[string]*resolver{} 10} 1112// 初始化负载均衡策略 13\tif config.Policy == nil { 14config.Policy = RandomPolicy{} 15} 1617config.datas = datas 18// 将指定配置追加到 dr.configs 中 19\tdr.configs = append(dr.configs, config) 20if dr.DB != nil { 21// 编译配置，本质上就是根据配置和*DB的信息生成一个 resolver 存到 dr 中 22\tdr.compileConfig(config) 23} 24return dr 25} 2627func (dr *DBResolver) compileConfig(config Config) (err error) { 28var ( 29// 默认的链接 30\tconnPool = dr.DB.Config.ConnPool 31r = resolver{ 32dbResolver: dr, 33policy: config.Policy, 34} 35) 3637if preparedStmtDB, ok := connPool.(*gorm.PreparedStmtDB); ok { 38connPool = preparedStmtDB.ConnPool 39} 4041// 如果没有配置 Sources，就让默认的 connPool 成为 Source 42 // 否则根据指定的 Sources 生成对应的 connPool 43\tif len(config.Sources) == 0 { 44r.sources = []gorm.ConnPool{connPool} 45} else if r.sources, err = dr.convertToConnPool(config.Sources); err != nil { 46return err 47} 4849// 和 Sources 道理一样，只不过处理的是读的数据源 50\tif len(config.Replicas) == 0 { 51r.replicas = r.sources 52} else if r.replicas, err = dr.convertToConnPool(config.Replicas); err != nil { 53return err 54} 5556if len(config.datas) \u0026gt; 0 { 57for _, data := range config.datas { 58// 如果传了字符串的附属信息，则用这个字符串当做当前这个配置生成的resolver的名字 59\tif t, ok := data.(string); ok { 60dr.resolvers[t] = \u0026amp;r 61} else { 62// 否则从模型中去解析表名当做resolver的名字 63 // 这也是可以指定某些表走某些数据源的实现原理 64\tstmt := \u0026amp;gorm.Statement{DB: dr.DB} 65if err := stmt.Parse(data); err == nil { 66dr.resolvers[stmt.Table] = \u0026amp;r 67} else { 68return err 69} 70} 71} 72} else if dr.global == nil { 73// 如果没有指定应用到哪个表，则把这个 resolver 当做全局的 74\tdr.global = \u0026amp;r 75} else { 76// 从这里可以看到，全局的resolver只支持一个（也就是不带datas参数的config只支持传入一个） 77\treturn errors.New(\u0026#34;conflicted global resolver\u0026#34;) 78} 7980// 如果有回调的话，执行下回调函数 81\tfor _, fc := range dr.compileCallbacks { 82if err = r.call(fc); err != nil { 83return err 84} 85} 8687return nil 88} 插件初始化 上面分析的是实例化插件并注册的过程，gorm 的插件机制，当注册后会调用插件的 Initialize 方法进行初始化，dbresolver 的功能就是在这里以 callbacks 的方式和 gorm 结合起来的\n1func (dr *DBResolver) Initialize(db *gorm.DB) error { 2dr.DB = db 3dr.registerCallbacks(db) 4return dr.compile() 5} 67// 我们只关注 query 行为的 callback 8// 将 switchReplica 这个方法注册到了所有 callback 的最前面 9func (dr *DBResolver) registerCallbacks(db *gorm.DB) { 10... 11dr.Callback().Query().Before(\u0026#34;*\u0026#34;).Register(\u0026#34;gorm:db_resolver\u0026#34;, dr.switchReplica) 12... 13} 1415func (dr *DBResolver) switchReplica(db *gorm.DB) { 16// 当前不在事务中才能进行切换 17\tif !isTransaction(db.Statement.ConnPool) { 18if rawSQL := db.Statement.SQL.String(); len(rawSQL) \u0026gt; 0 { 19// 通过 sql 来确定要切换到哪个副本 20\tdr.switchGuess(db) 21} else { 22// 如果指定了 WRITE/FOR 的 Clause，切换到写的数据源上 23\t_, locking := db.Statement.Clauses[\u0026#34;FOR\u0026#34;] 24if _, ok := db.Statement.Clauses[writeName]; ok || locking { 25db.Statement.ConnPool = dr.resolve(db.Statement, Write) 26} else { 27// 否则切换到读的数据源 28\tdb.Statement.ConnPool = dr.resolve(db.Statement, Read) 29} 30} 31} 32} 3334func (dr *DBResolver) switchGuess(db *gorm.DB) { 35if !isTransaction(db.Statement.ConnPool) { 36// 如果指定了 WRITE 的 Clause ，走写 37 // 如果原始 sql 包含 select 但是不包含 for， 走读 38 // 其他情况走写 39\tif _, ok := db.Statement.Clauses[writeName]; ok { 40db.Statement.ConnPool = dr.resolve(db.Statement, Write) 41} else if rawSQL := strings.TrimSpace(db.Statement.SQL.String()); len(rawSQL) \u0026gt; 10 \u0026amp;\u0026amp; strings.EqualFold(rawSQL[:6], \u0026#34;select\u0026#34;) \u0026amp;\u0026amp; !strings.EqualFold(rawSQL[len(rawSQL)-10:], \u0026#34;for update\u0026#34;) { 42db.Statement.ConnPool = dr.resolve(db.Statement, Read) 43} else { 44db.Statement.ConnPool = dr.resolve(db.Statement, Write) 45} 46} 47} 4849func (dr *DBResolver) resolve(stmt *gorm.Statement, op Operation) gorm.ConnPool { 50// 配置了针对指定表的 resolver 的情况 51\tif len(dr.resolvers) \u0026gt; 0 { 52// 使用了指定名字的 Clause，直接使用对应名字的解析 53\tif u, ok := stmt.Clauses[usingName].Expression.(using); ok \u0026amp;\u0026amp; u.Use != \u0026#34;\u0026#34; { 54if r, ok := dr.resolvers[u.Use]; ok { 55return r.resolve(stmt, op) 56} 57} 5859// 使用表名 60\tif stmt.Table != \u0026#34;\u0026#34; { 61if r, ok := dr.resolvers[stmt.Table]; ok { 62return r.resolve(stmt, op) 63} 64} 6566if stmt.Schema != nil { 67if r, ok := dr.resolvers[stmt.Schema.Table]; ok { 68return r.resolve(stmt, op) 69} 70} 7172// 从原始 sql 解析表名 73\tif rawSQL := stmt.SQL.String(); rawSQL != \u0026#34;\u0026#34; { 74if r, ok := dr.resolvers[getTableFromRawSQL(rawSQL)]; ok { 75return r.resolve(stmt, op) 76} 77} 78} 7980// 全局的不为空，返回全局的 81\tif dr.global != nil { 82return dr.global.resolve(stmt, op) 83} 8485// 兜底返回*DB中的 86\treturn stmt.ConnPool 87} 结尾 从上面的代码分析我们可以看出，gorm 的 callbacks 机制还是很强大的，我们可以基于这个机制灵活的定制我们想要的功能\n","date":"2022-02-02","img":"","permalink":"https://wangtingkui.space/posts/go/gorm-read-write-split/","series":null,"tags":["go"],"title":"Gorm源码阅读 - 3.读写分离"},{"categories":[],"content":"承上 在基础流程篇中我们层多次提到 Clause 的概念，本片就让我们详细分析下 Clause 究竟是什么\n从基础流程篇中我们可以知道 Clause 就是一个 sql 子句，我们调用 gorm 提供的链式api的过程，就是不断的添加子句，最后当调用 Finisher 方法的时候，将所有的子句构建成一个完整的 sql，然后执行。举个简单的例子，当我们调用db.Where(\u0026quot;a = ?\u0026quot;, 1)这个方法的时候，就是用这些参数去生成了一个clause.Where的Clause对象，不同的Clause对象（比如Where、Limit\u0026hellip;）可能会有不同的参数，但他们都会实现Build方法。去根据自己需要的参数构建出真实的sql片段，比如上面的例子就会构建出where a = 1的sql 片段。那我们其实就知道了，gorm生成sql的方式就是实现不同关键字对应的Clause，然后将这些sql片段拼接起来而已\n我们还是通过基础流程篇的代码来简单分析下这个流程，关注Where和First方法\n1// 连接数据库 2db, err := gorm.Open(sqlite.Open(\u0026#34;test.db\u0026#34;), \u0026amp;gorm.Config{}) 3if err != nil { 4panic(\u0026#34;failed to connect database\u0026#34;) 5} 67// 自动创建表结构 8if err = db.AutoMigrate(\u0026amp;Test{}); err != nil { 9panic(\u0026#34;auto migrate err\u0026#34;) 10} 1112// 查询 13var v Test 14db.Debug().Model(\u0026amp;Test{}).Where(\u0026#34;b = ?\u0026#34;, \u0026#34;test\u0026#34;).First(\u0026amp;v) 在详细研究之前，我们先看下源码中都有哪些对Clause的相关定义\n1// clause.go:4 2// Interface clause interface 3// clasue.Interface 就是对 Cluase 的抽象，Where、Limit等Cluase都是实现了这些方法的对象 4type Interface interface { 5Name() string // Clause 的名字 6\tBuild(Builder) // 这个 Clause 怎么构造自己的 sql 片段 7\tMergeClause(*Clause) // 多个同名的Clause被添加的时候应该怎么处理 8} 910// clause.go:26 11// Clause 12// 这个 Clause 是一个衔接方，他将Statement对象和具体的Clause实现串联起来（本人觉得这个名字起得不好，容易误导） 13type Clause struct { 14Name string // WHERE 15\tBeforeExpression Expression 16AfterNameExpression Expression 17AfterExpression Expression 18Expression Expression 19Builder ClauseBuilder 20} Where代码分析 那接下来看下Where的代码：\n1// Where add conditions 2// tx.Statement.BuildCondition(query, args...) 先不用关注，我们只需要知道他是构建了一些子条件，这个不是当前分析的重点 3func (db *DB) Where(query interface{}, args ...interface{}) (tx *DB) { 4// 获取 DB 实例 5\ttx = db.getInstance() 6if conds := tx.Statement.BuildCondition(query, args...); len(conds) \u0026gt; 0 { 7// 将 Clause 添加到 Statement 中 8\ttx.Statement.AddClause(clause.Where{Exprs: conds}) 9} 10return 11} 我们可以看到，Where 方法会生成一个 clause.Where 的对象追加到 Statement 对象中\n1// AddClause add clause 2func (stmt *Statement) AddClause(v clause.Interface) { 3// StatementModifier 扩展功能，先不用关注 4\tif optimizer, ok := v.(StatementModifier); ok { 5optimizer.ModifyStatement(stmt) 6} else { 7// Cluase 的名字，clause.Where 的名字就是 \u0026#34;WHERE\u0026#34; 8\tname := v.Name() 9// 因为是用 map 存放的，所以同一个名字的 Clause 只能有一个，这也是为什么 clause.Interface 需要定一个 MergeClause 的方法 10 // 不判断存在性，如果没有，那也能获取到对应的零值 11\tc := stmt.Clauses[name] 12c.Name = name 13v.MergeClause(\u0026amp;c) 14// merge 之后再存放回去 15\tstmt.Clauses[name] = c 16} 17} 那我们再看下clause.Where 的实现，这个其实没有什么好讲的，where条件本身被调用的频率极高，又可以有很多复杂的条件，所以构造 sql 的 Build 方法实现起来会比较复杂，如果有兴趣可以研究一下，其他的Clause就会简单许多\n1// clause/where.go 2// Where where clause 3type Where struct { 4Exprs []Expression 5} 67// Name where clause name 8func (where Where) Name() string { 9return \u0026#34;WHERE\u0026#34; 10} 1112// Build build where clause 13func (where Where) Build(builder Builder) { 14// Switch position if the first query expression is a single Or condition 15\tfor idx, expr := range where.Exprs { 16if v, ok := expr.(OrConditions); !ok || len(v.Exprs) \u0026gt; 1 { 17if idx != 0 { 18where.Exprs[0], where.Exprs[idx] = where.Exprs[idx], where.Exprs[0] 19} 20break 21} 22} 2324buildExprs(where.Exprs, builder, \u0026#34; AND \u0026#34;) 25} 2627// MergeClause merge where clauses 28func (where Where) MergeClause(clause *Clause) { 29if w, ok := clause.Expression.(Where); ok { 30exprs := make([]Expression, len(w.Exprs)+len(where.Exprs)) 31copy(exprs, w.Exprs) 32copy(exprs[len(w.Exprs):], where.Exprs) 33where.Exprs = exprs 34} 3536clause.Expression = where 37} 顺便拿 Limit 的 Clause 实现对比一下\n1package clause 23import \u0026#34;strconv\u0026#34; 45// Limit limit clause 6type Limit struct { 7Limit int 8Offset int 9} 1011// Name where clause name 12func (limit Limit) Name() string { 13return \u0026#34;LIMIT\u0026#34; 14} 1516// Build build where clause 17func (limit Limit) Build(builder Builder) { 18if limit.Limit \u0026gt; 0 { 19builder.WriteString(\u0026#34;LIMIT \u0026#34;) 20builder.WriteString(strconv.Itoa(limit.Limit)) 21} 22if limit.Offset \u0026gt; 0 { 23if limit.Limit \u0026gt; 0 { 24builder.WriteString(\u0026#34; \u0026#34;) 25} 26builder.WriteString(\u0026#34;OFFSET \u0026#34;) 27builder.WriteString(strconv.Itoa(limit.Offset)) 28} 29} 3031// MergeClause merge order by clauses 32func (limit Limit) MergeClause(clause *Clause) { 33clause.Name = \u0026#34;\u0026#34; 3435if v, ok := clause.Expression.(Limit); ok { 36if limit.Limit == 0 \u0026amp;\u0026amp; v.Limit != 0 { 37limit.Limit = v.Limit 38} 3940if limit.Offset == 0 \u0026amp;\u0026amp; v.Offset \u0026gt; 0 { 41limit.Offset = v.Offset 42} else if limit.Offset \u0026lt; 0 { 43limit.Offset = 0 44} 45} 4647clause.Expression = limit 48} First 代码分析 1// First find first record that match given conditions, order by primary key 2func (db *DB) First(dest interface{}, conds ...interface{}) (tx *DB) { 3// First 的语义是获取符合条件的第一条纪录，所以 gorm 会默认添加 `Limit` 的 `Clause`，排序默认使用的主键增序 4\ttx = db.Limit(1).Order(clause.OrderByColumn{ 5Column: clause.Column{Table: clause.CurrentTable, Name: clause.PrimaryKey}, 6}) 7// First 同样支持调用的时候再构建条件，这段代码就是对这个功能的支持 8\tif len(conds) \u0026gt; 0 { 9if exprs := tx.Statement.BuildCondition(conds[0], conds[1:]...); len(exprs) \u0026gt; 0 { 10tx.Statement.AddClause(clause.Where{Exprs: exprs}) 11} 12} 13// 没有记录的时候生成错误 14\ttx.Statement.RaiseErrorOnNotFound = true 15// 保存结果的地址 16\ttx.Statement.Dest = dest 17// 执行 18\treturn tx.callbacks.Query().Execute(tx) 19} callbacks 的流程我们在基础篇已经提到了，这里我们着重分析下 query callbacks 的具体实现\n首先看下具体给 query 行为注册了哪些 callbacks，以sqlite为例，相关代码是在 Initialize 的时候调用 callbacks.RegisterDefaultCallbacks 实现的\n1... 2callbacks.RegisterDefaultCallbacks(db, \u0026amp;callbacks.Config{ 3CreateClauses: []string{\u0026#34;INSERT\u0026#34;, \u0026#34;VALUES\u0026#34;, \u0026#34;ON CONFLICT\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 4UpdateClauses: []string{\u0026#34;UPDATE\u0026#34;, \u0026#34;SET\u0026#34;, \u0026#34;WHERE\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 5DeleteClauses: []string{\u0026#34;DELETE\u0026#34;, \u0026#34;FROM\u0026#34;, \u0026#34;WHERE\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 6LastInsertIDReversed: true, 7}) 8... 1// callbacks/callbacks.go:50 2queryCallback := db.Callback().Query() 3queryCallback.Register(\u0026#34;gorm:query\u0026#34;, Query) 4queryCallback.Register(\u0026#34;gorm:preload\u0026#34;, Preload) 5queryCallback.Register(\u0026#34;gorm:after_query\u0026#34;, AfterQuery) 6queryCallback.Clauses = config.QueryClauses 这里我们重点看下 Query 回调\n1func Query(db *gorm.DB) { 2if db.Error == nil { 3BuildQuerySQL(db) 45if !db.DryRun \u0026amp;\u0026amp; db.Error == nil { 6rows, err := db.Statement.ConnPool.QueryContext(db.Statement.Context, db.Statement.SQL.String(), db.Statement.Vars...) 7if err != nil { 8db.AddError(err) 9return 10} 11gorm.Scan(rows, db, 0) 12db.AddError(rows.Close()) 13} 14} 15} 1617// BuildQuerySQL 就是构建我们的sql，这个方法可以说是超级复杂，我们直接略过前面各种条件的补足（就是不断的补充Clause） 18// 直接看调用什么方法构建的sql 19func BuildQuerySQL(db *gorm.DB) { 20if db.Statement.SQL.Len() == 0 { 21// 超级省略 22 ... 23db.Statement.Build(db.Statement.BuildClauses...) 24} 25} 现在压力来到了 db.Statement.Build 方法\n1// Build build sql with clauses names 2// 这里的 clauses 参数就是各个 dialector 初始化的时候调用 callbacks.RegisterDefaultCallbacks 传入的支持的 Clause 3// 毕竟不是所有的数据库都支持所有的标准sql语法 4// 同样的，不同 db 可能对同样的 Clause 有自己的语法解析，所以我们可以看到，源码中还支持给 DB 对象设置 ClauseBuilder，如果有的话，使用 5// 设置的 ClauseBuilder 来构建 sql 6func (stmt *Statement) Build(clauses ...string) { 7var firstClauseWritten bool 89for _, name := range clauses { 10if c, ok := stmt.Clauses[name]; ok { 11if firstClauseWritten { 12stmt.WriteByte(\u0026#39; \u0026#39;) 13} 1415firstClauseWritten = true 16if b, ok := stmt.DB.ClauseBuilders[name]; ok { 17b(c, stmt) 18} else { 19// 执行 Clause 的 Build 的方法构建 sql 片段，这里你可以再回头看下 Limit 的 Build 方法实现，相当简单 20\tc.Build(stmt) 21} 22} 23} 24} ","date":"2022-02-02","img":"","permalink":"https://wangtingkui.space/posts/go/gorm-clause/","series":null,"tags":["go"],"title":"Gorm源码阅读 - 2.Clause"},{"categories":[],"content":"gorm 是目前项目中使用较多的用来和数据库操作的类库，本系列文章的目的是对其源码进行研读和学习，达到知其然和知其所以然\n本篇文章主要是从宏观的角度看下使用 gorm 执行一条 sql 的整体流程，了解这个类库大概是怎么使用的，里面涉及的一些核心的对象是什么，方便我们日后针对某一组件进行剖析打好基础\n版本信息 1# go 版本 2go version go1.16.10 darwin/amd64 34# 类库版本 5gorm.io/driver/mysql v1.2.3 // indirect 6gorm.io/driver/sqlite v1.2.6 7gorm.io/gorm v1.22.5 一个最简单的使用demo 1package main 23import ( 4\u0026#34;gorm.io/driver/sqlite\u0026#34; 5\u0026#34;gorm.io/gorm\u0026#34; 6) 78// model 定义 9type Test struct { 10ID uint `gorm:\u0026#34;primarykey\u0026#34;` 11A int32 12B string 13} 1415func main() { 16// 连接数据库 17\tdb, err := gorm.Open(sqlite.Open(\u0026#34;test.db\u0026#34;), \u0026amp;gorm.Config{}) 18if err != nil { 19panic(\u0026#34;failed to connect database\u0026#34;) 20} 2122// 自动创建表结构 23\tif err = db.AutoMigrate(\u0026amp;Test{}); err != nil { 24panic(\u0026#34;auto migrate err\u0026#34;) 25} 2627// 查询 28\tvar v Test 29db.Debug().Model(\u0026amp;Test{}).Where(\u0026#34;b = ?\u0026#34;, \u0026#34;test\u0026#34;).First(\u0026amp;v) 30} 在这个demo中，我们首先使用gorm.Open获取一个*gorm.DB的实例，我们后续就是通过这里实例进行一系列操作的，gorm.Open方法需要传入两个参数，第一个是实现了Dialector接口的对象，这个就是对不同类型数据库的抽象，上面的代码使用的是sqlite的实现，当我们需要切换不同类型的数据库的时候，使用对应的驱动就可以实现轻松的替换；第二个参数是gorm.Config，是对gorm的一些配置项\n来简单的看下gorm.Open方法，注意源码中的注释\n1// Open initialize db session based on dialector 2func Open(dialector Dialector, opts ...Option) (db *DB, err error) { 3config := \u0026amp;Config{} 45// 可以到，Open方法的第二个参数实际上是Option类型的变参 6 // 但我们实际上传入的是gorm.Config类型，这里看起来虽然有点别扭，但也正是ducktype的体现 7 // 下面的这个排序是确保如果传入的选项中有gorm.Config类型，确保这些类型的排在前面，防止覆盖掉 8 // 其他的选项 9\tsort.Slice(opts, func(i, j int) bool { 10_, isConfig := opts[i].(*Config) 11_, isConfig2 := opts[j].(*Config) 12return isConfig \u0026amp;\u0026amp; !isConfig2 13}) 1415// 应用 Option 16\tfor _, opt := range opts { 17... 18} 1920// 如果 dialector 实现了 Apply 方法，也执行一下 21\tif d, ok := dialector.(interface{ Apply(*Config) error }); ok { 22if err = d.Apply(config); err != nil { 23return 24} 25} 2627// 一些普通的初始化操作 28 ... 2930// 实例化一个 *DB 类型变量，这个函数返回的也是它 31\tdb = \u0026amp;DB{Config: config, clone: 1} 3233// 初始化 callbacks，gorm 所有行为都是基于 callback 来实现的，后续单独拿一篇文章出来讲解 34\tdb.callbacks = initializeCallbacks(db) 3536if config.ClauseBuilders == nil { 37config.ClauseBuilders = map[string]clause.ClauseBuilder{} 38} 3940// 执行 dialector 的初始化 41\tif config.Dialector != nil { 42err = config.Dialector.Initialize(db) 43} 4445// 设置 preparedStmt 对象（执行一些预编译的sql） 46\tpreparedStmt := \u0026amp;PreparedStmtDB{ 47ConnPool: db.ConnPool, 48Stmts: map[string]Stmt{}, 49Mux: \u0026amp;sync.RWMutex{}, 50PreparedSQL: make([]string, 0, 100), 51} 52db.cacheStore.Store(preparedStmtDBKey, preparedStmt) 5354if config.PrepareStmt { 55db.ConnPool = preparedStmt 56} 5758// 设置 Statement 对象，用来通过我们指定的各种条件生成最终sql，交给db执行 59\tdb.Statement = \u0026amp;Statement{ 60DB: db, 61ConnPool: db.ConnPool, 62Context: context.Background(), 63Clauses: map[string]clause.Clause{}, 64} 6566if err == nil \u0026amp;\u0026amp; !config.DisableAutomaticPing { 67if pinger, ok := db.ConnPool.(interface{ Ping() error }); ok { 68err = pinger.Ping() 69} 70} 7172if err != nil { 73config.Logger.Error(context.Background(), \u0026#34;failed to initialize database, got error %v\u0026#34;, err) 74} 7576return 77} 上面的步骤中，值得在这个时间点去细看一下的就是 config.Dialector.Initialize(db) 这行，这句代码是执行我们传入的 dialector 的初始化方法。简单了解下对我们把我整理流程会有些好处\n我这里就用 sqlite 的 dialector 简单分析下，不同db的dialector实现可能会不同，但是所做的事大同小异\n1func (dialector Dialector) Initialize(db *gorm.DB) (err error) { 2// 初始化 DriverName 3\tif dialector.DriverName == \u0026#34;\u0026#34; { 4dialector.DriverName = DriverName 5} 67// 设置连接池 8\tif dialector.Conn != nil { 9db.ConnPool = dialector.Conn 10} else { 11conn, err := sql.Open(dialector.DriverName, dialector.DSN) 12if err != nil { 13return err 14} 15db.ConnPool = conn 16} 1718// 查看 sqlite 版本 19\tvar version string 20if err := db.ConnPool.QueryRowContext(context.Background(), \u0026#34;select sqlite_version()\u0026#34;).Scan(\u0026amp;version); err != nil { 21return err 22} 23// https://www.sqlite.org/releaselog/3_35_0.html 24 // 根据不同版本注册回调到 gorm.DB 实例 25\tif compareVersion(version, \u0026#34;3.35.0\u0026#34;) \u0026gt;= 0 { 26callbacks.RegisterDefaultCallbacks(db, \u0026amp;callbacks.Config{ 27CreateClauses: []string{\u0026#34;INSERT\u0026#34;, \u0026#34;VALUES\u0026#34;, \u0026#34;ON CONFLICT\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 28UpdateClauses: []string{\u0026#34;UPDATE\u0026#34;, \u0026#34;SET\u0026#34;, \u0026#34;WHERE\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 29DeleteClauses: []string{\u0026#34;DELETE\u0026#34;, \u0026#34;FROM\u0026#34;, \u0026#34;WHERE\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 30LastInsertIDReversed: true, 31}) 32} else { 33callbacks.RegisterDefaultCallbacks(db, \u0026amp;callbacks.Config{ 34LastInsertIDReversed: true, 35}) 36} 3738// 获取 dialector 的 ClauseBuilders 注册到 gorm.DB 实例 39\tfor k, v := range dialector.ClauseBuilders() { 40db.ClauseBuilders[k] = v 41} 42return 43} 一些概念的补充 看了上面Open流程的代码，我相信你一定和我一样对其中出现的一些名词有些迷惑，不知道它代表的什么含义，我这里说一些我自己的理解\n callbacks\n 在gorm.Open代码中，我们提到gorm是基于回调来编写的，这点gorm的文档中也有提到过\n那 callbacks 究竟是什么，我们还是回归源码看一下，在上面的代码中涉及 callbacks 一共有两处\n第一处是 gorm.Open 初始化过程中的 db.callbacks = initializeCallbacks(db)\n1db.callbacks = initializeCallbacks(db) 23// 初始化 callbacks 4func initializeCallbacks(db *DB) *callbacks { 5return \u0026amp;callbacks{ 6processors: map[string]*processor{ 7\u0026#34;create\u0026#34;: {db: db}, 8\u0026#34;query\u0026#34;: {db: db}, 9\u0026#34;update\u0026#34;: {db: db}, 10\u0026#34;delete\u0026#34;: {db: db}, 11\u0026#34;row\u0026#34;: {db: db}, 12\u0026#34;raw\u0026#34;: {db: db}, 13}, 14} 15} 1617// callbacks gorm callbacks manager 18// callbacks 中只有一个对象: processors，是一组 processor 的结合 19// 从 initalizeCallbacks 我们也能猜测到一个 processor 就是对应一个行为的处理逻辑，初始化的过程给 20// create/query/update/delete/row/raw 这几个行为进行了初始化 21type callbacks struct { 22processors map[string]*processor 23} 2425// 一个行为对应的处理，可以看到一个行为是可以对应多个处理方法（callback）的 26type processor struct { 27db *DB 28Clauses []string 29fns []func(*DB) 30callbacks []*callback 31} 3233// 一个处理方法 34type callback struct { 35name string 36before string 37after string 38remove bool 39replace bool 40match func(*DB) bool 41handler func(*DB) 42processor *processor 43} 第二处是在sqlite dialector 的初始化过程中调用了callbacks.RegisterDefaultCallbacks方法\n1// sqlite.go:57 2callbacks.RegisterDefaultCallbacks(db, \u0026amp;callbacks.Config{ 3CreateClauses: []string{\u0026#34;INSERT\u0026#34;, \u0026#34;VALUES\u0026#34;, \u0026#34;ON CONFLICT\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 4UpdateClauses: []string{\u0026#34;UPDATE\u0026#34;, \u0026#34;SET\u0026#34;, \u0026#34;WHERE\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 5DeleteClauses: []string{\u0026#34;DELETE\u0026#34;, \u0026#34;FROM\u0026#34;, \u0026#34;WHERE\u0026#34;, \u0026#34;RETURNING\u0026#34;}, 6LastInsertIDReversed: true, 7}) 89// callbacks.go:22 10func RegisterDefaultCallbacks(db *gorm.DB, config *Config) { 11enableTransaction := func(db *gorm.DB) bool { 12return !db.SkipDefaultTransaction 13} 1415if len(config.CreateClauses) == 0 { 16config.CreateClauses = createClauses 17} 18if len(config.QueryClauses) == 0 { 19config.QueryClauses = queryClauses 20} 21if len(config.DeleteClauses) == 0 { 22config.DeleteClauses = deleteClauses 23} 24if len(config.UpdateClauses) == 0 { 25config.UpdateClauses = updateClauses 26} 2728// 获取到gorm.DB 中的 callbacks[\u0026#34;create\u0026#34;] 对象，也就是一个 processor 29\tcreateCallback := db.Callback().Create() 3031// 调用 processor.Match 方法生成一个 callback 32 // Match 接受一个`fc func(*DB) bool`的方法作为参数放到 callback 对象的 match 字段中 33 // 当事件发生的时候，只有这个函数返回 true 的时候，对应的 callback 才会执行 34 // Register 就是提供一个名字和回调函数，注册到 callback 中 35\tcreateCallback.Match(enableTransaction).Register(\u0026#34;gorm:begin_transaction\u0026#34;, BeginTransaction) 36createCallback.Register(\u0026#34;gorm:before_create\u0026#34;, BeforeCreate) 37createCallback.Register(\u0026#34;gorm:save_before_associations\u0026#34;, SaveBeforeAssociations(true)) 38createCallback.Register(\u0026#34;gorm:create\u0026#34;, Create(config)) 39createCallback.Register(\u0026#34;gorm:save_after_associations\u0026#34;, SaveAfterAssociations(true)) 40createCallback.Register(\u0026#34;gorm:after_create\u0026#34;, AfterCreate) 41createCallback.Match(enableTransaction).Register(\u0026#34;gorm:commit_or_rollback_transaction\u0026#34;, CommitOrRollbackTransaction) 42createCallback.Clauses = config.CreateClauses 4344// 以下就和上面的过程大同小异了，只不多针对的是不同的行为 45 ... 46} 从上面的分析中我们可以得出，callbacks就是定义的一系列的处理流程，当某个行为发生之后，就会调用这个行为对应的 callbacks进行处理，这个当我们下面分析到一个简单的sql是如何执行的时候会有更深刻的理解\n一条sql是怎么被组装和执行的 我们在从一条sql被拼凑而成然后执行的流程来看下上面分析的初始化过程生成的“乱七八糟”的对象都是干啥的\n也就是分析下下面这条源码就近干了点什么\n1// 查询 2var v Test 3db.Debug().Model(\u0026amp;Test{}).Where(\u0026#34;b = ?\u0026#34;, \u0026#34;test\u0026#34;).First(\u0026amp;v) 在分析上面的代码之前，有一点小知识需要了解下，在使用gorm的过程中，我们几乎所有的交互都是通过gorm.DB这个 struct 来完成的，我们可以把他理解成一个“和数据库的会话”，这个会话有各种各样的属性，用来控制和数据库交互过程中的行为，我们也可以基于某个会话生成新的会话，在生成新会话的过程中指定数据，从而得到满足我们需求的会话\n有了这个知识点，我们继续进行分析，Debug()这个方法，就是基于当前的会话生成新的会话，设置了会话的Logger属性，从而能输出最终执行的sql，效果如下\n1// Debug start debug mode 2func (db *DB) Debug() (tx *DB) { 3return db.Session(\u0026amp;Session{ 4Logger: db.Logger.LogMode(logger.Info), 5}) 6} Model方法指定了 Statement 中 Model 的值，明确了我们要操作的是哪个数据表\n1func (db *DB) Model(value interface{}) (tx *DB) { 2tx = db.getInstance() 3tx.Statement.Model = value 4return 5} Where 和 First 方法是我们关注的重点，我们的sql就是通过这两个入口构造并执行的，这里还要补充一个知识点，gorm提供的是流式的api，这些api分几类，可以参考文档 ，其中最主要的是链式方法和Finisher方法。链式方法是将Clauses修改或添加到当前的Statement的方法，比如Where；Finisher方法是会立即执行注册回调的方法（没错，这个回调指的就是我们上面分析到的回调:-)），比如First\n先来看下Where：\n1// Where add conditions 2// 根据传入的参数生成表达式，然后作为一个子句(Clause)添加到 Statement 中 3// 关于 Clause 和 Statement 更细化的分析，有空单写一篇文章 4func (db *DB) Where(query interface{}, args ...interface{}) (tx *DB) { 5tx = db.getInstance() 6if conds := tx.Statement.BuildCondition(query, args...); len(conds) \u0026gt; 0 { 7tx.Statement.AddClause(clause.Where{Exprs: conds}) 8} 9return 10} 再看下First：\n1// First find first record that match given conditions, order by primary key 2func (db *DB) First(dest interface{}, conds ...interface{}) (tx *DB) { 3// first的语义是查找满足条件的第一条纪录 4 // 所以这里默认添加了 limit 和 order 子句（Clause） 5\ttx = db.Limit(1).Order(clause.OrderByColumn{ 6Column: clause.Column{Table: clause.CurrentTable, Name: clause.PrimaryKey}, 7}) 8// conds 就是传一些其他的条件来进行过滤，同样也是个构造子句的过程 9\tif len(conds) \u0026gt; 0 { 10if exprs := tx.Statement.BuildCondition(conds[0], conds[1:]...); len(exprs) \u0026gt; 0 { 11tx.Statement.AddClause(clause.Where{Exprs: exprs}) 12} 13} 14// 没有记录的时候生成error 15\ttx.Statement.RaiseErrorOnNotFound = true 16// 指定纪录存放的变量 17\ttx.Statement.Dest = dest 18// 触发 query 行为，指定 query 对应的回调 19\treturn tx.callbacks.Query().Execute(tx) 20} 看了这么多，终于绕回来了，我们的查询行为最终回到了我们注册的回调上面，这也是为啥官网都说 gorm 是基于回调的原因\n我们直接来看这个处理过程：\n1func (p *processor) Execute(db *DB) *DB { 2// call scopes 3 // scope 先忽略，不是主流程 4\tfor len(db.Statement.scopes) \u0026gt; 0 { 5scopes := db.Statement.scopes 6db.Statement.scopes = nil 7for _, scope := range scopes { 8db = scope(db) 9} 10} 1112var ( 13curTime = time.Now() 14stmt = db.Statement 15resetBuildClauses bool 16) 1718if len(stmt.BuildClauses) == 0 { 19stmt.BuildClauses = p.Clauses 20resetBuildClauses = true 21} 2223// assign model values 24 // 兼容处理下，如果没有手动调用过`Model`方法，就用传进来的对象类型作为要操作的表 25\tif stmt.Model == nil { 26stmt.Model = stmt.Dest 27} else if stmt.Dest == nil { 28stmt.Dest = stmt.Model 29} 3031// parse model values 32 // 根据stmt.Model 解析库表 33\tif stmt.Model != nil { 34if err := stmt.Parse(stmt.Model); err != nil \u0026amp;\u0026amp; (!errors.Is(err, schema.ErrUnsupportedDataType) || (stmt.Table == \u0026#34;\u0026#34; \u0026amp;\u0026amp; stmt.TableExpr == nil \u0026amp;\u0026amp; stmt.SQL.Len() == 0)) { 35if errors.Is(err, schema.ErrUnsupportedDataType) \u0026amp;\u0026amp; stmt.Table == \u0026#34;\u0026#34; \u0026amp;\u0026amp; stmt.TableExpr == nil { 36db.AddError(fmt.Errorf(\u0026#34;%w: Table not set, please set it like: db.Model(\u0026amp;user) or db.Table(\\\u0026#34;users\\\u0026#34;)\u0026#34;, err)) 37} else { 38db.AddError(err) 39} 40} 41} 4243// assign stmt.ReflectValue 44 // 解析\u0026amp;校验结果存放地址 45\tif stmt.Dest != nil { 46stmt.ReflectValue = reflect.ValueOf(stmt.Dest) 47for stmt.ReflectValue.Kind() == reflect.Ptr { 48if stmt.ReflectValue.IsNil() \u0026amp;\u0026amp; stmt.ReflectValue.CanAddr() { 49stmt.ReflectValue.Set(reflect.New(stmt.ReflectValue.Type().Elem())) 50} 5152stmt.ReflectValue = stmt.ReflectValue.Elem() 53} 54if !stmt.ReflectValue.IsValid() { 55db.AddError(ErrInvalidValue) 56} 57} 5859// fns 就是经过处理和排序的 processor 下的 callbacks，可以额参考 processor.compile 方法 60 // 在每次注册callback后都会调用 61 // 很明显，构造query sql并执行等一系列流程都是在这些 callback中搞的 62\tfor _, f := range p.fns { 63f(db) 64} 6566// 打一些追踪日志 67\tif stmt.SQL.Len() \u0026gt; 0 { 68db.Logger.Trace(stmt.Context, curTime, func() (string, int64) { 69return db.Dialector.Explain(stmt.SQL.String(), stmt.Vars...), db.RowsAffected 70}, db.Error) 71} 7273if !stmt.DB.DryRun { 74stmt.SQL.Reset() 75stmt.Vars = nil 76} 7778if resetBuildClauses { 79stmt.BuildClauses = nil 80} 8182return db 83} 通过上面的分析，我们知道想要进一步了解，就要看query这个行为注册了哪些callback，可以再返回注册的时候的代码看看，是在callbacks包中\n1// callbacks.go:22 2func RegisterDefaultCallbacks(db *gorm.DB, config *Config) { 3... 4// callbacks包为query行为注册了3个callback 5 queryCallback := db.Callback().Query() 6queryCallback.Register(\u0026#34;gorm:query\u0026#34;, Query) 7queryCallback.Register(\u0026#34;gorm:preload\u0026#34;, Preload) 8queryCallback.Register(\u0026#34;gorm:after_query\u0026#34;, AfterQuery) 9queryCallback.Clauses = config.QueryClauses 10... 11} 1213func Query(db *gorm.DB) { 14if db.Error == nil { 15// 构造sql 16\tBuildQuerySQL(db) 1718if !db.DryRun \u0026amp;\u0026amp; db.Error == nil { 19// 执行sql，这里就交给真正的db去执行了 20\trows, err := db.Statement.ConnPool.QueryContext(db.Statement.Context, db.Statement.SQL.String(), db.Statement.Vars...) 21if err != nil { 22db.AddError(err) 23return 24} 25gorm.Scan(rows, db, 0) 26db.AddError(rows.Close()) 27} 28} 29} 总结 到这里，我们完整的分析了 gorm 的初始化和一次query sql 的执行流程，相信有了这个宏观的地图，在我们之后对 gorm 中某个组件进行分析的时候会更加的方便\n","date":"2022-02-01","img":"","permalink":"https://wangtingkui.space/posts/go/gorm-base/","series":null,"tags":["go"],"title":"Gorm源码阅读 - 1.基础流程"},{"categories":[],"content":"写在前面 我们知道，使用 go 构建一个 http 服务是一件非常简单的事情，比如使用下面区区几行代码，就可以运行起一个 http server\n1package main 23import ( 4\u0026#34;log\u0026#34; 5\u0026#34;net/http\u0026#34; 6) 78func main() { 9http.HandleFunc(\u0026#34;/\u0026#34;, func(resp http.ResponseWriter, req *http.Request) { 10_, err := resp.Write([]byte(\u0026#34;test http\u0026#34;)) 11if err != nil { 12log.Println(err) 13} 14}) 15if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil); err != nil { 16panic(err) 17} 18} 那 go 底层究竟是如何处理这一切呢，今天就来分析下 net/http 这个包的源码实现\n环境 1❯ go version 2go version go1.16.10 darwin/amd64 源码分析 那么就开始我们的源码分析，首先要说明，这里的分析不会面面俱到，会忽略一些细节，目的是为了让大家了解net/http包的核心流程和结构，有了这张“大的地图”，相信每个同学都能在此基础上完成源码阅读。\n我们知道，http 协议是一种请求/响应模式的协议，【客户端】发出一个【请求】，【服务】接受到【请求】，通过【路由】确定处理逻辑，处理完成后将【响应】返回给【客户端】\n从上面的描述我们可以很容易的抽象出在这个过程中涉及到的实体\n 服务 路由 请求 响应  如果我们之前看过相关的源码，会发现 go 中相关的实现也是按照这些实体来实现的\n服务 我们启动服务是通过 http.ListenAndServe(\u0026quot;:8080\u0026quot;, nil) 这行代码来实现的，那我们追进去看他做了哪些事情\n1func ListenAndServe(addr string, handler Handler) error { 2server := \u0026amp;Server{Addr: addr, Handler: handler} 3return server.ListenAndServe() 4} 可以看到，这个方法就是使用指定的端口生成了我们所谓的【服务】，其中第二个参数 handler 就是提到的【路由】，这个我们稍后再说，我们先关注【服务】的整体流程，看下server.ListenAndServe方法\n1func (srv *Server) ListenAndServe() error { 2... 3ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) 4if err != nil { 5return err 6} 7return srv.Serve(ln) 8} 这个方法也非常简单，就是使用我们指定的地址创建了一个 listener（监听socket），然后将这个 listener 传递给 Server（也就是我们上面说的【服务】实体） 的 Serve 方法，正式开启服务\nServe 方法中，就开始不断的循环，不断的接受新的连接，每个连接创建单独的 goroutine 进行处理，注意代码中的注释\n1func (srv *Server) Serve(l net.Listener) error { 2... 34// 对原始的net.Listener 进行简单的封装，只能执行一次Close 5\torigListener := l 6l = \u0026amp;onceCloseListener{Listener: l} 7defer l.Close() 89... 1011// 构建基础Context 12\tbaseCtx := context.Background() 13if srv.BaseContext != nil { 14baseCtx = srv.BaseContext(origListener) 15if baseCtx == nil { 16panic(\u0026#34;BaseContext returned a nil context\u0026#34;) 17} 18} 1920var tempDelay time.Duration // how long to sleep on accept failure 21 22// 基于基础的Context构建Context，这里把整个服务用 ServerContextKey 注入到了Context中 23\tctx := context.WithValue(baseCtx, ServerContextKey, srv) 24for { 25// 接受连接 26\trw, err := l.Accept() 27if err != nil { 28select { 29case \u0026lt;-srv.getDoneChan(): 30return ErrServerClosed 31default: 32} 33if ne, ok := err.(net.Error); ok \u0026amp;\u0026amp; ne.Temporary() { 34... 35// 网络错误处理 36\t} 37return err 38} 39// 拷贝本连接要使用的Context 40\tconnCtx := ctx 41// 如果有自定义的连接Content方法，执行下对应的钩子 42\tif cc := srv.ConnContext; cc != nil { 43connCtx = cc(connCtx, rw) 44if connCtx == nil { 45panic(\u0026#34;ConnContext returned nil\u0026#34;) 46} 47} 48tempDelay = 0 49// 对原始的net.Conn 进行包装，返回server.conn进行后续处理 50\tc := srv.newConn(rw) 51c.setState(c.rwc, StateNew, runHooks) // before Serve can return 52 // 启动 goroutine 开始连接的处理流程 53\tgo c.serve(connCtx) 54} 55} 请求处理 可以看到，在Serve方法最后，每个连接会启动一个goroutine进行单独处理，每个请求的处理流程就是在 server.conn 的 server 方法中\n1func (c *conn) serve(ctx context.Context) { 23// Context 注入客户端地址 4\tc.remoteAddr = c.rwc.RemoteAddr().String() 5ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) 67... 89// https 的处理，省略 10\tif tlsConn, ok := c.rwc.(*tls.Conn); ok { 11... 12} 1314// HTTP/1.x from here on. 15 16ctx, cancelCtx := context.WithCancel(ctx) 17c.cancelCtx = cancelCtx 18defer cancelCtx() 1920c.r = \u0026amp;connReader{conn: c} 21c.bufr = newBufioReader(c.r) 22c.bufw = newBufioWriterSize(checkConnErrorWriter{c}, 4\u0026lt;\u0026lt;10) 2324// 循环处理链接 25\tfor { 26// 生成服务端的 respose，这里面主要就是解析了传来的http文本协议，生成响应的 request 对象 27\t// 但这里有点奇怪的是把 request 对象放到了 response 对象里 28\tw, err := c.readRequest(ctx) 2930// 这里省去不少代码，主要是些错误处理还有长连接的处理 31\t... 3233// HTTP cannot have multiple simultaneous active requests.[*] 34\t// Until the server replies to this request, it can\u0026#39;t read another, 35\t// so we might as well run the handler in this goroutine. 36\t// [*] Not strictly true: HTTP pipelining. We could let them all process 37\t// in parallel even if their responses need to be serialized. 38\t// But we\u0026#39;re not going to implement HTTP pipelining because it 39\t// was never deployed in the wild and the answer is HTTP/2. 40\tserverHandler{c.server}.ServeHTTP(w, w.req) // 这里就是找到我们自定义的处理逻辑，然后执行 41\tw.cancelCtx() 42... 43} 44} 逻辑处理 看下serverHandler{c.server}.ServeHTTP(w, w.req) 这段代码是如何根据请求找到我们的自定义逻辑执行的\n首先将 c.server 强制类型转换为 serverHandler 类型，然后调用了 ServeHTTP 方法\n1// serverHandler delegates to either the server\u0026#39;s Handler or 2// DefaultServeMux and also handles \u0026#34;OPTIONS *\u0026#34; requests. 3type serverHandler struct { 4srv *Server 5} 67func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { 8// 首先获取 server 的 Handler（也就是我们的路由器），也就是我们最开始调用的http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)的第二个参数 9\t// 这里我们调用的时候没有传，就会使用默认的 DefaultServeMux（是 ServeMux 类型的一个实例） 10\thandler := sh.srv.Handler 11if handler == nil { 12handler = DefaultServeMux 13} 14if req.RequestURI == \u0026#34;*\u0026#34; \u0026amp;\u0026amp; req.Method == \u0026#34;OPTIONS\u0026#34; { 15handler = globalOptionsHandler{} 16} 17handler.ServeHTTP(rw, req) 18} 可以看到，代码最终调用的是路由器的ServeHTTP方法\n1// DefaultServeMux 就是该类型的一个实例 2type ServeMux struct { 3mu sync.RWMutex 4m map[string]muxEntry 5es []muxEntry // slice of entries sorted from longest to shortest. 6\thosts bool // whether any patterns contain hostnames 7} 89type muxEntry struct { 10h Handler 11pattern string 12} 1314// ServeHTTP dispatches the request to the handler whose 15// pattern most closely matches the request URL. 16func (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { 17if r.RequestURI == \u0026#34;*\u0026#34; { 18if r.ProtoAtLeast(1, 1) { 19w.Header().Set(\u0026#34;Connection\u0026#34;, \u0026#34;close\u0026#34;) 20} 21w.WriteHeader(StatusBadRequest) 22return 23} 24// 找对应的处理器，也就是我们调用 http.HandleFunc 注册的方法 25\th, _ := mux.Handler(r) 26h.ServeHTTP(w, r) 27} 2829func (mux *ServeMux) Handler(r *Request) (h Handler, pattern string) { 3031// CONNECT requests are not canonicalized. 32\tif r.Method == \u0026#34;CONNECT\u0026#34; { 33... 34} 3536// All other requests have any port stripped and path cleaned 37\t// before passing to mux.handler. 38\thost := stripHostPort(r.Host) 39path := cleanPath(r.URL.Path) 4041// If the given path is /tree and its handler is not registered, 42\t// redirect for /tree/. 43\tif u, ok := mux.redirectToPathSlash(host, path, r.URL); ok { 44return RedirectHandler(u.String(), StatusMovedPermanently), u.Path 45} 4647if path != r.URL.Path { 48_, pattern = mux.handler(host, path) 49url := *r.URL 50url.Path = path 51return RedirectHandler(url.String(), StatusMovedPermanently), pattern 52} 5354// 根据host和path找对应的处理方法 55\treturn mux.handler(host, r.URL.Path) 56} 5758// handler is the main implementation of Handler. 59// The path is known to be in canonical form, except for CONNECT methods. 60func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { 61mux.mu.RLock() 62defer mux.mu.RUnlock() 6364// Host-specific pattern takes precedence over generic ones 65\tif mux.hosts { 66h, pattern = mux.match(host + path) 67} 68if h == nil { 69h, pattern = mux.match(path) 70} 71if h == nil { 72h, pattern = NotFoundHandler(), \u0026#34;\u0026#34; 73} 74return 75} 7677// Find a handler on a handler map given a path string. 78// Most-specific (longest) pattern wins. 79func (mux *ServeMux) match(path string) (h Handler, pattern string) { 80// Check for exact match first. 81\tv, ok := mux.m[path] 82if ok { 83return v.h, v.pattern 84} 8586// Check for longest valid match. mux.es contains all patterns 87\t// that end in / sorted from longest to shortest. 88\tfor _, e := range mux.es { 89if strings.HasPrefix(path, e.pattern) { 90return e.h, e.pattern 91} 92} 93return nil, \u0026#34;\u0026#34; 94} ","date":"2022-01-16","img":"","permalink":"https://wangtingkui.space/posts/go/net-http/","series":null,"tags":[],"title":"源码阅读-Go(net/Http)"},{"categories":["go标准库使用和源码分析"],"content":"排序是日常开发工作中最常见的需求之一，本片文章我们来看下 Go 中如何对数据进行排序\nGo 的标准库中提供了 sort 包来辅助我们进行排序工作，只要我们的数据实现了 sort.Interface 接口，就可以调用 sort.Sort(data Interface) 进行排序操作了\n先来看下 sort.Interface 都定义了哪些方法：\n1type Interface interface { 2// Len is the number of elements in the collection. 3 // Len 为集合内元素的总数 4 Len() int 5// Less reports whether the element with 6 // index i should sort before the element with index j. 7 // 8 // Less 返回索引为 i 的元素是否应排在索引为 j 的元素之前。 9 Less(i, j int) bool 10// Swap swaps the elements with indexes i and j. 11 // Swap 交换索引为 i 和 j 的元素 12 Swap(i, j int) 13} 还是比较简单的，只需要实现获取长度,比较,交换三个动作的方法就可以了\n一个简单的例子 假设我们要对一个整型数组切片进行排序，那么我们要为 []int 实现 sort.Interface 接口\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sort\u0026#34; 6) 78type IntArr []int 910func (arr IntArr) Len() int { 11return len(arr) 12} 1314func (arr IntArr) Less(i, j int) bool { 15return arr[i] \u0026lt; arr[j] 16} 1718func (arr IntArr) Swap(i, j int) { 19arr[i], arr[j] = arr[j], arr[i] 20} 2122func main() { 23a := IntArr([]int{4, 3, 6, 5, 7, 8, 9}) 24sort.Sort(a) 25fmt.Println(a) 26} 可以看到，实现起来是相对比较简单的，其实对于这种常用简单数据类型，Go 的 sort 包早就为我们封装好了快捷方法，对于整型，直接调用 sort.Ints([]int) 方法就可以了，没有必要自己去实现，而且如果你去查看源码的话，会发现和我们上面实现的方法是一模一样的\n排序自定义结构 多数情况下，我们要实现的是自定义结构数据的排序，比如有Person结构，按照 Age 字段进行排序。这种场景下就需要我们自己去为我们的数据实现接口了\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sort\u0026#34; 6) 78type Person struct { 9Name string 10Age int 11} 1213type PersonList []Person 1415func (p PersonList) Len() int { 16return len(p) 17} 1819func (p PersonList) Less(i, j int) bool { 20return p[i].Age \u0026lt; p[j].Age 21} 2223func (p PersonList) Swap(i, j int) { 24p[i], p[j] = p[j], p[i] 25} 2627func main() { 28p := PersonList{ 29{Name: \u0026#34;A\u0026#34;, Age: 36}, 30{Name: \u0026#34;B\u0026#34;, Age: 45}, 31{Name: \u0026#34;C\u0026#34;, Age: 36}, 32{Name: \u0026#34;D\u0026#34;, Age: 12}, 33} 3435sort.Sort(p) 3637for _, person := range p { 38fmt.Println(person.Name, person.Age) 39} 40} 通过多个字段属性进行排序 通过结构体的多字段进行排序，也是常见的需求，官网为我们提供了比较好的例子 ，参考其中的SortMultiKeys，本质上就是提供了一层 wrapper\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sort\u0026#34; 6) 78type MyStruct struct { 9A, B, C int 10} 1112type CompareFunc func(a, b *MyStruct) bool 1314// 需要为 StructMultiSorter 实现 sort.Interface 接口 15type StructMultiSorter struct { 16structs []MyStruct 17compareFuncs []CompareFunc 18} 1920func (ms *StructMultiSorter) Less(i, j int) bool { 21// 原理就是依次调用 compareFunc 进行比较 22\tlenOfCompareFuncs := len(ms.compareFuncs) 23for k := 0; k \u0026lt; (lenOfCompareFuncs - 1); k++ { 24lessFunc := ms.compareFuncs[k] 25switch true { 26case lessFunc(\u0026amp;ms.structs[i], \u0026amp;ms.structs[j]): 27return true 28case lessFunc(\u0026amp;ms.structs[j], \u0026amp;ms.structs[i]): 29return false 30} 31// 如果相等，就会到下一个比较函数 32\t} 33// 如果前面的比较函数都相等，直接返回最后一个比较函数的结果 34\treturn ms.compareFuncs[lenOfCompareFuncs-1](\u0026amp;ms.structs[i], \u0026amp;ms.structs[j]) 35} 3637func (ms *StructMultiSorter) Swap(i, j int) { 38ms.structs[i], ms.structs[j] = ms.structs[j], ms.structs[i] 39} 4041func (ms *StructMultiSorter) Len() int { 42return len(ms.structs) 43} 4445func main() { 46f1 := func(a, b *MyStruct) bool { 47return a.A \u0026lt; b.A 48} 49f2 := func(a, b *MyStruct) bool { 50return a.B \u0026lt; b.B 51} 52f3 := func(a, b *MyStruct) bool { 53return a.C \u0026lt; b.C 54} 5556ms := \u0026amp;StructMultiSorter{ 57structs: []MyStruct{ 58{A: 3, B: 25, C: 28}, 59{A: 1, B: 24, C: 28}, 60{A: 2, B: 25, C: 2}, 61}, 62compareFuncs: []CompareFunc{f1, f2, f3}, 63} 6465sort.Sort(ms) 6667fmt.Println(ms.structs) 68} ","date":"2020-10-14","img":"","permalink":"https://wangtingkui.space/posts/go/sort/","series":null,"tags":["go"],"title":"Go 中 Sort 包的使用"},{"categories":["性能调优"],"content":"简介 火焰图 是用来分析 CPU 瓶颈的利器，它利用可交互 svg 图片可视化的展示了 CPU 的占用情况，可以帮助我们快速的定位优化方向。因为生成的图片非常像一团熊熊燃烧的火焰，所以起名为火焰图。\n使用火焰图的步骤 使用火焰图有两个步骤\n 使用trace工具收集采样数据 使用火焰图生成工具将收集的采样数据生成火焰图  火焰图的类型 根据要分析的问题不同，火焰图有不同的类型，一般由以下五种，其中最常用的是 CPU（也就是常说的ON-CPU） 类型\n CPU  Memory  Off-CPU  Hot/Cold  Differential   在 Linux 下使用火焰图进行 CPU 性能分析 收集采样信息 在 linux 下，一般使用操作系统自带的 perf 命令收集采样信息\n1# 查找指定程序的pid 2ps -ef | grep \u0026lt;target_program_name\u0026gt; 34# 生成cpu采样文件 5perf record -F 99 -p \u0026lt;target_program_pid\u0026gt; -g -o perf.data -- sleep 60 6# -F 指定的是采样频率，每秒99次 7# -p 指定要采样的程序pid 8# -g 纪录调用栈 9# sleep 60 持续60秒 生成火焰图 一般使用FlameGraph 来生成火焰图\n1# 下载火焰图生成工具 2git clone --depth 1 https://github.com/brendangregg/FlameGraph.git 34# 将采样数据生成 perf 文件 5perf script -i perf.data \u0026gt; perf.perf 67# 生成折叠文件 8./FlameGraph/stackcollapse-perf.pl perf.perf \u0026gt; perf.folded 910# 生成 svg 图片 11./FlameGraph/flamegraph.pl perf.folded \u0026gt; perf.svg 如何进行性能分析 通过上面的步骤，我们已经获取到了类似下面图片中的火焰图，那么如何才能从图中分析出存在的性能问题呢？\n阮大的一篇文章 已经有了很好的说明\n参考  官方文档  如何读懂火焰图  使用火焰图来分析程序性能   ","date":"2020-07-20","img":"","permalink":"https://wangtingkui.space/posts/performance/flame/","series":null,"tags":["火焰图"],"title":"使用火焰图分析性能瓶颈"},{"categories":["工具"],"content":"现如今，各种开发工具百花齐放，每个开发者都会有自己最中意的一款编辑器，但是各种编辑器的配置方式不同，当我们切换编辑器的时候，又需要针对新的编辑器进行配置，以保证代码格式的相同。那么有没有什么方式可以让我们在不同的编辑器之间随意切换而不用考虑配置带来的成本呢？那就是 EditorConfig\n官方网站 https://editorconfig.org/ 原理 EditorConfig 的运作原理是设计了一套标准的配置文件，然后在各种编辑器中开发对应的插件，插件解析配置文件，从而保证不同编辑器的配置相同\n现在几乎大部分编辑器都内置了 EditorConfig 的支持，不需要额外的安装插件\n配置文件 EditorConfig 的配置文件是一个 ini 格式的文件，名字为 .editorconfig，项目中每个文件夹下都可以有自己的 .editorconfig 文件，就近原则生效\n配置文件格式 一个简单的配置文件demo:\n1# EditorConfig is awesome: https://EditorConfig.org 23# top-most EditorConfig file 4root = true 56# Unix-style newlines with a newline ending every file 7[*] 8end_of_line = lf 9insert_final_newline = true 1011# Matches multiple files with brace expansion notation 12# Set default charset 13[*.{js,py}] 14charset = utf-8 1516# 4 space indentation 17[*.py] 18indent_style = space 19indent_size = 4 2021# Tab indentation (no size specified) 22[Makefile] 23indent_style = tab 2425# Indentation override for all JS under lib directory 26[lib/**.js] 27indent_style = space 28indent_size = 2 2930# Matches the exact files either package.json or .travis.yml 31[{package.json,.travis.yml}] 32indent_style = space 33indent_size = 2 可以看到，配置文件的格式还是比较简单的，整体使用的是 ini 配置文件的语法\n基本上可以分为两个部分：\n 控制指令生效的配置节部分：这个部分使用中括号括起来，里面的值支持 glob 语法来匹配文件   配置指令：支持的指令可以参考官方文档   ","date":"2020-07-20","img":"","permalink":"https://wangtingkui.space/posts/tool/editorconfig/","series":null,"tags":["EditorConfig"],"title":"Editorconfig"},{"categories":["php基础"],"content":"介绍 在书写单测代码的过程中，我们要测试的代码段往往会依赖其他的模块，如果是简单的模块还好，但是如果遇到复杂的模块（比如依赖各种其他的组件，db、redis、api调用等等），被依赖模块的稳定程度会影响我们的单测。而且被依赖模块返回的不确定性也使得我们无法编写单测代码\n为了解决这类型问题，我们可以使用测试替身 ，本质其实就是对数据进行mock\n在 phpunit 中，使用测试替身有两种方式，一种是Stubs（桩件），另外一种是Mock Object（仿件对象）。这两个概念有啥区别呢？其实是测试重点不同：\n 桩件注重的是可以对我们被依赖的模块进行返回值的设置，让单测可以按照我们期望的路径运行，往往还需要在我们的单测代码中书写各种断言 仿件对象注重的是被依赖模块的调用过程，比如被依赖对象中的A方法一定会被调用一次，使用仿件对象的单测，往往不需要在我们的单测代码中显示出现断言  使用 关于测试替身的详细使用，可以直接参考官方文档 ","date":"2020-07-19","img":"","permalink":"https://wangtingkui.space/posts/php/phpunit%E8%A7%A3%E5%86%B3%E6%B5%8B%E8%AF%95%E4%BE%9D%E8%B5%96/","series":null,"tags":["php"],"title":"Phpunit解决测试依赖"},{"categories":["php基础"],"content":"php 中匿名函数也叫做闭包函数，允许我们创建一个没有名称的函数，经常用作回调函数\nphp 中的匿名函数是基于 Closure 这个类来实现的\n基本使用 通常会将匿名函数用作回调函数\n1array_filter([1,2,3], function ($item) { 2return $item % 2 == 0; 3}); 45// 也可以赋值给变量，供后续使用 6$func = function () { 7echo \u0026#34;called\u0026#34; . PHP_EOL; 8} 910$func(); 使用父作用域变量 接触过其他有闭包特性语言的同学，一定会知道闭包的一大特点是可以使用父作用域的变量，php中的必报同样可以，但是使用上稍微有些区别\nphp 中使用父作用域的变量，需要使用 use 关键字传递\n1$a = 1; 2$func = function () use ($a) { 3echo $a; 4}; 5$func(); // 1 6$a = 2; 7$func(); // 1 可能有的同学会感到奇怪，为什么上面两次调用输出的都是1，这是因为在 php 中，传值方式默认使用的都是值传递，如果需要在匿名函数中保有对父作用域变量的引用，需要使用引用传值的方式\n1$a = 1; 2$func = function () use (\u0026amp;$a) { 3echo $a; 4}; 5$func(); // 1 6$a = 2; 7$func(); // 2 特别需要注意的是\n 闭包的父作用域指的是定义闭包时的作用域，而不是调用时的父作用域 use 中传递的参数，不能是 $this 和 超全局变量  $this 的自动绑定 当闭包定义在类中的时候，可以在闭包函数内使用 $this 代表类的对象\n1\u0026lt;?php 23class A 4{ 5protected $a = 1; 67public function test() 8{ 9$func = function () { 10echo $this-\u0026gt;a; 11}; 12$func(); 13} 14} 1516(new A())-\u0026gt;test(); // 1 如果不想自动绑定 $this，可以将闭包声明为静态的\n1\u0026lt;?php 23class A 4{ 5protected $a = 1; 67public function test() 8{ 9$func = static function () { 10var_dump($this); // null 11 }; 12$func(); 13} 14} 1516(new A())-\u0026gt;test(); // 1 这样就获取不到 $this 了\n","date":"2020-06-24","img":"","permalink":"https://wangtingkui.space/posts/php/closure/","series":null,"tags":["php"],"title":"Php 中的匿名函数和 Closure"},{"categories":["go标准库使用和源码分析"],"content":"Go 的一大特点就是在语言级别实现了并发，一旦涉及并发，那么不可避免的就需要同步，来确保多个 goroutine 在访问共享资源的时候不会出现混乱的状况\nGo 中的 sync 包提供了常见的并发编程同步原语，我们接下来就看下各种同步的方式如何使用，以及不同的同步方式都适用于什么样的场景，从而能让我们在日常使用中可以有针对性的挑选\nsync.Mutex sync.Mutex 是使用最广泛的一种原语，它保证同一时刻，只有一个 goroutine 可以访问临界资源，也就是我们常说的互斥锁\n1m := \u0026amp;sync.Mutex{} 2m.Lock() 3// 临界区 4m.Unlock() sync.RWMutex sync.RWMutex 是一个读写锁，它有两种锁的方式，读锁和写锁，当一个 goroutine 成功获取读锁的时候，其他 goroutine 也可以成功获取读锁，但是无法获取写锁。如果一个 goroutine 成功获取了写锁的时候，其他 goroutine 读锁和写锁都无法获得\nsync.RWMutex是基于sync.Mutex实现的，具体原理在这里就不多说了，可以看下另外一篇文章\n1m := sync.RWMutex{} 23m.Lock() 4// 执行一些写操作 5m.Unlock() 67m.RLock() 8// 执行一些可以并发的读操作 9m.RUnlock() sync.RWMutex常用于读写场景都有，但是读场景远远多于写场景的情况\nsync.WaitGroup sync.WaitGroup 常常用来等待一组 goroutine 执行完成\n1wg := \u0026amp;sync.WaitGroup{} 2wg.Add(2) 3go func() { wg.Done() }() 4go func() { wg.Done() }() 5wg.Wait() sync.Map Go 中的 map 类型本身是非并发安全的，如果在并发场景下，必须加锁来保证数据安全，sync.Map是一个并发版本的map，可以直接在并发场景下使用\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sync\u0026#34; 6) 78func main() { 9m := sync.Map{} 1011// 添加元素 12\tm.Store(\u0026#34;key\u0026#34;, \u0026#34;value\u0026#34;) 1314// 获取元素 15\tif v, ok := m.Load(\u0026#34;key\u0026#34;); ok { 16fmt.Println(v.(string)) 17} else { 18fmt.Println(\u0026#34;key is not exists\u0026#34;) 19} 2021// 返回指定key，如果不存在，使用给定的值设置到map中 22\tif v, loaded := m.LoadOrStore(\u0026#34;k\u0026#34;, \u0026#34;value\u0026#34;); loaded { 23fmt.Println(\u0026#34;读取到\u0026#34;, v) 24} else { 25fmt.Println(\u0026#34;存入\u0026#34;, v) 26} 2728// 删除元素 29\tm.Delete(\u0026#34;k\u0026#34;) 3031// 遍历元素 32\tm.Range(func(k, v interface{}) bool { 33fmt.Println(v.(string)) 34// 如果返回 false，则停止迭代 35\treturn true 36}) 37} 当我们的场景是写入不频繁但是读取特别频繁，或者多个 goroutine 的map写入区间不同的时候，使用sync.Map比普通 map 配合 mutex 效果要好很多\nsync.Pool sync.Pool是一个并发安全的对象池，当我们想重用长期存在的共享对象或者想优化内存使用的收，可以尝试使用sync.Pool\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sync\u0026#34; 6) 78func main() { 9type V struct { 10v int 11} 1213pool := sync.Pool{} 1415pool.Put(V{1}) 16pool.Put(V{2}) 17pool.Put(V{3}) 1819fmt.Println(pool.Get().(V).v) 20fmt.Println(pool.Get().(V).v) 21fmt.Println(pool.Get().(V).v) 22} sync.Once sync.Once可以保证一个函数只被执行一次\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sync\u0026#34; 6\u0026#34;time\u0026#34; 7) 89func main() { 10once := \u0026amp;sync.Once{} 1112for i := 1; i \u0026lt; 3; i++ { 13j := i 14go func() { 15once.Do(func() { 16fmt.Println(j) 17}) 18}() 19} 2021time.Sleep(time.Second) 22} sync.Cond sync.Cond常常用来处理的场景是：当一个数据状态发生变化的时候，通知其他等待的 goroutine\n它的原理就是维护了一个等待队列，当变量满足条件的时候，通知队列中等待的 goroutine\n使用 sync.Cond 的时候有几个注意点：\n 需要确保想要唤醒的 goroutine 已经进入 wait 状态 在调用 wait 前需要加锁（主要是为了确保互斥的修改等待队列）  由于条件变量需要和锁配合使用，如果使用不严谨容易发生死锁，所以建议尽量少用\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;sync\u0026#34; 6\u0026#34;time\u0026#34; 7) 89func main() { 10cond := sync.NewCond(\u0026amp;sync.Mutex{}) 11for i := 1; i \u0026lt;= 10; i++ { 12go func(x int) { 13cond.L.Lock() 14cond.Wait() 15cond.L.Unlock() 16fmt.Println(x) 17}(i) 18} 1920// 保证所有 goroutine 都进入 wait 状态 21\ttime.Sleep(time.Second) 2223// 释放一个 24\tcond.Signal() 2526// 隔一秒在释放一个 27\ttime.Sleep(time.Second) 28cond.Signal() 2930// 全部释放 31\ttime.Sleep(time.Second) 32cond.Broadcast() 3334time.Sleep(time.Second) 35} ","date":"2020-06-19","img":"","permalink":"https://wangtingkui.space/posts/go/sync/","series":null,"tags":["go"],"title":"Go标准库（sync）- 使用"},{"categories":["go基础"],"content":"go 中的 Context 的主要作用是在多个 groutine 之间同步取消信号或者截止日期，用于减少对资源的消耗和长时间占用，避免资源浪费。也可以利用 Context 来进行值的传递，但是使用比较少\n使用 Context 本身是 context 包对外暴露的一个接口\n1type Context interface { 2Deadline() (deadline time.Time, ok bool) // 返回当前 Context 的截止日期 3 Done() \u0026lt;-chan struct{} // 返回一个 channel，这个channel会在 Context 截止日期到了或者被取消之后关闭，多次调用Done会返回同一个channel 4 Err() error // 表明 Done 的原因，如果是超时，为DeadlineExceeded错误。如果是被取消，则是Canceled错误 5 Value(key interface{}) interface{} // 返回Context中key对应的value 6} 当前 go 中为我们提供了多个方法来创建 Context：\n context.TODO 和 context.Background，这两个方法都是返回一个预先实例化好的空 context 对象，如果没有特殊需求，所有的 context 应该都基于 context.Background来创建 context.WithCancel，创建可取消的上下文 context.WithDeadline，创建有超时时间的上下文 context.WithTimeout，对 context.WithDeadline的封装，更容易使用 context.WithValue，创建有键值对的上下文  一个简单的使用 demo：\n1func main() { 2ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second) 3defer cancel() 45go handle(ctx, 500*time.Millisecond) 67select { 8case \u0026lt;-ctx.Done(): 9fmt.Println(\u0026#34;main\u0026#34;, ctx.Err()) 10} 11} 1213func handle(ctx context.Context, duration time.Duration) { 14select { 15case \u0026lt;-ctx.Done(): 16fmt.Println(\u0026#34;handle\u0026#34;, ctx.Err()) 1718case \u0026lt;-time.After(duration): 19fmt.Println(\u0026#34;process request with\u0026#34;, duration) 20} 21} 输出：\n1$ go run context.go 2process request with 500ms 3main context deadline exceeded 使用 context 同步信号，取消 goroutine执行的最佳实践 参考：学会使用context取消goroutine执行的方法 参考  大神是如何学习 Go 之并发编程与 Context  学会使用context取消goroutine执行的方法   ","date":"2020-06-07","img":"","permalink":"https://wangtingkui.space/posts/go/context/","series":null,"tags":["go"],"title":"Go中Context的使用"},{"categories":["go三方库使用和源码分析"],"content":"在 go 官方的标准库中，提供了 net/smtp 库可以让我们使用 smtp 协议来发送邮件，但是这个库使用起来不是很方便，而且官方也不再维护这个库，推荐我们使用功能更丰富的第三方库来处理邮件发送\njordan-wright/email 就是一个使用的比较多的用来处理邮件发送的类库，它底层还是基于net/smtp实现的，但是提供了方便的调用方式供使用者使用\n安装 go get github.com/jordan-wright/email\n使用demo 1e := email.NewEmail() 2e.From = \u0026#34;Jordan Wright \u0026lt;test@gmail.com\u0026gt;\u0026#34; 3e.To = []string{\u0026#34;test@example.com\u0026#34;} 4e.Bcc = []string{\u0026#34;test_bcc@example.com\u0026#34;} 5e.Cc = []string{\u0026#34;test_cc@example.com\u0026#34;} 6e.Subject = \u0026#34;Awesome Subject\u0026#34; 7e.Text = []byte(\u0026#34;Text Body is, of course, supported!\u0026#34;) 8e.HTML = []byte(\u0026#34;\u0026lt;h1\u0026gt;Fancy HTML is supported, too!\u0026lt;/h1\u0026gt;\u0026#34;) 9e.Send(\u0026#34;smtp.gmail.com:587\u0026#34;, smtp.PlainAuth(\u0026#34;\u0026#34;, \u0026#34;test@gmail.com\u0026#34;, \u0026#34;password123\u0026#34;, \u0026#34;smtp.gmail.com\u0026#34;)) 可以看到这个类库调用起来还是非常的语义化的\n更多的使用可以参考官方文档\n","date":"2020-06-07","img":"","permalink":"https://wangtingkui.space/posts/go/mail/","series":null,"tags":["go"],"title":"使用 Jordan-Wright/Email 处理邮件发送"},{"categories":["go基础"],"content":"channel 类型 go 中 channel 类型分为两类：\n 带缓冲区的channel，定义方式如：ch := make(chan int, 2) 不带缓冲区的channel，定义方式如：ch := make(chan int)  不带缓冲区的 channel，写入和读取都会阻塞，在使用的时候必须有对应的写入 goroutine 和读取 goroutine，否则会造成死锁；带缓冲区的 channel，在缓冲区没满的时候会先将数据发到缓冲区，然后立即返回，如果缓冲区满了，会阻塞 goroutine\n为了操作上的安全和可读性，我们还可以限制 channel 的读写属性，默认 channel 都是可读可写的，可以使用 \u0026lt;-chan 来限定只读 channel， 使用chan\u0026lt;-来限定只写 channel，需要注意的是，只读的channel是不能关闭的\n1func main() { 2ch := make(chan int, 10) 3go func(ch chan\u0026lt;- int) { 4for i := 0; i \u0026lt; 10; i++ { 5ch \u0026lt;- 1 // 这里如果使用 \u0026lt;- ch，编译是不通过的 6\t} 7close(ch) 8}(ch) 910for i := 0; i \u0026lt; 10; i++ { 11fmt.Println(\u0026lt;-ch) 12} 13} 最重要的一点：channel 必须初始化后才能使用\nchannel 操作 创建 1// 不带缓冲区的 channel 2ch := make(chan int) 34// 带10个缓冲区的 channel 5bufferedChannel := make(chan int, 10) 关闭操作 1close(ch) 注意，不能在已经关闭的 channel 上调用 close，会panic：panic: close of closed channel \n写操作 1ch := make(chan int, 10) 2ch \u0026lt;- 1 注意，如果已经 close 的 channel 不能再写入，如果执行写入操作会 panic：send on closed channel\n读操作 1value := \u0026lt;- ch 注意，被关闭的 channel 也能正常读取，但是读取到的永远是 channel 类型的零值，可以通过接受读取操作返回的第二个值确定读取的零值是不是因为 channel 关闭而读到的\n1func main() { 2ch := make(chan int, 1) 3ch \u0026lt;- 1 4val, ok := \u0026lt;-ch 5fmt.Println(val, ok) // 1 true 6close(ch) 7val, ok = \u0026lt;-ch 8fmt.Println(val, ok) // 0 false 9} range 操作 使用 range 关键字来操作 channel 其实也是读的一种，只不过处理起来更方便，也更易阅读\nrange 可以持续的从一个 channel 读取数据，如果 channel 被关闭，读取完数据之后会自动退出循环\n12func makeSomeData(ch chan int, size int) { 3for i := 0; i \u0026lt; size; i++ { 4ch \u0026lt;- i 5} 6close(ch) 7} 8func main() { 9ch := make(chan int, 10) 10go makeSomeData(ch, 100) 11for num := range ch { 12fmt.Println(num) 13} 14} select 操作 当 chan 缓冲区满的时候，再往里面写入的时候会阻塞，或者 chan 里面没有数据，想从里面读数据的时候，也会阻塞，如果我们不想让 goroutine 阻塞，可以使用 select\nselect的执行流程是这样的：\n 检测每个case代码块 如果任意一个case代码块追备好发送或者接受，执行对应内容 如果有一个以上的代码块准备好了发送或者接受数据，随机选取一个执行 如果所有的case代码块都没准备好，则阻塞等待 如果所有的case代码块都没准备好，但是有default代码块，则执行default代码块  1c := make(chan int, 10) 2for { 3select { 4case v := \u0026lt;-c: 5fmt.Println(v) 6default: 7fmt.Println(\u0026#34;暂无数据\u0026#34;) 8time.Sleep(time.Second) 9} 10} ","date":"2020-06-01","img":"","permalink":"https://wangtingkui.space/posts/go/channel/","series":null,"tags":["go"],"title":"Go中channel的使用"},{"categories":["工具"],"content":"在vmware funsion上安装完centos7后，不经过配置的话网络是无法使用的，下面看下如何给新安装的 centos7 虚拟机配置 NAT 模式的网络\n一、确定网络信息 vmnet8是安装 vmware funsion 之后自动生成的一张虚拟网卡，NAT 模式使用的就是这张网卡\n进入vmnet8网卡配置目录 1\u0026gt; cd /Library/Preferences/VMware Fusion/vmnet8 查看nat信息，记住nat网关信息，也就是ip和netmask字段 1\u0026gt; cat nat.conf nat.conf 文件内容：\n1... # 省略文件其他部分 2[host] 34# NAT gateway address 5ip = 172.16.5.2 6netmask = 255.255.255.0 7... # 省略文件其他部分 查看dhcp信息，记住range范围，这里指的就是可用ip范围 1\u0026gt; cat dhcpd.conf dhcpd.conf 文件信息：\n1... # 省略文件其他部分 2subnet 172.16.5.0 netmask 255.255.255.0 { 3range 172.16.5.128 172.16.5.254; 4option broadcast-address 172.16.5.255; 5option domain-name-servers 172.16.5.2; 6option domain-name localdomain; 7default-lease-time 1800; # default is 30 minutes 8max-lease-time 7200; # default is 2 hours 9option netbios-name-servers 172.16.5.2; 10option routers 172.16.5.2; 11} 12... # 省略文件其他部分 确定dns 在系统偏好设置中的网络查看当前主机的dns配置\n配置虚拟机网络设置 在设置中将网络模式设置为共享\n设置centos7网络 登录虚拟机，配置 centos7 的网卡\n1\u0026gt; vim /etc/sysconfig/network-scripts/ifcfg-ens33 上面部分ifcfg-ens33是网卡名称，不同的虚拟机有可能会变，这个注意下\n按照下面红框部分进行设置\n BOOTPROTO=static：设置为固定ip ONBOOT=yes: 设置开启网卡 IPADDR=172.16.5.200: 使用哪个静态ip GATEWAY=172.16.5.2: 刚才看的vmnet8的网关 NETMAST=255.255.255.0: vmnet8的掩码 DNS1=192.168.50.1: DNS  重启网卡 1\u0026gt; service network restart ","date":"2020-05-31","img":"","permalink":"https://wangtingkui.space/posts/tool/net-fix-on-centos-7/","series":null,"tags":["vmware"],"title":"VMware Funsion 安装 Centos7 后配置 NAT 网络"},{"categories":["工具"],"content":"plex 是一个跨平台的家庭影音中心，基本上使用nas的小伙伴都会使用它来搭建自己的影音中心，他可以根据影片名称和年份信息自动拉取其他元信息（封面、演员等），易用程度和美观程度都非常高\n本片文章主要写一下 plex 在群辉nas上的基本使用\n第一步 安装 Plex Media Server 套件\n第二步 根据步骤注册 plex 账号\n第三步 点击头像旁边的+号，添加资料库\n选择要添加的资料库类型，官网强烈建议不同的媒体类型分类存储，比如电影和电视剧最好分开，否则可能会造成元信息搜索不到或者不准确\n这里假设我们要创建电影类型的资料库\n选择文件夹的时候要注意，plex只能展示第一层文件夹，比如我们的电影存储路径在/a/b/c，plex只能展示/a/b，所以这里我们最好是直接手动输入电影路径\n点击添加就好了\n第四步 通常在完成上面的操作后还是扫描不到文件夹里面的电影，这是因为 plex 没有对电影所在文件夹的操作权限，所以需要我们手动添加一下\n打开file station选中我们电影存储的文件夹，右键选择属性，点击权限，新增，给plex账户添加读写权限即可\n","date":"2020-05-24","img":"","permalink":"https://wangtingkui.space/posts/tool/plex/","series":null,"tags":["nas"],"title":"群辉nas使用plex套件"},{"categories":["工具"],"content":"vscode 扩展推荐\n实用    扩展名 用途    推荐主题    主题名 备注     vscode-icons 可以替换vscode的默认图标   Atom One Dark Theme    Monokai Pro     ","date":"2020-05-23","img":"","permalink":"https://wangtingkui.space/posts/tool/extension/","series":null,"tags":["vscode"],"title":"Vscode推荐扩展"},{"categories":["工具"],"content":"如果有多台电脑，可以使用 alfred 提供的配置同步功能来进行配置同步，以保证在多台电脑间的无缝使用\nalfred 的同步功能本质上是将配置打包成一个文件，然后借助第三方云同步功能同步这个文件，所以首先我们需要有个可用的云同步的文件夹，alfred 官方推荐的是 dropbox，但是由于一些不可描述的原因在国内使用起来不是很方便，所以这里我推荐另外一个软件，坚果云 具体坚果云的配置非常简单，这里就不赘述了，下面说一下怎么开启 alfred 的同步功能\n配置  打开偏好设置 找到Advanced配置项 右下角一个 Syncing 的配置 点击 Set preferences folder.. 按钮，选择我们的云同步文件夹就好了  ","date":"2020-05-23","img":"","permalink":"https://wangtingkui.space/posts/tool/sync-setting/","series":null,"tags":["alfred"],"title":"Alfred配置同步"},{"categories":["go基础"],"content":"单测能够极大的提升rd的回归效率（也能极大的提升开发效率），go内置了完整的单测支持\n单测基本规则  单元测试文件必须以_test.go结尾 单元测试文件名前面的部分最好和要被测试的方法所在的文件名保持一致 单元测试函数名称必须要以TestXxxx的格式书写，函数必须要接受一个testing.T类型的指针，不能有返回值 单元测试函数名最好能和被测试的函数保持对应，比如要测试的方法是Add，那么单测函数的名字最好是TestAdd，如果被测试的方法在同一个包下的多个结构体中都有，那么单测函数的名字可以是Test结构体名字_方法名，比如TestMyStruct_Add  一个demo 包文件结构\n1❯ tree 2. 3├── main.go 4└── main_test.go 560 directories, 2 files main.go文件内容\n1package main 23func Add(x, y int) int { 4return x + y 5} 67func main() { 89} main_test.go内容\n1package main 23import ( 4\u0026#34;testing\u0026#34; 5) 67func TestAdd(t *testing.T) { 8if Add(1, 2) != 3 { 9t.Errorf(\u0026#34;test add func err\u0026#34;) 10} 11} 执行结果\n1❯ go test 2PASS 3ok test-go/unit-testing\t0.006s 使用testing.T标记单测成功和纪录运行时日志 可以看到，我们的单测方法都需要接受一个testing.T类型的指针，testing.T类型用于管理测试状态并支持格式化测试日志，测试日志会在执行测试的过程中不断积累，在这个单元测试方法结束的时候输出到标准输出\n测试函数结束的方式：\n 当测试函数返回的时候 调用FailNow、Fatal、Fatalf、SkipNow、Skip、Skipf中的任意一个，测试宣告结束  常用的报告方法：\n 纪录运行时的日志，不会对运行产生日和信息\n Log:输出信息 Logf:格式化输出信息\n 遇到断言错误，想要标识这个测试失败\n Fail:标记测试失败，但是测试还会继续，之后的代码会继续执行 FailNow:标记测试失败，测试终端，也就是之后的代码不会在执行了 Error:相当于Log + Fail Errorf:相当于Logf + Fail Fatal:相当于Log + FailNow Fatalf:相当于Logf + FailNow\n 遇到断言错误，希望跳过这个错误，不标记为失败\n SkipNow:跳过测试，测试中断 Skip:相当于Log + SkipNow Skipf:相当于Logf + SkipNow\n执行单测 执行单测的对象可以是以下三种：\n 包的导入路径go test \u0026lt;package_import_path\u0026gt; 如果当前在包的路径下，可以直接执行go test，会执行当前包下所有单测 可以测试单独文件go test path_of_a.go path_of_a_test.go  下面是常用的一些指令\n1# 执行当前包中的单测 2go test 34# 执行指定包的单测（注意使用的是包的导入路径） 5go test testproject 67# go test 默认只会输出最后包的测试结果，如果想要看中间的测试过程和输出，使用下面的命令 8go test -v 910# 测试指定文件 11go test -v a.go a_test.go 1213# 测试指定方法，使用test.run变量可以用正则过滤要执行 14go test -v -test.run TestFunc 使用TestMain进行额外的setup（设置）或teardown（拆卸） 很多情况下，我们的多个测试case会依赖同一段初始化逻辑，这时候我们要么在每个测试函数中重复书写初始化代码，要么会将初始化逻辑封装成一个函数，然后在测试函数中调用。\ngo 的 testing 包提供了 TestMain(* testing.M)函数，如果测试文件中包含该函数，那么生成的测试将调用 TestMain(m)，而不是直接运行测试。TestMain 运行在主 goroutine 中 , 可以在调用 m.Run 前后做任何设置和拆卸。注意，在 TestMain 函数的最后，应该使用 m.Run 的返回值作为参数调用 os.Exit\n下面是一个demo（测试main包中的Add函数）\n1package main 23import ( 4\u0026#34;flag\u0026#34; 5\u0026#34;os\u0026#34; 6\u0026#34;testing\u0026#34; 7) 89var result int 1011func TestMain(m *testing.M) { 12flag.Parse() 13result = 2 14os.Exit(m.Run()) 15} 1617func TestAdd(t *testing.T) { 18if Add(1, 1) != result { 19t.Fatal() 20} 21} 注意事项 禁用缓存 当功能代码和测试代码都没有改动的时候，go test会在下次执行的时候直接取用缓存中的结果，并在执行结果中标记cached字样，如下图：\n如果禁用缓存，需要在执行单测的时候添加-count=1的参数:go test . -count=1 -v\n注意init函数的影响 如果执行的单测是包级别的，那么go test会执行包内的init函数，可能会影响测试结果\n单测覆盖率 go 也提供了检测单测覆盖率的工具，可以帮助我们快速定位没有包含在单测范围内的代码，可以在执行单测时添加-coverprofile选项开启\n-coverprofile 的值是覆盖率相关数据导出的文件名称\n1go test -coverprofile=c.out 首先可以看到覆盖率已经随着命令行输出\n1╰─$ go test -coverprofile=c.out 2PASS 3coverage: 50.0% of statements 4ok timing/sub\t0.012s 然后通过go tool cover工具分析哪些代码不在单测涵盖的范围内，通过以下命令将刚才生成的覆盖率文件生成可视的html文件\ngo tool cover -html=c.out -o=info.html\n打开生成的html文件，可以看到工具已经为我们标记除了已经覆盖的（绿色）和未覆盖（红色）的代码了\n参考  http://blog.studygolang.com/2017/10/how-to-test-with-go/  https://books.studygolang.com/The-Golang-Standard-Library-by-Example/chapter09/09.0.html   ","date":"2020-05-17","img":"","permalink":"https://wangtingkui.space/posts/go/unit-testing/","series":null,"tags":["go"],"title":"在go中使用单元测试"},{"categories":["工具"],"content":"atom 是一个插件化的编辑器，使用合适的插件可以极大的提升我们的使用效率，下面推荐一些我自己常用的插件\nproject-manager（atom项目管理） 可以将文件保存为项目，方便管理。我一般会配合 alfred workflow 方便的打开自己想要的项目\nsync-settings（atom配置同步） 如果使用多台电脑，必不能少的插件，将atom配置同步到 github gist 来达到同步目的\npretty-json（json格式化） 开发中经常用的，可以对json字符串进行格式化\nide-yaml（yaml格式化和校验） yaml格式化和校验\npp-markdown（markdown预览） markdown预览\natom-beautify（代码格式化） 代码格式化\ncss-snippets（css代码提示） 支持css、scss、sass、less\n","date":"2020-05-16","img":"","permalink":"https://wangtingkui.space/posts/tool/pakage/","series":null,"tags":["atom"],"title":"推荐的atom插件"},{"categories":["工具"],"content":"和插件一样，zsh 为我们提供了丰富的主题和自定义主题的能力，主题也分为两大类，一类是内置主题，另一类是自定义的扩展主题\n内置主题 这个其实没啥好说的，在官网 浏览下，挑选自己喜欢的，然后再~/.zshrc中配置对应的主题名称就行\n以官网中下图这个主题为例，主题名字叫robbyrussell\n在配置文件中修改ZSH_THEME变量的值即可\n1# Set name of the theme to load --- if set to \u0026#34;random\u0026#34;, it will 2# load a random theme each time oh-my-zsh is loaded, in which case, 3# to know which specific one was loaded, run: echo $RANDOM_THEME 4# See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes 5ZSH_THEME=\u0026#34;robbyrussell\u0026#34; 自定义主题（也称为外部主题） 这种主题类似插件，需要下载到${ZSH_CUSTOM}/themes这个目录下，然后再去配置文件中配置即可\n下面以一个超推荐的外部主题powerlevel10k/powerlevel10k为例，超级强大和漂亮（已经超越了主题的范畴）\n step1\n 先下载主题：git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/themes/powerlevel10k\n step2\n 修改主题\n1# Set name of the theme to load --- if set to \u0026#34;random\u0026#34;, it will 2# load a random theme each time oh-my-zsh is loaded, in which case, 3# to know which specific one was loaded, run: echo $RANDOM_THEME 4# See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes 5ZSH_THEME=\u0026#34;powerlevel10k/powerlevel10k\u0026#34;  step3\n 重新启动终端\n step4\n 按照主题的安装向导进行配置（没错，主题带了安装向导。。。）\n配置完之后，就可以快乐的使用了，如果之后对设置不满意，可以重新运行设置向导p10k configure\n","date":"2020-05-12","img":"","permalink":"https://wangtingkui.space/posts/tool/theme/","series":null,"tags":[],"title":"使用zsh主题"},{"categories":["工具"],"content":"这篇文站整理下自己经常使用的 alfred workflow\nTerminalFinder 可以快速在终端和finder直接切换，比如在iterm中打开当前finder的目录\nalfred-jetbrains 快速打开 jetbrains 系列 IDE 的项目\nYoudaoTranslate 有道词典翻译\n","date":"2020-05-10","img":"","permalink":"https://wangtingkui.space/posts/tool/plugin-recommend/","series":null,"tags":["alfred"],"title":"Alfred Workflow 推荐"},{"categories":["工具"],"content":"oh-my-zsh为我们提供了丰富的插件可以极高的提升我们的使用效率。插件分为两类，一类是内建插件， 这种插件不需要我们单独下载，只需要在.zshrc配置文件中开启即可使用，另外一类是自定义插件，我们需要将这类插件下载到~/.oh-my-zsh/custom/plugins目录中，然后再配置使用\n我们使用插件的时候要按需启用，启用过多的插件会导致shell的启动很慢\n内建插件 内建插件的使用很简单，只需要在~/.zshrc中开启即可\n1# .zshrc 文件 23# Which plugins would you like to load? 4# Standard plugins can be found in ~/.oh-my-zsh/plugins/* 5# Custom plugins may be added to ~/.oh-my-zsh/custom/plugins/ 6# Example format: plugins=(rails git textmate ruby lighthouse) 7# Add wisely, as too many plugins slow down shell startup. 8plugins=(git ruby) 这里就列出一些自己常用的插件\n   插件名 描述 截图     git 显示git分支，改动状态等，还自带了很多git命令的缩写    urltools 提供urlencode 和 urldecode功能     自定义插件 自定义插件需要你手动将插件下载到~/.oh-my-zsh/custom/plugins中，然后再启用\n一些推荐的自定义插件\n   插件名 描述 地址 截图     zsh-autosuggestions 自动提示 https://github.com/zsh-users/zsh-autosuggestions     zsh-syntax-highlighting 命令行代码高亮 https://github.com/zsh-users/zsh-syntax-highlighting      ","date":"2020-05-10","img":"","permalink":"https://wangtingkui.space/posts/tool/plugin/","series":null,"tags":["zsh","oh-my-zsh"],"title":"使用zsh插件"},{"categories":["go三方库使用和源码分析"],"content":"viper 是一个 go 的配置解决方案，它支持多种多样的配置文件，也支持从配置系统读取配置，比如 etcd。它还可以监视配置文件的变动，实时的载入最新的配置。\n配置优先级 viper 可以从环境变量，配置文件等地方读取配置，甚至可以手动的在运行时设置值，那么 viper 读取配置的优先级是什么呢？根据官网，viper 读取的值得优先级如下\n 通过 Set 设置的值 从命令行选项读取的值 环境变量的值 配置文件的值 key/value store 默认值  快速上手 一个使用 viper 的基本示例如下，基本上完成一个应用也就使用这些功能\n1# myconfig.yaml2name:xiaok3age:284sex:male5book:6- php7- java8- c9other:other_value1package main 23import ( 4\u0026#34;fmt\u0026#34; 56\u0026#34;github.com/spf13/viper\u0026#34; 7) 89func main() { 1011viper.AddConfigPath(\u0026#34;.\u0026#34;) // viper 不会帮我们设置任何默认路径，我们需要至少添加一个寻找配置文件的路径 12\tviper.SetConfigName(\u0026#34;myconfig\u0026#34;) // 设置配置文件名称 13\tviper.SetConfigType(\u0026#34;yaml\u0026#34;) // 如果配置文件没有后缀的话，这个值必须设置 14 15err := viper.ReadInConfig() 16if err != nil { 17panic(fmt.Sprintf(\u0026#34;Read config file err: %v\u0026#34;, err)) 18} 1920// 读取 21\tname := viper.GetString(\u0026#34;name\u0026#34;) 22fmt.Println(name) 23age := viper.GetInt(\u0026#34;age\u0026#34;) 24fmt.Println(age) 25books := viper.GetStringSlice(\u0026#34;book\u0026#34;) 26fmt.Println(books) 2728viper.SetDefault(\u0026#34;test_default\u0026#34;, \u0026#34;default_value\u0026#34;) // 设置默认值 29\tdefaultv := viper.GetString(\u0026#34;test_default\u0026#34;) 30fmt.Println(defaultv) 3132viper.RegisterAlias(\u0026#34;alias_of_age\u0026#34;, \u0026#34;age\u0026#34;) // 设置配置key别名 33\tfmt.Println(viper.GetInt(\u0026#34;alias_of_age\u0026#34;)) 3435viper.Set(\u0026#34;name\u0026#34;, \u0026#34;wudixiaok\u0026#34;) // 运行时设置配置值 36\tfmt.Println(viper.GetString(\u0026#34;name\u0026#34;)) 3738// 如果值得类型比较复杂，可以先读取出来，然后再断言 39\tv := viper.Get(\u0026#34;other\u0026#34;) 40realvalue := v.(string) 41fmt.Println(realvalue) 4243} 1# 输出 2xiaok 328 4[php java c] 5default_value 628 7wudixiaok 8other_value 其他高级功能 viper 还支持各种其他的高级功能，如果想要了解，可以到官网 去看看\n","date":"2020-05-03","img":"","permalink":"https://wangtingkui.space/posts/go/viper/","series":null,"tags":["go"],"title":"使用 Viper 处理项目配置"},{"categories":["go三方库使用和源码分析"],"content":"当前，go 本身并没有良好的错误处理机制，一个比较常见错误处理方式如下：\n1if err != nil { 2return err 3} 然后层层传递，最终将错误传递到最上层，这里面存在着两个问题：\n 没有错误发生时的上下文信息（或者叫堆栈信息） 在层层的错误传递过程中，有可能已经将原始错误转化，丢失了最原始的 error  当前，比较优雅的方式是使用 github.com/pkg/errors 这个包来进行错误处理，官方文档 QUICK START 一个基本的使用如下：\n1package main 23import ( 4e \u0026#34;errors\u0026#34; 5\u0026#34;fmt\u0026#34; 67\u0026#34;github.com/pkg/errors\u0026#34; 8) 910func main() { 11oldErr := e.New(\u0026#34;我是底层error\u0026#34;) 1213// 添加错误信息和堆栈信息，生成一个新的 error 14\twrappedErr := errors.Wrap(oldErr, \u0026#34;我是封装error\u0026#34;) 1516// 输出错误信息 17\tfmt.Printf(\u0026#34;%v\\n\u0026#34;, wrappedErr) 1819fmt.Println(\u0026#34;===============================\u0026#34;) 2021// 输出错误信息和堆栈信息 22\tfmt.Printf(\u0026#34;%+v\\n\u0026#34;, wrappedErr) 2324fmt.Println(\u0026#34;===============================\u0026#34;) 2526// 获取底层错误 27\terr := errors.Cause(wrappedErr) 28fmt.Println(err) 2930} 我们也可以使用errors.WithMessage和errors.WithStack单独添加错误信息和堆栈信息\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 56\u0026#34;github.com/pkg/errors\u0026#34; 7) 89func func1() { 10e := errors.New(\u0026#34;make a error by errors.New\u0026#34;) 11e = errors.WithMessage(e, \u0026#34;add a message\u0026#34;) 12e = errors.WithMessage(e, \u0026#34;add another message\u0026#34;) 13e = errors.WithStack(e) 14fmt.Printf(\u0026#34;%+v\u0026#34;, e) 15} 1617func test() { 18func1() 19} 2021func main() { 22test() 23} 正常的使用方式  在错误的发生点使用errors.New生成错误，或者使用errors.Wrap封装错误，这时候会纪录堆栈信息，在之后就不需要在添加堆栈信息了 如果需要对错误添加错误信息，使用errors.WithMessage方法 顶层使用errors.Cause获取原始错误信息，使用%+v纪录整条链路的错误信息和堆栈信息  ","date":"2020-04-28","img":"","permalink":"https://wangtingkui.space/posts/go/pkg-errors/","series":null,"tags":["go"],"title":"使用 Pkg/Errors 进行错误处理"},{"categories":null,"content":"markdown 因为简洁的语法非常受到写文章的人的喜爱，但是某些情况下 markdown 也有不足，比如我们想展示一些特殊的样式或者格式的时候，往往需要直接书写 html 代码，这就和 markdown 简洁的初衷相违背了，hugo 提供了shortcode的功能来弥补了 markdown 的这个不足。shortcode 本质上是一些模板，我们可以使用定义好的指令来引用这些模板，相当于书写了一段html在文章中，更多的说明可以查看官网 ，接下来我们来看看怎么使用 shortcode\n简单使用 使用 shortcode 的语法是 {{% shortcodename parameters %}}，其中：\n shortcodename 是 shortcode 的名字 parameters 是参数列表，如果有多个参数，使用空格分隔，如果某个参数中有空格，需要用双引号把这个参数包起来 % 是定界符，也有使用\u0026lt;和\u0026gt;做定界符的，{{\u0026lt; shortcodename parameters \u0026gt;}}  参数有两种传递方式，基于名字的({{% shortcodename name1=value1 name2=value2 %}}))和基于位置的({{% shortcodename value1 value2 %}})，使用哪种方式取决于 shortcode 自己模板的定义。\n有的 shortcode 使用的时候要求闭合，类似 html 标签，比如 {{\u0026lt; highlight go \u0026gt;}} A bunch of code here {{\u0026lt; /highlight \u0026gt;}}\n常用的内置 shortcode\n   shortcodename 说明 usage     ref 使用绝对路径引用博客内其他文章 {{% ref \u0026quot;blog/other_article.md\u0026quot; %}}   relref 使用相对路径引用博客内其他文章 {{% relref \u0026quot;blog/other_article.md\u0026quot; %}}    ","date":"2020-04-14","img":"","permalink":"https://wangtingkui.space/posts/tool/shortcodes/","series":["使用hugo搭建个人网站"],"tags":["hugo"],"title":"在hugo中使用shortcode"},{"categories":["go标准库使用和源码分析"],"content":"本篇文章主要讲解下 go 的 time 包如何使用。go 中 time 的使用主要分为以下三个方面：\n 时间点的表示及其操作，以及时间点的格式化展示 时间段的表示及其操作 定时器的操作  本文只是列举比较常用的场景，更多的细节还是要参考官方文档 时间点 在 go 中，时间点使用 time.Time 来表示，这是一个基于纳秒精度的时间表示，我们还是通过一些例子来来学习\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;time\u0026#34; 6) 78func main() { 9// 获取时间 10\tnow := time.Now() // 获取当前时间点对象 11\tt := time.Unix(1586708379, 0) // 从指定时间戳实例化Time对象，第二个参数可以指定纳秒的精度 12 s, _ := time.Parse(\u0026#34;2006-01-02 03:04:05\u0026#34;, time.Now().Format(\u0026#34;2006-01-02 03:04:05\u0026#34;)) // 从时间字符串解析 13\tfmt.Println(now, t, s) 1415// 分解时间中的时间元素 16\tyear := t.Year() // 获取年 17\tmonth := t.Month() // 获取月份 18\tday := t.Day() // 获取日 19\thour := t.Hour() // 获取小时 20\tminute := t.Minute() // 获取分钟 21\tsecond := t.Second() // 获取秒数 22\tt.Unix() // 转换成时间戳 23\tt.UnixNano() // 转换成纳秒时间戳 24\tfmt.Println(year, month, day, hour, minute, second) 2526// 时间操作 27\tt.Add(time.Second * 10) // 添加10s 28\ttime.Now().Sub(t) // 计算时间差值，结果是个时间段 29\tt.Equal(time.Now()) // 比较两个时间是否相等，而且支持跨时区比较 30\tt.Before(time.Now()) // 比较某个时间是否在另一个时间之前 31\tt.After(time.Now()) // 比较某个时间是否在另一个时间之后 32 33// 格式化展示 34\tfmt.Println(t.Format(\u0026#34;2006-01-02 03:04:05\u0026#34;)) 35} 3637在 go 中，时间的格式化非常特别，是通过一些指定的数字来进行格式化的，这些数字也非常有记忆点，口诀是`2006 1 2 3 4 5`，也就是2006年1月2日下午3点4分5秒，不同的格式化就是通过摆弄这些数字来得到的 时间段 在 go 中，时间段是使用 time.Duration 来表示的，也是纳秒精度的一个数值，同时 go 也定义了一系列常用的时间精度，比如秒，小时等，看 go 中的源码很简单就能看明白：\n1// go 源码 2type Duration int64 34const ( 5Nanosecond Duration = 1 6Microsecond = 1000 * Nanosecond 7Millisecond = 1000 * Microsecond 8Second = 1000 * Millisecond 9Minute = 60 * Second 10Hour = 60 * Minute 11) 1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;time\u0026#34; 6) 78func main() { 9d := 10 * time.Second 10hour := d.Hours() // 转换成小时 11\tminite := d.Minutes() // 转换成分钟 12\tsecond := d.Seconds() // 转换成秒 13\tnano := d.Nanoseconds() // 转换成纳秒 14\tfmt.Println(hour, minite, second, nano) 15} 定时器 定时器的本质是一个 Time 类型的 channel，会以我们指定的时间间隔在 channel 中产生值\n1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;time\u0026#34; 6) 78func main() { 9ticker := time.Tick(time.Second) // 定义一个1秒间隔的定时器 10\tfor i := range ticker { 11fmt.Println(i) // 每秒都会执行的任务 12\t} 13} ","date":"2020-04-12","img":"","permalink":"https://wangtingkui.space/posts/go/time/","series":null,"tags":["go"],"title":"Go标准库（time）- 使用"},{"categories":["go标准库使用和源码分析"],"content":"log 标准包实现了一个简单的日志功能，本片文章主要写下 log 标准包的基本使用\n实例化 logger 进行日志记录 首先看一个最简单的 demo：\n1package main 23import ( 4\u0026#34;log\u0026#34; 5\u0026#34;os\u0026#34; 6) 78func main() { 9logger := log.New(os.Stdout, \u0026#34;我是自定义日志前缀：\u0026#34;, log.LstdFlags) 10logger.Println(\u0026#34;I\u0026#39;m print call\u0026#34;) 11} 1213// 我是自定义日志前缀：2020/03/29 20:45:43 I\u0026#39;m print call log 包最终输出到哪里和包本身无关，取决于 io.Writer（第一个参数） 对应的实际对象底层传递的是什么。\nlog 可以支持我们指定每条日志的前缀（第二个参数）和一些固定的标记（第三个参数）\nlogger 有Print、Fatal、Panic三个系列的方法，区别如下\n Print只记录日志 Fatal记录日志后会调用os.Exit(1)推出应用 Panic记录日志后会调用Panic  每个系列也都提供了三种调用方式，比如Print系列有以下三种方式：\n Print输出给定的信息 Println输出给定的信息并且在后面追加一个换行 Printf支持使用格式化参数  使用辅助方法进行日志记录 log 包还提供了一些快捷方法，可以直接通过包的方法调用，比如\n1package main 23import ( 4\u0026#34;log\u0026#34; 5) 67func main() { 8log.Println(\u0026#34;hahahha\u0026#34;) 9} 10// 2020/03/29 20:47:42 hahahha 它其实是在包内生成了一个输出到 stdout 的 logger，方便我们使用而已\n","date":"2020-03-29","img":"","permalink":"https://wangtingkui.space/posts/go/log/","series":null,"tags":["go"],"title":"Go标准库（log）- 使用"},{"categories":["php基础"],"content":"本篇文章是写一下我怎么进行php的多版本管理，利用的是phpbrew这个工具\n phpbrew github 地址   phpbrew安装过程 第一步 首先需要下载 phpbrew 的二进制文件\n1# 下载执行文件 2curl -L -O https://github.com/phpbrew/phpbrew/releases/latest/download/phpbrew.phar 34# 添加执行权限 5chmod +x phpbrew.phar 67# Move the file to some directory within your $PATH 8sudo mv phpbrew.phar /usr/local/bin/phpbrew 第二步 安装好二进制文件之后，phpbrew还需要一点简单的配置才能使用\n1# 初始化phpbrew shell脚本 2phpbrew init 34# 在shell配置文件（~/.bashrc 或者 ~/.zshrc）中添加 5echo \u0026#34;[[ -e ~/.phpbrew/bashrc ]] \u0026amp;\u0026amp; source ~/.phpbrew/bashrc\u0026#34; \u0026gt;\u0026gt; ~/.zshrc 67# 重新加载shell配置文件 8source ~/.zshrc 第三步 设置用于查找库文件的默认前缀，可选值有 macports，homebrew，debian，ubuntu 或是自定义路径。\n对于使用homebrew的用户，可以设置phpbrew lookup-prefix homebrew\nphpbrew命令简单使用 1# 查看phpbrew版本 2phpbrew --version 34# 查看可以安装的版本 5phpbrew know 67# 列出本地已经安装的版本 8phpbrew list 910# 临时切换版本 11phpbrew use 7.0.1 1213# 设置默认php版本 14phpbrew switch 7.0.1 1516# 关闭phpbrew 17phpbrew off 1819# 编辑当前版本的php.ini文件 20phpbrew config 2122# 编辑当前版本的fpm文件 23phpbrew fpm config 2425# 测试当前版本fpm配置 26phpbrew fpm test 2728# 进行当前版本的fpm操作 29phpbrew fpm [start|restart|stop] 3031# 升级phpbrew 32phpbrew self-update 一个安装demo 编译安装过php的同学都知道，php有很多复杂的编译选项，phpbrew提出了一个Variants的概念，将php编译的复杂的配置选项屏蔽起来\n你只需简单地指定某个 Variant 即可，phpbrew 会自动在配置过程中检测引用目录、编译选项等。\nPHPBrew 提供默认的 Variants ，以及一些虚拟 Variants。 「Default Variants」包含绝大多数公共 Variants； 「Virtual Variants」可包含多个 Variants，使用一个虚拟 Variants 即可一次性启用多个 Variants。\n可以使用phpbrew variants查看都有哪些variants\n1➜ ~ phpbrew variants 2Variants: 3all, apxs2, bcmath, bz2, calendar, cgi, cli, ctype, curl, dba, debug, dom, 4dtrace, editline, embed, exif, fileinfo, filter, fpm, ftp, gcov, gd, 5gettext, gmp, hash, iconv, imap, inifile, inline, intl, ipc, ipv6, json, 6kerberos, ldap, libgcc, mbregex, mbstring, mcrypt, mhash, mysql, opcache, 7openssl, pcntl, pcre, pdo, pear, pgsql, phar, phpdbg, posix, readline, 8session, soap, sockets, sodium, sqlite, static, tidy, tokenizer, wddx, 9xml, xmlrpc, zip, zlib, zts 101112Virtual variants: 13dbs: sqlite, mysql, pgsql, pdo 14mb: mbstring, mbregex 15neutral: 16small: bz2, cli, dom, filter, ipc, json, mbregex, mbstring, pcre, phar, 17posix, readline, xml, curl, openssl 18default: bcmath, bz2, calendar, cli, ctype, dom, fileinfo, filter, ipc, 19json, mbregex, mbstring, mhash, pcntl, pcre, pdo, pear, phar, posix, 20readline, sockets, tokenizer, xml, curl, openssl, zip 21everything: dba, ipv6, dom, calendar, wddx, static, inifile, inline, cli, 22ftp, filter, gcov, zts, json, hash, exif, mbstring, mbregex, libgcc, 23pdo, posix, embed, sockets, debug, phpdbg, zip, bcmath, fileinfo, ctype, 24cgi, soap, pcntl, phar, session, tokenizer, opcache, imap, ldap, tidy, 25kerberos, xmlrpc, fpm, dtrace, pcre, mhash, mcrypt, zlib, curl, readline, 26editline, gd, intl, sodium, openssl, mysql, sqlite, pgsql, xml, gettext, 27iconv, bz2, ipc, gmp, pear 282930Using variants to build PHP: 3132phpbrew install php-5.3.10 +default 33phpbrew install php-5.3.10 +mysql +pdo 34phpbrew install php-5.3.10 +mysql +pdo +apxs2 35phpbrew install php-5.3.10 +mysql +pdo +apxs2=/usr/bin/apxs2 在mac下安装，我们几乎必然会遇到某些依赖的头文件找不到的问题，遇到这种问题，我们可以先手动下载依赖库，然后在使用Variants的时候明确指定下依赖库的路径即可\n比如遇到下面的情况，明显是找不到openssl的依赖库，所以我们可以执行下面的操作\n1# 先手动安装openssl 2brew install openssl 3# 明确指定openssl的位置 4phpbrew install 7.0.13 +all +openssl=/usr/local/opt/openssl 如果有些配置没有被包含到variants中，我们可以在安装命令的末尾添加原始的编译选项-- 原始选项，注意--是必不可少的，他是variants和原始编译选项的分隔符\n我安装的一个demo\n1phpbrew install 7.0.33 +default +mb +dbs +fpm -pgsql +zlib=/usr/local/opt/zlib 常见问题 mac安装过程中经常会缺少的库报错集合 1# error 2configure: error: utf8_mime2text() has new signature, but U8T_CANONICAL is missing. This should not happen. Check config.log for additional information. 34#fix 5brew install imap-uw 安装指定版本 php，提示解压错误 这种问题一般都是通过phpbrew下载php压缩包文件格式不对，可以自己先将指定版本的压缩包下载到 ~/.phpbrew/distfiles 目录，这要就可以跳过 phpbrew 自身的下载过程，然后再重新执行 phpbrew install 就好了\n","date":"2020-01-14","img":"","permalink":"https://wangtingkui.space/posts/php/php-multi-version/","series":null,"tags":["php"],"title":"Php多版本管理"},{"categories":["go基础"],"content":"go 的 os 包提供了与基础的与操作系统无关的文件操作，包括创建、删除、读写等。同时为了更便捷的操作和性能上的提升，go在 io/ioutil 、bufio 等包中也提供了一些常用的方法供开发者使用\n本文只列出了一些常用的方法，更多的操作可以参考：https://colobu.com/2016/10/12/go-file-operations\n使用 os 包进行文件操作  打开文件\n 1package main 23import ( 4\u0026#34;os\u0026#34; 5) 67func main() { 89var ( 10file *os.File 11err error 12) 1314// 以只读方式打开一个文件 15\tfile, err = os.Open(\u0026#34;a.txt\u0026#34;) 16if err != nil { 17panic(err) 18} 19_ = file.Close() 2021// 以指定的模式打开文件，这个方法更具有通用性 22\t// 一般情况下我们应该尽量使用 os.Open 和 os.Create 方法而不是这个方法 23\tfile, err = os.OpenFile(\u0026#34;a.txt\u0026#34;, os.O_APPEND, 0666) 24if err != nil { 25panic(err) 26} 27_ = file.Close() 28}  创建文件\n 1package main 23import ( 4\u0026#34;os\u0026#34; 5) 67func main() { 89// 创建一个空文件 10\t// 看源码就可以发现它其实就是 OpenFile(name, O_RDWR|O_CREATE|O_TRUNC, 0666) 的快捷方式 11\tfile, err := os.Create(\u0026#34;create.txt\u0026#34;) 12if err != nil { 13panic(err) 14} 15_ = file.Close() 1617// 使用给定的unix文件描述符和名称创建文件，一般不使用 18\tfile = os.NewFile(3, \u0026#34;haha.txt\u0026#34;) 19_ = file.Close() 20}  删除文件\n 1package main 23import ( 4\u0026#34;os\u0026#34; 5) 67func main() { 8err := os.Remove(\u0026#34;create.txt\u0026#34;) 9if err != nil { 10panic(err) 11} 12}  重命名和移动文件\n 1package main 23import ( 4\u0026#34;os\u0026#34; 5) 67func main() { 8err := os.Rename(\u0026#34;a.txt\u0026#34;, \u0026#34;b.txt\u0026#34;) 9if err != nil { 10panic(err) 11} 12}  清空文件\n 1package main 23import ( 4\u0026#34;os\u0026#34; 5) 67func main() { 8// 第二个参数是要保留的字节数，如果传入0，就是清空整个文件 9\terr := os.Truncate(\u0026#34;b.txt\u0026#34;, 2) 10if err != nil { 11panic(err) 12} 13}  获取文件信息\n 1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;os\u0026#34; 6) 78var ( 9fileInfo os.FileInfo 10err error 11) 1213func main() { 14fileInfo, err = os.Stat(\u0026#34;b.txt\u0026#34;) 15if err != nil { 16panic(err) 17} 18fmt.Println(\u0026#34;File name:\u0026#34;, fileInfo.Name()) 19fmt.Println(\u0026#34;Size in bytes:\u0026#34;, fileInfo.Size()) 20fmt.Println(\u0026#34;Permissions:\u0026#34;, fileInfo.Mode()) 21fmt.Println(\u0026#34;Last modified:\u0026#34;, fileInfo.ModTime()) 22fmt.Println(\u0026#34;Is Directory: \u0026#34;, fileInfo.IsDir()) 23fmt.Printf(\u0026#34;System interface type: %T\\n\u0026#34;, fileInfo.Sys()) 24fmt.Printf(\u0026#34;System info: %+v\\n\\n\u0026#34;, fileInfo.Sys()) 25}  文件读取\n 1package main 23import ( 4\u0026#34;fmt\u0026#34; 5\u0026#34;os\u0026#34; 6) 78func main() { 9file, err := os.Open(\u0026#34;b.txt\u0026#34;) 10if err != nil { 11panic(err) 12} 1314buf := make([]byte, 10) 15for { 16l, err := file.Read(buf) 17if l \u0026gt; 0 { 18fmt.Println(string(buf[:l])) 19} 20if err != nil { 21break 22} 23} 24}  写文件\n 1package main 23import ( 4\u0026#34;os\u0026#34; 5) 67func main() { 8file, err := os.Create(\u0026#34;newfile.txt\u0026#34;) 9if err != nil { 10panic(err) 11} 12defer file.Close() 1314file.Write([]byte(\u0026#34;fuck1\u0026#34;)) 15file.WriteString(\u0026#34;fuck2\u0026#34;) 16} 使用 bufio 操作文件  按行读取文件\n 1package main 23import ( 4\u0026#34;bufio\u0026#34; 5\u0026#34;fmt\u0026#34; 6\u0026#34;os\u0026#34; 7) 89func main() { 10file, err := os.Open(\u0026#34;b.txt\u0026#34;) 11if err != nil { 12panic(err) 13} 14defer file.Close() 1516// 通过 bufio.Reader 读取行 17\t// 默认 buffer 是4096 18\treader := bufio.NewReader(file) 19for { 20// 读取文件的一行，默认用 \\r\\n 或者 \\n 分隔，读取出来的行是不包含分隔符的 21\t// 如果文件的行太长，h超过了 bufio.Reader 内部的 buffer， 会将第二个返回参数 isPrefix 设置为 true 22\tbuf, _, err := reader.ReadLine() 23if err != nil { 24break 25} 26fmt.Println(string(buf)) 27} 2829// 通过bufio.Scanner 读取行 30\tfile.Seek(0, 0) 31scanner := bufio.NewScanner(file) 32// scanner.Split() ，可以通过这个函数设置自定义的分隔方式，默认是换行 33\tfor scanner.Scan() { 34fmt.Println(scanner.Text()) 35} 36} 使用 io/ioutil 进行文件操作 ","date":"2020-01-05","img":"","permalink":"https://wangtingkui.space/posts/go/go-file-operation/","series":null,"tags":["go"],"title":"Go进行文件操作"},{"categories":["go标准库使用和源码分析"],"content":"net/http 包为我们提供了对 http 协议的处理，包含了客户端和服务端两大部分的实现\n版本  go1.12  主要结构体 几乎任何语言中的http包都是围绕客户端，服务端，请求和响应这4个对象展开的，go 也不例外。本篇主要是讲解包的使用，所以还是通过例子来说明\n客户端 快速入门 http 客户端基本的使用流程：\n 构造请求 构造客户端 使用客户端发送请求获取响应 使用响应  下面用一个最简单的例子来展示下上面的流程：\n1func main() { 23// 创建一个请求 4\treq, err := http.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;http://www.baidu.com\u0026#34;, nil) 5if err != nil { 6panic(err) 7} 89// 创建一个客户端 10\tclient := http.Client{} 1112// 使用客户端发送请求 13\tresp, err := client.Do(req) 14if err != nil { 15panic(err) 16} 1718// 使用响应 19\tdefer resp.Body.Close() 20if ret, err := ioutil.ReadAll(resp.Body); err != nil { 21panic(err) 22} else { 23fmt.Println(string(ret)) 24} 25} 当我们没有特殊需求，只是想要简单的发送一个 get 或者是 post 请求的时候，上面的代码明显有些冗长，还是同其他的包一样，对这种简单使用，go 的官方包通常会为我们提供一些\u0026quot;快捷方法\u0026quot;（其实就是在包内生成一些默认对象，再导出一些方法，使用这些默认对象而已，从而节省了我们构造对象的过程）。\n1func main() { 23// 创建一个请求 4\tif resp, err := http.Get(\u0026#34;http://www.baidu.com\u0026#34;); err != nil { 5panic(err) 6} else { 7defer resp.Body.Close() 8body, _ := ioutil.ReadAll(resp.Body) 9fmt.Println(string(body)) 10} 11} 像这样的“快捷方法”还有Post,PostForm,Head\n精细化控制各项请求参数 当我们想要控制比如超时时间、重定向规则等属性的时候，我们就必须手动的去构造请求和客户端，设置我们的参数，从而达到精细控制的目的，下面让我们看以下如何设置常用的参数\n设置超时时间 1// 超时控制需要在客户端中设置 2client := http.Client{ 3Transport: \u0026amp;http.Transport{ 4DialContext: (\u0026amp;net.Dialer{ 5Timeout: time.Second, // 连接超时 6 }).DialContext, 7}, 8CheckRedirect: nil, // 用来判断重定向 9 Jar: nil, // 用来设置cookie 10 Timeout: 4 * time.Second, // 从发出请求到读取完响应的整体时间 11} 设置header 1req := http.NewRequest(\u0026#34;GET\u0026#34;, \u0026#34;http://www.baidu.com\u0026#34;, nil) 2req.Header.Add(\u0026#34;Test-Header1\u0026#34;, \u0026#34;header1\u0026#34;) 3req.Header.Add(\u0026#34;Test-Header2\u0026#34;, \u0026#34;header2\u0026#34;) 服务端 快速入门 创建一个服务端的基本步骤：\n 创建一个路由器 设置路由 启动server监听  1// 同样的，官方包也为我们提供了快速创建服务端的“快捷方式”\n1func main() { 2http.HandleFunc(\u0026#34;/ping\u0026#34;, func(w http.ResponseWriter, req *http.Request) { 3w.Write([]byte(\u0026#34;pong\u0026#34;)) 4}) 5http.ListenAndServe(\u0026#34;:8888\u0026#34;, nil) 6} ","date":"2019-12-22","img":"","permalink":"https://wangtingkui.space/posts/go/%E4%BD%BF%E7%94%A8net-http/","series":null,"tags":["go"],"title":"Go标准库（net/Http）- 使用"},{"categories":["go标准库使用和源码分析"],"content":"net/url包是官方为我们提供的处理 url 链接的库，基本能覆盖我们大多数场景下的使用\nurl 结构 想要使用好这个库，我们需要了解url的基本结构：标准结构：scheme://[userinfo@]host/path[?query][#fragment]，如果 scheme 之后不是以斜线开头的，那么结构被认为是 scheme:opaque[?query][#fragment]，也就是用户信息、域名和路径部分是不透明的，可以认为是被加密或者被编码过的\n更多详细的信息，可以参考百科 环境 1❯ go version 2go version go1.16.15 darwin/amd64 包中的基本结构体 先概览下包中导出的方法和结构\n可以看到包中有3个比较主要的结构：\n URL：代表一个被解析的url UserInfo：代表 url 中的用户信息部分 Values：存放 query 参数或者 form 参数  1type URL struct { 2Scheme string 3Opaque string // encoded opaque data 4\tUser *Userinfo // username and password information 5\tHost string // host or host:port 6\tPath string // path (relative paths may omit leading slash) 7\tRawPath string // encoded path hint (see EscapedPath method) 8\tForceQuery bool // append a query (\u0026#39;?\u0026#39;) even if RawQuery is empty 9\tRawQuery string // encoded query values, without \u0026#39;?\u0026#39; 10\tFragment string // fragment for references, without \u0026#39;#\u0026#39; 11\tRawFragment string // encoded fragment hint (see EscapedFragment method) 12} 1314type Userinfo struct { 15username string 16password string 17passwordSet bool 18} 1920type Values map[string][]string 基本使用 解析url 1func main() { 2rowUrl := \u0026#34;http://xiaok:mypwd@xiaokspace.com:8080/mypath/xxx?a=123\u0026amp;b=456\u0026amp;c=中文#tag\u0026#34; 3u, err := url.Parse(rowUrl) 4if err != nil { 5panic(err) 6} 7fmt.Println(u.Scheme) // http 8\tfmt.Println(u.Opaque) // 9\tfmt.Println(u.User) // xiaok:mypwd 10\tfmt.Println(u.Host) // xiaokspace.com:8080 11\tfmt.Println(u.Path) // /mypath/xxx 12\tfmt.Println(u.RawPath) // 13\tfmt.Println(u.RawQuery) // a=123\u0026amp;b=456\u0026amp;c=中文 14\tfmt.Println(u.Fragment) // tag 15\tfmt.Println(u.RawFragment) // 16 17// 不过有的情况也不会直接使用暴露的值，而是通过url中封装好的方法使用 18\tfmt.Println(u.EscapedPath()) // /mypath/xxx 19\tfmt.Println(u.EscapedFragment()) // tag 20\tfmt.Println(u.Hostname()) // xiaokspace.com 21\tfmt.Println(u.Port()) // 8080 22\tfmt.Println(u.RequestURI()) // /mypath/xxx?a=123\u0026amp;b=456\u0026amp;c=中文 23} 在 url 包中，有三个关于解析的方法，Parse,ParseRequestURI和ParseQuery：\n Parse 解析一个通用的 url（url不仅仅代表http中的地址） ParseRequestURI 断定入参是从正常的 http request 中来的 ParseQuery 解析 query 的参数  构造url 1func main() { 2u := url.URL{ 3Scheme: \u0026#34;http\u0026#34;, 4Host: \u0026#34;baidu.com\u0026#34;, 5Path: \u0026#34;/s\u0026#34;, 6RawQuery: \u0026#34;a=c\u0026#34;, 7Fragment: \u0026#34;tag\u0026#34;, 8} 9fmt.Println(u.String()) //http://baidu.com/s?a=c#tag 10} 编码和解码操作 1func main() { 23var ( 4rowUrl = \u0026#34;http://www.baidu.com?q=我 曹#123\u0026#34; 5escapedUrl string 6unescapedUrl string 7) 89// 可以保证安全的放在query中 10\tescapedUrl = url.QueryEscape(rowUrl) 11unescapedUrl, _ = url.QueryUnescape(escapedUrl) 1213fmt.Println(escapedUrl) 14fmt.Println(unescapedUrl) 1516// 可以保证安全的放在path段中 17\tescapedUrl = url.PathEscape(rowUrl) 18unescapedUrl, _ = url.PathUnescape(escapedUrl) 1920fmt.Println(escapedUrl) 21fmt.Println(unescapedUrl) 22} 2324// http%3A%2F%2Fwww.baidu.com%3Fq%3D%E6%88%91+%E6%9B%B9%23123 25// http://www.baidu.com?q=我 曹#123 26// http:%2F%2Fwww.baidu.com%3Fq=%E6%88%91%20%E6%9B%B9%23123 27// http://www.baidu.com?q=我 曹#123 URL 其他常用方法 1func main() { 23rowUrl := \u0026#34;http://www.baidu.com/fuck?a=a\u0026amp;b=b\u0026amp;c=c#123\u0026#34; 4url, _ := url.Parse(rowUrl) 56// 是否是绝对路径（scheme是否为空） 7\tfmt.Println(url.IsAbs()) // true 8} Values 常用方法 1func main() { 23rowUrl := \u0026#34;http://www.baidu.com/fuck?a=a\u0026amp;b=b\u0026amp;c=c#123\u0026#34; 4url, _ := url.Parse(rowUrl) 56values := url.Query() 7fmt.Println(values) 89// 添加一个元素 10\tvalues.Add(\u0026#34;d\u0026#34;, \u0026#34;d\u0026#34;) 11fmt.Println(values) 1213// 删除一个元素 14\tvalues.Del(\u0026#34;a\u0026#34;) 15fmt.Println(values) 1617// 获取一个元素 18\tfmt.Println(values.Get(\u0026#34;b\u0026#34;)) 1920// 设置一个元素 21\tvalues.Set(\u0026#34;c\u0026#34;, \u0026#34;ccc\u0026#34;) 22fmt.Println(values) 23values.Set(\u0026#34;name\u0026#34;, \u0026#34;王\u0026#34;) 2425// 编码成 url query 格式 26\tfmt.Println(values.Encode()) 27} 2829// map[a:[a] b:[b] c:[c]] 30// map[a:[a] b:[b] c:[c] d:[d]] 31// map[b:[b] c:[c] d:[d]] 32// b 33// map[b:[b] c:[ccc] d:[d]] 34// b=b\u0026amp;c=ccc\u0026amp;d=d\u0026amp;name=%E7%8E%8B ","date":"2019-12-21","img":"","permalink":"https://wangtingkui.space/posts/go/net-url/","series":null,"tags":["go"],"title":"Go标准库（net/Url）"},{"categories":["go三方库使用和源码分析"],"content":"zap 是一个高性能的第三方日志类库，本篇主要说明下如何使用 zap\n版本 本篇基于的 zap 版本是 v1.10.0\n使用 基本概念 在使用 zap 之前，我们还是先了解下 zap 里面的一些基本概念，方便在我们阅读 demo 或者写代码的时候能大体的感知到我们在用什么，为什么这样用。为了不产生翻译上的歧义，书写过程中涉及到的概念会用 zap 源码中的命名\n Logger\n 这是 zap 暴露给我们类型，正常情况下，我们也是通过 Logger 这个结构体的方法来记录日志的\n Config\n 这个是 zap 提供给我们的 Logger 的配置，我们可以按需配置，然后通过 Build 方法来构造出我们想要的 Logger，是典型的的构造者模式\n Field\n 除了日志级别、日志时间、日志信息等这些基本的通用字段之外，我们在记录日志的时候通常会想记录一些额外的字段（用来记录打日志时的上下文），这些字段在 zap 中需要封装成 Field 类型\n Core\n Logger 是一个结构体，为我们暴露了使用日志的方法，而 Core 是一个接口，它被包含在 Logger 中，用来真正提供日志格式化和输出功能，这样的实现使日志记录器的使用和输出实现了高度解耦。我们可以实现自己的 Core 从而达到不同的输出的目的\n Encoder\n Encoder 同样是一个接口，刚才说到 Core 是实现具体输出行为的核心，而 Encoder 是 Core 中真正进行日志信息和字段格式化的编码器，它把我们输入的各种日志信息经过处理得到字节切片。从而可以记录在各种存储载体中。zap 对于 Encoder 自带了两个实现，jsonEncoder 和 consoleEncoder\n EncoderConfig\n 这个就很好理解了，就是我们 Encoder 的配置，由于不同的 Encoder 实现不一样，所以如果是我们自己实现的 Encoder，完全可以实现自己的 EncoderConfig，zap 中的 EncoderConfig 自然也是为了 jsonEncoder 和 consoleEncoder 服务的。\nLogger 快速入门 了解了 zap 中的一些基础概念，让我们先来搞一个小 demo 感受一下\n代码：\n1func main() { 2// 实例化一个 EncoderConfig 3\tencoderCfg := zapcore.EncoderConfig{ 4MessageKey: \u0026#34;msg\u0026#34;, // 序列化成json时在输出中的key 5\tLevelKey: \u0026#34;level\u0026#34;, 6NameKey: \u0026#34;logger\u0026#34;, 7EncodeLevel: zapcore.LowercaseLevelEncoder, // 日志级别字段的值序列化方式，这里使用了zap自带的小写格式编码 8\tEncodeTime: zapcore.ISO8601TimeEncoder, // 时间字段的值序列化方式，这里使用了自带的ISO8601格式编码 9\tEncodeDuration: zapcore.StringDurationEncoder, // 时间段类型的值序列化方式，这里使用自带的字符串格式 10\t} 1112// 用刚才 EncoderConfig 实例化一个 jsonEncoder，也就是输出成json格式 13\tjsonEncoder := zapcore.NewJSONEncoder(encoderCfg) 1415// 实例化一个 Core，使用 jsonEncoder，将 InfoLevel 级别以上（包含 InfoLevel）的日志输出到标准输出中 16\tcore := zapcore.NewCore(jsonEncoder, os.Stdout, zapcore.InfoLevel) 1718// 用 Core 实例化一个 Logger 19\tlogger := zap.New(core) 2021logger.Debug(\u0026#34;debug level log\u0026#34;, zap.String(\u0026#34;k\u0026#34;, \u0026#34;v\u0026#34;)) 22logger.Info(\u0026#34;info level log\u0026#34;, zap.Bool(\u0026#34;k\u0026#34;, false)) 23logger.Warn(\u0026#34;warn level log\u0026#34;, zap.Time(\u0026#34;t\u0026#34;, time.Now())) 24logger.Error(\u0026#34;error level log\u0026#34;, zap.Int(\u0026#34;i\u0026#34;, 9)) 25} 输出：\n1{\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;info level log\u0026#34;,\u0026#34;k\u0026#34;:false} 2{\u0026#34;level\u0026#34;:\u0026#34;warn\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;warn level log\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;2019-12-16T23:58:53.324+0800\u0026#34;} 3{\u0026#34;level\u0026#34;:\u0026#34;error\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;error level log\u0026#34;,\u0026#34;i\u0026#34;:9} 之所以少一条，是应为我们设置了 info 级别以上才输出。\n使用构造方法获取预置 Logger 可以看到上面的整个使用过程，基本上都是围绕着我们最开始提到的基本概念展开的，同时也能明显的感受到，构造一个 Logger 的过程还是复杂的，所以同很多包一样，zap 也为我们提供了几个方便的构造函数，能让我们快速的获取 Logger，基本也能覆盖我们大多数简单的使用场景，分别是zap.NewExample，zap.NewDevelopment和zap.NewProduction，除了这3个，还有一个zap.NewNop，这个相当于一个空 Logger，不做任何操作，所以也不用着重介绍了。下面让我们依次看下前三个。\n zap.NewExample\n 1func main() { 2logger := zap.NewExample() 3logger.Debug(\u0026#34;我是debug信息\u0026#34;, zap.String(\u0026#34;k\u0026#34;, \u0026#34;v\u0026#34;)) 4logger.Info(\u0026#34;我是info信息\u0026#34;, zap.Bool(\u0026#34;b\u0026#34;, true)) 5} 67// {\u0026#34;level\u0026#34;:\u0026#34;debug\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;我是debug信息\u0026#34;,\u0026#34;k\u0026#34;:\u0026#34;v\u0026#34;} 8// {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;我是info信息\u0026#34;,\u0026#34;b\u0026#34;:true} 可以看到这样用起来就非常方便了，如果我们取看他的源码，会发现其实就是封装了我们上面创建一个 Logger 的过程\n zap.NewDevelopment\n 1func main() { 2logger, _ := zap.NewDevelopment() 3logger.Debug(\u0026#34;我是debug信息\u0026#34;, zap.String(\u0026#34;k\u0026#34;, \u0026#34;v\u0026#34;)) 4logger.Info(\u0026#34;我是info信息\u0026#34;, zap.Bool(\u0026#34;b\u0026#34;, true)) 5} 67// 2019-12-17T11:40:33.606+0800 DEBUG zap/main.go:9 我是debug信息 {\u0026#34;k\u0026#34;: \u0026#34;v\u0026#34;} 8// 2019-12-17T11:40:33.606+0800 INFO zap/main.go:10 我是info信息 {\u0026#34;b\u0026#34;: true}  zap.NewProduction\n 1func main() { 2logger, _ := zap.NewProduction() 3logger.Debug(\u0026#34;我是debug信息\u0026#34;, zap.String(\u0026#34;k\u0026#34;, \u0026#34;v\u0026#34;)) 4logger.Info(\u0026#34;我是info信息\u0026#34;, zap.Bool(\u0026#34;b\u0026#34;, true)) 5} 67// {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:1576554152.8352141,\u0026#34;caller\u0026#34;:\u0026#34;zap/main.go:10\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;我是info信息\u0026#34;,\u0026#34;b\u0026#34;:true} 通过配置构造 Logger 上面的几种用法都是我们手动的创建 Logger，我们还可以通过构造 Logger 的 Config，从而来构建 Logger，可以通过 zap.NewDevelopment 的源码学习\n这种方法也能给我们带来比较大的灵活性，能在 Logger 的配置上有更大的自由度\n如果想更加精细的配置 Logger，比如同时使用多个 Core 输出，可以参考本文的 zap 高级配置小节\n使用 SugaredLogger 进行日志记录 即便是 zap 为我们提供了几个预置的 Logger，但是当我们想添加自己的附加字段的时候，需要对每个字段调用对应的封装函数将其包装为 zap.Field 类型，这样做的好处是效率非常高，但是当我们不在乎这一点性能的提升，愿意用一点点性能的损耗来换取编程的方便的时候，可以使用 zap 为我们提供的 SugaredLogger 这个类，名字也非常形象，语法糖，方便我们的编程过程\nSugaredLogger 是对 Logger 的封装，提供了更加方便的api供我们使用，其实就是不必去调用 zap 的一系列函数，将我们的额外字段封装成 Field 类型，在 SugaredLogger 底层会自动帮我们处理\nLogger 和 SugaredLogger 之间的转换也非常简单，我们完全可以在一个项目中根据需求混合使用两种日志记录方式\n1func main() { 2logger, _ := zap.NewDevelopment() 34// 通过 Logger 转换成 SugaredLogger 5\tsugar := logger.Sugar() 6sugar.Info(\u0026#34;sugar info message\u0026#34;) 7sugar.Infof(\u0026#34;sugar info formatted message %s\u0026#34;, \u0026#34;hehe\u0026#34;) 8sugar.Infow(\u0026#34;sugar info message with extra context\u0026#34;, \u0026#34;key1\u0026#34;, \u0026#34;val1\u0026#34;, \u0026#34;ket2\u0026#34;, true) 910// 通过 SugaredLogger 转换成 Logger 11\tlg := sugar.Desugar() 12lg.Debug(\u0026#34;我是debug信息\u0026#34;, zap.String(\u0026#34;k\u0026#34;, \u0026#34;v\u0026#34;)) 13lg.Info(\u0026#34;我是info信息\u0026#34;, zap.Bool(\u0026#34;b\u0026#34;, true)) 14} 1516//2019-12-17T12:08:14.535+0800 INFO zap/main.go:12 sugar info message 17//2019-12-17T12:08:14.535+0800 INFO zap/main.go:13 sugar info formatted message hehe 18//2019-12-17T12:08:14.535+0800 INFO zap/main.go:14 sugar info message with extra context {\u0026#34;key1\u0026#34;: \u0026#34;val1\u0026#34;, \u0026#34;ket2\u0026#34;: true} 19//2019-12-17T12:08:14.535+0800 DEBUG zap/main.go:18 我是debug信息 {\u0026#34;k\u0026#34;: \u0026#34;v\u0026#34;} 20//2019-12-17T12:08:14.535+0800 INFO zap/main.go:19 我是info信息 {\u0026#34;b\u0026#34;: true} zap 高级配置 可以参考：https://godoc.org/go.uber.org/zap#pkg-examples\n","date":"2019-12-16","img":"","permalink":"https://wangtingkui.space/posts/go/zap/","series":null,"tags":["go"],"title":"Go日志库zap使用"},{"categories":["go标准库使用和源码分析"],"content":"简介 这个库主要是对文件路径的操作，是比较常用的一个库，由于这个库比较简单，没有什么需要过多的说明，大部分的方法会以实例的形式来展示\n而且要注意的是，path/filepath这个库并不会去判断你指定的路径存不存在，也不会去判断指定的路径是一个文件还是一个目录\n环境 1╰─$ go version 2go version go1.12.14 darwin/amd64 说明 获取指定路径的目录 filepath.Dir() 代码：\n1func main() { 2examples := []string{ 3\u0026#34;/etc/a.txt\u0026#34;, 4\u0026#34;/etc/\u0026#34;, 5\u0026#34;/etc\u0026#34;, 6\u0026#34;etc/a.txt\u0026#34;, 7\u0026#34;etc\u0026#34;, 8\u0026#34;\u0026#34;, 9} 1011for _, path := range examples { 12fmt.Println(filepath.Dir(path)) 13} 14} 输出：\n1╰─$ go run main.go 2/etc 3/etc 4/ 5etc 6. 7. 获取指定路径的文件名 filepath.Base() 代码：\n1func main() { 2examples := []string{ 3\u0026#34;/etc/a.txt\u0026#34;, 4\u0026#34;/etc/\u0026#34;, // 在拆分之前会去除末尾的斜杠，相当于 /etc 5\t\u0026#34;/etc\u0026#34;, 6\u0026#34;etc/a.txt\u0026#34;, 7\u0026#34;etc\u0026#34;, 8\u0026#34;\u0026#34;, // 如果是空字符串，返回 . 9\t\u0026#34;/\u0026#34;, // 如果是 / ，返回 / 10\t} 1112for _, path := range examples { 13fmt.Println(filepath.Base(path)) 14} 15} 输出：\n1╰─$ go run main.go 2a.txt 3etc 4etc 5a.txt 6etc 7. 8/ 绝对路径和相对路径相关处理 代码：\n1func main() { 2var ( 3absPath = \u0026#34;/etc/a.txt\u0026#34; 4relPath = \u0026#34;a.txt\u0026#34; 5tmpPath string 6err error 7) 8// 判断是否绝对路径 9\tfmt.Println(\u0026#34;absPath is asb path:\u0026#34;, filepath.IsAbs(absPath)) 10fmt.Println(\u0026#34;relPath is abs path:\u0026#34;, filepath.IsAbs(relPath)) 11// 获取相对路径的绝对路径 12\tif tmpPath, err = filepath.Abs(relPath); err != nil { 13panic(err) 14} else { 15fmt.Println(\u0026#34;the abs path of rel path is:\u0026#34;, tmpPath) 16} 17// 获取绝对路径的相对路径 18\tif tmpPath, err = filepath.Rel(\u0026#34;/etc/a\u0026#34;, \u0026#34;/etc/a.txt\u0026#34;); err != nil { 19panic(err) 20} else { 21fmt.Println(\u0026#34;the rel path of /etc/a.txt based on /etc/a is:\u0026#34;, tmpPath) 22} 23} 输出：\n1╰─$ go run main.go 2absPath is asb path: true 3relPath is abs path: false 4the abs path of rel path is: /Users/wangtingkui/Projects/learnGo/filepath/a.txt 5the rel path of /etc/a.txt based on /etc/a is: ../a.txt 文件路径的拆分 对于一个确定是文件的路径，我们可以使用Split将他拆分为目录路径和文件名，这个函数拆分之后一定会保证 path = dir + file\n代码：\n1func main() { 2var ( 3filePaths = []string{ 4\u0026#34;/etc/a.txt\u0026#34;, 5\u0026#34;/etc/\u0026#34;, 6\u0026#34;/etc\u0026#34;, 7\u0026#34;etc/\u0026#34;, 8\u0026#34;etc\u0026#34;, 9\u0026#34;\u0026#34;, 10} 11) 1213for _, filePath := range filePaths { 14dir, file := filepath.Split(filePath) 15fmt.Printf(\u0026#34;dir is :%s , file is :%s\\n\u0026#34;, dir, file) 16} 17} 输出：\n1dir is :/etc/ , file is :a.txt 2dir is :/etc/ , file is : 3dir is :/ , file is :etc 4dir is :etc/ , file is : 5dir is : , file is :etc 6dir is : , file is : 规范化路径 有的路径虽然可以使用，但是看起来非常的绕，不易阅读和维护，比如ls /../etc/../etc/ 其实就是ls /etc，Clean就是用来清理这样的路径的\n代码：\n1func main() { 2var ( 3filePaths = []string{ 4\u0026#34;/../etc/../etc/\u0026#34;, 5\u0026#34;../a/./../a\u0026#34;, 6} 7) 89for _, filePath := range filePaths { 10fmt.Println(filepath.Clean(filePath)) 11} 12} 输出：\n1╰─$ go run main.go 2/etc 3../a 路径的拼接 可以使用Join来拼任意多段路径，这个函数会根据情况添加合适的路径分隔符，也会保证返回的结果是Clean过的\n代码：\n1func main() { 2fmt.Println(filepath.Join(\u0026#34;/etc/\u0026#34;, \u0026#34;/a.txt\u0026#34;)) 3fmt.Println(filepath.Join(\u0026#34;/etc\u0026#34;, \u0026#34;a.txt\u0026#34;)) 4} 输出：\n1╰─$ go run main.go 2/etc/a.txt 3/etc/a.txt 返回符合指定模式的文件列表 代码：\n1func main() { 23if paths, err := filepath.Glob(\u0026#34;./*.go\u0026#34;); err != nil { 4panic(err) 5} else { 6for _, path := range paths { 7fmt.Println(path) 8} 9} 10} 输出：\n1╰─$ go run main.go 2main.go 遍历目录树 filepath这个包给我们提供了一个方便的方法Walk来遍历我们的目录树\n代码：\n1func main() { 2filepath.Walk(\u0026#34;.\u0026#34;, func(path string, info os.FileInfo, err error) error { 3if info.IsDir() { 4return nil 5} 6fmt.Println(\u0026#34;file:\u0026#34;, info.Name(), \u0026#34;in directory:\u0026#34;, path) 7return nil 8}) 9} 输出：\n1╰─$ go run main.go 2file: main.go in directory: main.go ","date":"2019-12-15","img":"","permalink":"https://wangtingkui.space/posts/go/path-filepath/","series":null,"tags":["go"],"title":"Go标准库（path/Filepath）- 使用"},{"categories":["go基础"],"content":"之前写php，使用phpbrew来进行php的版本管理，非常方便，同样的，go也有自己的多版本管理工具gvm，这篇文章就记录下如何在mac下使用gvm进行go的多版本管理\ngvm的信息可以参考：https://github.com/moovweb/gvm\n环境信息  macOS 10.15.2 brew 2.1.16  安装gvm 1bash \u0026lt; \u0026lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer) 下载好之后，需要修改下个人配置文件，使gvm相关命令生效，如果用的是bash，则修改~/.bashrc，如果习惯用zsh，那就修改~/.zshrc，以此类推\n1[[ -s \u0026#34;$HOME/.gvm/scripts/gvm\u0026#34; ]] \u0026amp;\u0026amp; source \u0026#34;$HOME/.gvm/scripts/gvm\u0026#34; 修改之后，重开一会会话或者直接source ~/.zshrc（我用的是zsh）让刚才的修改生效。执行一下看下效果\n1╰─$ gvm version 2Go Version Manager v1.0.22 installed at /Users/wangtingkui/.gvm 可以看到，我装的是 1.0.22 的版本\n常用命令 1# 查看gvm版本 2gvm version 34# 查看所有可以安装的版本 5gvm listall 67# 查看本地已经安装的版本 8gvm list 910# 安装指定版本 11gvm install go1.13.5 1213# 删除指定版本 14gvm uninstall go1.13.5 1516# 临时切换版本 17gvm use go1.13.5 1819# 切换版本并指定为默认版本 20gvm use go1.13.5 --default 使用 由于go是使用自举的方式来编译，也就是用go来编译go，所有我们使用gvm来初始安装一个版本的时候，首先需要保证在自己的环境中有go，我是直接使用brew安装的，大家也可以使用其他方式下载安装\n 下面是我的安装过程\n 1brew install go 2gvm listall # 看下有哪些版本 3gvm install go1.13.6 # 选择一个版本安装 4brew unlink go # 使用gvm安装完之后就可以不适用brew安装的go了，所以直接断开连接 5gvm use go1.13.6 --default # 选择刚才安装的版本并且设置为默认版本 当我们使用gvm use \u0026lt;version\u0026gt;切换版本的时候，可以使用go env GOPATH看下，可以发现随着我们切换版本，GOPATH的路径也在变换，这样就不用害怕不同版本GOPATH下的内容冲突了\n","date":"2019-12-13","img":"","permalink":"https://wangtingkui.space/posts/go/go-multi-version-manage/","series":null,"tags":["go"],"title":"Go多版本管理"},{"categories":["go三方库使用和源码分析"],"content":"上一篇文章中简单介绍了如何使用cobra框架，这篇文章让我们来看下cobra的源码，本文基于的cobra版本是v0.0.5\n首先需要了解的是，在cobra中，所有的命令会组成一个树的结构，必然有一个根命令，我们应用的每次执行，都是从这个根命令开始的，官方文档也说过，基于cobra的应用的main包中的代码是很简单的，几乎没有额外的操作，仅有的操作其实就是执行我们的根命令。所以自然而然的，我们的代码分析之旅也是从根命令的执行开始的。\n为了有个直观的感受，我简单生成了一个基于cobra的应用。这个应用有一个根命令和一个test1的子命令，项目结构如下：\n1╰─$ tree . 2. 3├── LICENSE 4├── cmd 5│ ├── root.go 6│ └── test1.go 7├── go.mod 8├── go.sum 9└── main.go 10111 directory, 6 files 主线执行分析 所有的项目不可能都是简单的一条线到底，代码总会有很多分支，但我们阅读源码的时候精力和关注度总是有限的（不是有人说人在同一时间关注的点不能超过7个还是几个来着么），如果代码里面的每个分支都去看，每个函数的调用都进去瞅瞅，很快我们就会迷失在复杂的代码里面，忘了我们怎么看到的这行代码，所以本文去分析源码的时候，会优先挑一条主线，主要跟踪这条主线上的逻辑和调用，忽略其他支线。当然，也会有比较重要的其他支线，但是和当前的主线无关，会单开一个小节去阅读分析\ncobra主线自然是入口-找到目标命令-分析参数-执行这条路径啦~\n看下main.go文件中都有点啥\n1package main 23import \u0026#34;learnCobra/cmd\u0026#34; 45func main() { 6cmd.Execute() 7} 简洁的一比，直接进入cmd.Execute\n1func Execute() { 2if err := rootCmd.Execute(); err != nil { 3fmt.Println(err) 4os.Exit(1) 5} 6} 可以看到，其实就是执行了根命令的Execute方法，这个方法才是我们的重头戏。当然，所谓的根命令只是从命令的组织形态上来说的，所有的命令都是cobra.Command的这个结构体，后面绝大多数的代码也都是对这个结构体的成员和方法的分析\n1func (c *Command) Execute() error { 2_, err := c.ExecuteC() 3return err 4} 毫无波澜，直接进c.ExecuteC()，这里开始我会在源码里面写点注释了\n1func (c *Command) ExecuteC() (cmd *Command, err error) { 2// Regardless of what command execute is called on, run on Root only 3\t// 前面说过，我们所有的命令构成了一棵树，每次执行都是从根命令开始执行的 4\t// 如果我们手残在代码的某处直接执行了一个子命令，这个方法也会向上遍历到根，然后执行根命令的 5\tif c.HasParent() { 6return c.Root().ExecuteC() 7} 89// windows hook 10\t// windows 系统的钩子，不用care 11\tif preExecHookFn != nil { 12preExecHookFn(c) 13} 1415// initialize help as the last point possible to allow for user 16\t// overriding 17\t// 初始化默认的帮助命令，不是我们的主线，不care 18\tc.InitDefaultHelpCmd() 1920args := c.args 2122// Workaround FAIL with \u0026#34;go test -v\u0026#34; or \u0026#34;cobra.test -test.v\u0026#34;, see #155 23\t// 如果没有设置过命令的调用参数，使用os.Args[1:]作为默认参数 24\tif c.args == nil \u0026amp;\u0026amp; filepath.Base(os.Args[0]) != \u0026#34;cobra.test\u0026#34; { 25args = os.Args[1:] 26} 2728// 找真正要执行的命令，并解析flag 29\t// cobra为我们提供了两种flag，一种叫 persistant flag， 30\t// 这种 flag 可以在子命令中也获取到 31\t// 另外一种叫 local flag 32\t// 这种 flag 只会在指定命令中被解析 33\t// 默认情况下，cobra 只会解析目标命令的 local flag，父命令中的local flag将会被忽略 34\t// 可以将命令的 TraverseChildren 属性置为 true ，cobra 会在执行命令前解析所有命令 35\t// 的 local flag 36\tvar flags []string 37if c.TraverseChildren { 38cmd, flags, err = c.Traverse(args) 39} else { 40// 我们当然是挑软柿子捏，当然挑这条简单的路走 41\tcmd, flags, err = c.Find(args) 42} 43if err != nil { 44// If found parse to a subcommand and then failed, talk about the subcommand 45\tif cmd != nil { 46c = cmd 47} 48if !c.SilenceErrors { 49c.Println(\u0026#34;Error:\u0026#34;, err.Error()) 50c.Printf(\u0026#34;Run \u0026#39;%v --help\u0026#39; for usage.\\n\u0026#34;, c.CommandPath()) 51} 52return c, err 53} 5455// 记录这个命令被调用过了，和被调用的名字 56\tcmd.commandCalledAs.called = true 57if cmd.commandCalledAs.name == \u0026#34;\u0026#34; { 58cmd.commandCalledAs.name = cmd.Name() 59} 6061// 执行找到的命令 62\terr = cmd.execute(flags) 63if err != nil { 64// Always show help if requested, even if SilenceErrors is in 65\t// effect 66\tif err == flag.ErrHelp { 67cmd.HelpFunc()(cmd, args) 68return cmd, nil 69} 7071// If root command has SilentErrors flagged, 72\t// all subcommands should respect it 73\tif !cmd.SilenceErrors \u0026amp;\u0026amp; !c.SilenceErrors { 74c.Println(\u0026#34;Error:\u0026#34;, err.Error()) 75} 7677// If root command has SilentUsage flagged, 78\t// all subcommands should respect it 79\tif !cmd.SilenceUsage \u0026amp;\u0026amp; !c.SilenceUsage { 80c.Println(cmd.UsageString()) 81} 82} 83return cmd, err 84} 这里就有两个比较重要的方法了，c.Find和cmd.execute，我们先来看下怎么找到的目的命令\n1func (c *Command) Find(args []string) (*Command, []string, error) { 2// 声明了一个函数类型的变量 3\tvar innerfind func(*Command, []string) (*Command, []string) 45// 定义了这个函数 6\tinnerfind = func(c *Command, innerArgs []string) (*Command, []string) { 7// 去掉 flag， 剩下的就是参数 8\targsWOflags := stripFlags(innerArgs, c) 9if len(argsWOflags) == 0 { 10return c, innerArgs 11} 12// 参数的第一个就是要执行的命令 13\tnextSubCmd := argsWOflags[0] 1415// 在子命令中去找有没有匹配 nextSubCmd 的子命令 16\tcmd := c.findNext(nextSubCmd) 17if cmd != nil { 18// 递归的判断有没有匹配的子命令了 19\treturn innerfind(cmd, argsMinusFirstX(innerArgs, nextSubCmd)) 20} 21return c, innerArgs 22} 2324// 调用了上面定义的那个函数，我擦，我也不知道作者为什么这样写 25\t// 怕了怕了。。。先跳上去看逻辑吧 26\tcommandFound, a := innerfind(c, args) 27if commandFound.Args == nil { 28return commandFound, a, legacyArgs(commandFound, stripFlags(a, commandFound)) 29} 30return commandFound, a, nil 31} 然后我们再来看看cmd.execute\n1func (c *Command) execute(a []string) (err error) { 2// 如果命令是个nil，那还执行个蛋 3\tif c == nil { 4return fmt.Errorf(\u0026#34;Called Execute() on a nil Command\u0026#34;) 5} 67// 通过 Deprecated 这个属性判断这个命令是否将要被废弃 8\tif len(c.Deprecated) \u0026gt; 0 { 9c.Printf(\u0026#34;Command %q is deprecated, %s\\n\u0026#34;, c.Name(), c.Deprecated) 10} 1112// initialize help and version flag at the last point possible to allow for user 13\t// overriding 14\t// 添加默认的帮助flag和版本flag 15\tc.InitDefaultHelpFlag() 16c.InitDefaultVersionFlag() 1718// 解析flag 19\terr = c.ParseFlags(a) 20if err != nil { 21return c.FlagErrorFunc()(c, err) 22} 2324// If help is called, regardless of other flags, return we want help. 25\t// Also say we need help if the command isn\u0026#39;t runnable. 26\t// 如果使用了帮助flag，忽略其他的flag 27\thelpVal, err := c.Flags().GetBool(\u0026#34;help\u0026#34;) 28if err != nil { 29// should be impossible to get here as we always declare a help 30\t// flag in InitDefaultHelpFlag() 31\tc.Println(\u0026#34;\\\u0026#34;help\\\u0026#34; flag declared as non-bool. Please correct your code\u0026#34;) 32return err 33} 3435// 如果指定了帮助flag，返回一个帮助类型错误，上层会处理，调用命令的 HelpFunc 36\tif helpVal { 37return flag.ErrHelp 38} 3940// for back-compat, only add version flag behavior if version is defined 41\t// 如果设置了Version属性，并且传递了 version flag，输出版本信息 42\tif c.Version != \u0026#34;\u0026#34; { 43versionVal, err := c.Flags().GetBool(\u0026#34;version\u0026#34;) 44if err != nil { 45c.Println(\u0026#34;\\\u0026#34;version\\\u0026#34; flag declared as non-bool. Please correct your code\u0026#34;) 46return err 47} 48if versionVal { 49err := tmpl(c.OutOrStdout(), c.VersionTemplate(), c) 50if err != nil { 51c.Println(err) 52} 53return err 54} 55} 5657// 判断是否可运行（也就是是否设置了命令的 Run 或者 RunE 属性） 58\tif !c.Runnable() { 59return flag.ErrHelp 60} 6162// 执行准备，其实就是执行通过cobra.OnInitialize注册的初始化方法 63\tc.preRun() 6465// 获取所有flag之外的参数 66\targWoFlags := c.Flags().Args() 67if c.DisableFlagParsing { 68// 如果设置了 DisableFlagParsing 为 false 69\t// 也就是不解析 flag，把所有的参数当做命令的参数 70\targWoFlags = a 71} 7273// 通过命令的 Args 属性设置的方法验证我们的参数 74\tif err := c.ValidateArgs(argWoFlags); err != nil { 75return err 76} 7778// PersistentPreRun 钩子函数 79\tfor p := c; p != nil; p = p.Parent() { 80if p.PersistentPreRunE != nil { 81if err := p.PersistentPreRunE(c, argWoFlags); err != nil { 82return err 83} 84break 85} else if p.PersistentPreRun != nil { 86p.PersistentPreRun(c, argWoFlags) 87break 88} 89} 90// PreRun 钩子函数 91\tif c.PreRunE != nil { 92if err := c.PreRunE(c, argWoFlags); err != nil { 93return err 94} 95} else if c.PreRun != nil { 96c.PreRun(c, argWoFlags) 97} 9899// 验证所有必要的flag 100\tif err := c.validateRequiredFlags(); err != nil { 101return err 102} 103104// 执行自定义逻辑函数 105\tif c.RunE != nil { 106if err := c.RunE(c, argWoFlags); err != nil { 107return err 108} 109} else { 110c.Run(c, argWoFlags) 111} 112113// PostRun 钩子 114\tif c.PostRunE != nil { 115if err := c.PostRunE(c, argWoFlags); err != nil { 116return err 117} 118} else if c.PostRun != nil { 119c.PostRun(c, argWoFlags) 120} 121122// PersistentPostRun 钩子 123\tfor p := c; p != nil; p = p.Parent() { 124if p.PersistentPostRunE != nil { 125if err := p.PersistentPostRunE(c, argWoFlags); err != nil { 126return err 127} 128break 129} else if p.PersistentPostRun != nil { 130p.PersistentPostRun(c, argWoFlags) 131break 132} 133} 134135return nil 136} 到此，大概的命令执行流程我们就分析完了。可以发现，这次的分析过程，我们并没有预先把cobra.Command结构里面的成员先看一遍，因为里面的成员实在是太太太多了，简单看一遍几乎是秒忘，所以对于这种成员非常多的结构体，建议直接跟流程，看到用什么成员，再去结构里看这个成员的说明。\n以上就是我们的整个分析过程了，如果有空，之后会补充一些重要的支线逻辑\n","date":"2019-12-11","img":"","permalink":"https://wangtingkui.space/posts/go/cobra/","series":null,"tags":["go"],"title":"Go Cli 应用框架cobra（二）- 源码分析"},{"categories":null,"content":"hugo 是一个静态网页生成器，关于它的使用就不再多说，可以参考之前写过的使用hugo搭建个人站点系列文章。本系列主要是分析下 hugo 的源码，看下其他人是如何实现一个大型的 cli 应用\n第一篇文章从 hugo version 命令出发，简单了解下 hugo 应用的整体流程和代码结构，为后续比较复杂的命令分析做准备\n本系列文章都是基于 hugo 0.57.2 版本叙述的\n命令简介 version 命令的作用数输出当前 hugo 的版本，基本上所有的 cli 应用都会有这样的命令\n一个 hugo version 的输出：\n1╰─$ hugo version 2Hugo Static Site Generator v0.57.2-A849CB2D darwin/amd64 BuildDate: 2019-08-17T17:53:28Z 源码分析 hugo是基于 cobra 这个命令行应用框架做的，如果能了解下cobra的基本使用会对我们的源码分析过程有比较大的帮助，关于 cobra，可以参考之前的两篇文章\n go cli 应用框架cobra（一）- 简介  go cli 应用框架cobra（二）- 源码分析   为了使我们的分析过程比较轻松，先来看下在 hugo version 这条主线中，会涉及到哪些比较主要的结构体\n baseCmd\n 1type baseCmd struct { 2cmd *cobra.Command 3} 45func (c *baseCmd) getCommand() *cobra.Command { 6return c.cmd 7} 89func (c *baseCmd) flagsToConfig(cfg config.Provider) { 10initializeFlags(c.cmd, cfg) 11} 前面我们也提到过，hugo 是基于 cobra 框架开发的，baseCmd 其实就是对 cobra 的 cobra.Command 的简单封装\n commandsBuilder\n 1type commandsBuilder struct { 2hugoBuilderCommon 3commands []cmder 4} 这是一个命令的构建器，是它将我们的version,new,config,check\u0026hellip; 等命令打包起来放在一个命令的子命令中，从而使我们方便的使用，其实就是用来生成我们的根命令\n hugoCmd\n 1type hugoCmd struct { 2*baseBuilderCmd 34// Need to get the sites once built. 5\tc *commandeer 6} 上面提到了 commandsBuilder 将命令打包，其实就是新建了一个 hugoCmd，将我们的子命令都放到这个命令下，可以认为 hugoCmd 就是我们的 hugo 这个根命令\n了解了上面几个基本的结构体，下面就让我们进入源码分析之旅吧，首先看下 main.go 入口文件：\n1func main() { 2resp := commands.Execute(os.Args[1:]) 34if resp.Err != nil { 5if resp.IsUserError() { 6resp.Cmd.Println(\u0026#34;\u0026#34;) 7resp.Cmd.Println(resp.Cmd.UsageString()) 8} 9os.Exit(-1) 10} 1112} commands.Execute\n1// Execute adds all child commands to the root command HugoCmd and sets flags appropriately. 2// The args are usually filled with os.Args[1:]. 3func Execute(args []string) Response { 4// 通过commandsBuilder生成hugoCmd，这个比较简单，就不深入看了 5\thugoCmd := newCommandsBuilder().addAll().build() 6// 获取原始的 cobra.Command 7\tcmd := hugoCmd.getCommand() 8// 将os.Args[1:] 设置为根命令的参数 9\tcmd.SetArgs(args) 10// 执行命令，这里执行的cobra的源码，有兴趣的可以看一下，返回的是真正的哪个命令被执行以及一个error 11\tc, err := cmd.ExecuteC() 1213var resp Response 1415if c == cmd \u0026amp;\u0026amp; hugoCmd.c != nil { 16// Root command executed 17\tresp.Result = hugoCmd.c.hugo() 18} 1920if err == nil { 21errCount := int(loggers.GlobalErrorCounter.Count()) 22if errCount \u0026gt; 0 { 23err = fmt.Errorf(\u0026#34;logged %d errors\u0026#34;, errCount) 24} else if resp.Result != nil { 25errCount = resp.Result.NumLogErrors() 26if errCount \u0026gt; 0 { 27err = fmt.Errorf(\u0026#34;logged %d errors\u0026#34;, errCount) 28} 29} 3031} 3233resp.Err = err 34resp.Cmd = c 3536return resp 37} ","date":"2019-12-10","img":"","permalink":"https://wangtingkui.space/posts/go/version/","series":null,"tags":null,"title":"Hugo源码分析（一）- Version"},{"categories":null,"content":"hugo 内置了强大且支持自定义的分类系统，比如标签、类别、系列等，可以通过配置开启这些分类系统\n在config.toml中配置：\n1[taxonomies] 2tag = \u0026#34;tags\u0026#34; 3category = \u0026#34;categories\u0026#34; 4seris = \u0026#34;series\u0026#34; 开启之后，只需要在文章的Front Matter对应的属性中，添加想要划分到的分类即可\n1--- 2title: \u0026#34;php入门\u0026#34; 3date: 2019-10-10 4tags: [\u0026#34;php\u0026#34;] 5categories: [\u0026#34;php\u0026#34;] 6series: [\u0026#34;php入门系列\u0026#34;] ","date":"2019-12-07","img":"","permalink":"https://wangtingkui.space/posts/tool/hugo-categorize-your-artical/","series":["使用hugo搭建个人网站"],"tags":["go"],"title":"使用hugo搭建个人网站（七）- 给你的文章分类"},{"categories":null,"content":"github pages 为我们提供的站点域名是 \u0026lt;username\u0026gt;.github.io，但是有好多同学其实购买了自己的域名，那能否将自己的域名绑定到 github pages 上呢，当然是可以的\ngithub pages 支持多种域名类型，不同的域名类型配置有细微的区别\n配置二级域名 二级域名就是类似baidu.com这种，.com是顶级域,baidu是二级域\n首先进入到 github 仓库的设置，找到 GitHub Pages 项下的 Custom domain 配置项 输入你的二级域名，点击保存，这个操作会自动在你的仓库代码的根目录下添加一个CNAME文件 最后还需要在你的dns服务提供商那里配置一下域名解析，对于二级域名来说，你可以配置ALIAS记录,ANAME记录或者是A记录\n如果配置的是ALIAS或者ANAME，需要把你二级域名指向默认的站点域名，也就是\u0026lt;username.github,io\u0026gt;\n如果配置的是A记录，把你的二级域名指向下面的ip，具体会不会变化可以参考官方文档 1185.199.108.153 2185.199.109.153 3185.199.110.153 4185.199.111.153 配置子域名 可以参考官方文档\n参考  github pages 官方文档   ","date":"2019-12-07","img":"","permalink":"https://wangtingkui.space/posts/tool/hugo-custom-your-domain/","series":["使用hugo搭建个人网站"],"tags":["go","github pages"],"title":"使用hugo搭建个人网站（八）- 自定义你的站点域名"},{"categories":null,"content":"默认情况下，站点文章的 url 和我们 content 目录下的文件结构是一一对应的，比如有 content/posts/test.md 这篇文章，当我们发布之后，在站点访问的 url 就是 \u0026lt;domian\u0026gt;/posts/test，如果我们不想要这种形式，可以通过配置来改变默认的行为\n在使用配置之前，先让我们了解下 hugo 生成的 url 规则\n知道了每个段的含义，我们就可以使用hugo提供给我们的配置项来进行url的自定义\n可以在config.toml文件中的[permalinks]配置指定url的格式，比如\n1[permalinks] 2post = \u0026#34;/:year/:month/:title/\u0026#34; 所有可用的属性如下\n1:month 2:monthname 3:day 4:weekday 5:weekdayname 6:yearday 7:section 8:title 9:slug 10:filename ","date":"2019-12-07","img":"","permalink":"https://wangtingkui.space/posts/tool/hugo-custom-your-url/","series":["使用hugo搭建个人网站"],"tags":["go"],"title":"使用hugo搭建个人网站（六）- 定制你文章的url"},{"categories":null,"content":"加入我们要寻找content/posts下文章的模板\n当我们未在Front Matter中指定type和layout属性的时候，hugo默认的模板查找顺序是：\n1\u0026lt;project_path\u0026gt;/layouts/UNSPECIFIED/UNSPECIFIED.html 2\u0026lt;project_path\u0026gt;/layouts/posts/UNSPECIFIED.html 3\u0026lt;project_path\u0026gt;/layouts/UNSPECIFIED/single.html 4\u0026lt;project_path\u0026gt;/layouts/posts/single.html 5\u0026lt;project_path\u0026gt;/layouts/_default/single.html 6\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/UNSPECIFIED/UNSPECIFIED.html 7\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/posts/UNSPECIFIED.html 8\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/UNSPECIFIED/single.html 9\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/posts/single.html 10\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/_default/single.html 当指定了type和layout属性的时候，查找顺序是：\n1\u0026lt;project_path\u0026gt;/layouts/review/reviewarticle.html 2\u0026lt;project_path\u0026gt;/layouts/posts/reviewarticle.html 3\u0026lt;project_path\u0026gt;/layouts/review/single.html 4\u0026lt;project_path\u0026gt;/layouts/posts/single.html 5\u0026lt;project_path\u0026gt;/layouts/_default/single.html 6\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/review/reviewarticle.html 7\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/posts/reviewarticle.html 8\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/review/single.html 9\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/posts/single.html 10\u0026lt;project_path\u0026gt;/themes/\u0026lt;THEME\u0026gt;/layouts/_default/single.html ","date":"2019-12-07","img":"","permalink":"https://wangtingkui.space/posts/tool/hugo-template-order/","series":["使用hugo搭建个人网站"],"tags":["go"],"title":"使用hugo搭建个人网站（五）- 模板选择顺序"},{"categories":null,"content":"Front Matter 是扉页，前页的意思，顾名思义，他出现在我们文章的最前面，用来设定一些文章的元信息，比如是否是草稿，写作时间，文章所属的标签等等。\nFront Matter 支持4种配置语言 YAML,JSON,TOML,ORG，可以通过Front Matter的前导符（包裹Front Matter的定界符）来告诉hugo我们使用的是什么配置语言，各种配置语言的前导符如下：\n   格式 定界符     toml 开始和结束行使用+++   yaml 开始和结束行使用---   json 使用一个json对象，对象后需要跟一个空白行   org a group of Org mode keywords in the format ‘#+KEY: VALUE’. Any line that does not start with #+ ends the front matter section. Keyword values can be either strings (#+KEY: VALUE) or a whitespace separated list of strings (#+KEY[]: VALUE_1 VALUE_2).    Front Matter支持的标准配置有很多，但是只有两个属性是必须的，那就是title和date，代表了文章的标题和写作时间\n下面是hugo默认支持的常用Front Matter属性：\n1title:\u0026#34;文章标题\u0026#34;2date:2012-12-123description:\u0026#34;文章描述信息\u0026#34;4tags:[\u0026#34;标签1\u0026#34;,\u0026#34;标签2\u0026#34;]5categories:[\u0026#34;分类1\u0026#34;,\u0026#34;分类2\u0026#34;]6keywords:[\u0026#34;关键字1\u0026#34;,\u0026#34;关键字2\u0026#34;]7lastmod:2015-10-1089isCJKLanguage:true# 是否是CJK语言1011draft:true# 是否是草稿12expiryDate:2020-10-10# 文章过期时间13publishDate:2020-10-10# 文章发布时间1415weight:40# 文章排序权重，数值越小越在前1617# 使用这两个参数会重置permalink，默认使用文件名18url:19slug:2021# 文章地址的别名22aliases:23- /posts/hxxxx24- xxxx2526# type 和 layout 将会改变 hugo 寻找文章模板的顺序27type:review28layout:reviewartical参考  官方文档   ","date":"2019-12-07","img":"","permalink":"https://wangtingkui.space/posts/tool/front-matter/","series":["使用hugo搭建个人网站"],"tags":["go"],"title":"使用hugo搭建个人网站（四）- Front Matter 配置详解"},{"categories":null,"content":"我们可以在文章中引用自己的其他文章，hugo 帮我们实现了这种功能，只需要在文章中使用 {{\u0026lt; ref \u0026quot;posts/my_post.md\u0026quot; \u0026gt;}}或者{{\u0026lt; relref \u0026quot;posts/my_post.md\u0026quot; \u0026gt;}}即可，前者是相对链接，后者是绝对链接\n这个功能其实是 hugo 提供的 Shortcodes功能 一些例子：\n1{{\u0026lt; ref \u0026#34;blog/post.md\u0026#34; \u0026gt;}} =\u0026gt; https://example.com/blog/post/ 2{{\u0026lt; ref \u0026#34;post.md#tldr\u0026#34; \u0026gt;}} =\u0026gt; https://example.com/blog/post/#tldr:caffebad 3{{\u0026lt; relref \u0026#34;post.md\u0026#34; \u0026gt;}} =\u0026gt; /blog/post/ 4{{\u0026lt; relref \u0026#34;blog/post.md#tldr\u0026#34; \u0026gt;}} =\u0026gt; /blog/post/#tldr:caffebad 5{{\u0026lt; ref \u0026#34;#tldr\u0026#34; \u0026gt;}} =\u0026gt; #tldr:badcaffe 6{{\u0026lt; relref \u0026#34;#tldr\u0026#34; \u0026gt;}} =\u0026gt; #tldr:badcaffe 如果是不是需要引用，而仅仅是需要展示{{\u0026lt; ref \u0026quot;blog/post.md\u0026quot; \u0026gt;}}这样的文本，需要在标签内加上/* */这样的注释，比如{{\u0026lt;/* ref \u0026quot;blog/post.md\u0026quot; */\u0026gt;}}\n","date":"2019-12-02","img":"","permalink":"https://wangtingkui.space/posts/tool/ref-other-article/","series":["使用hugo搭建个人网站"],"tags":["hugo"],"title":"使用hugo搭建个人网站（三）- 引用其他文章"},{"categories":null,"content":"flag 包是官方给我们提供的解析命令行选项的标准包，本文主要对其进行源码分析，如果仅仅只是需要学会简单的使用，可以参考Go标准库（flag）- 使用核心数据类型 首先还是来看下flag包中有哪些核心的类型，主要有两个接口和两个结构体\ninterface:\n1// 抽象类型， 我们后续也是通过这个接口来扩展我们flag包支持的数据类型的 2type Value interface { 3String() string 4Set(string) error 5} 67type Getter interface { 8Value 9Get() interface{} 10} struct:\n1// 代表一个命令行选项 2type Flag struct { 3Name string // name as it appears on command line // 标签在命令行显示的名字 4 Usage string // help message // 帮助信息 5 Value Value // value as set // 标签的值 6 DefValue string // default value (as text); for usage message // 默认值（文本格式）；这也是一个用法的信息说明 7} 89// 代表一个选项集合，其实可以认为就是在shell中敲入的命令被拆分解析之后就是FlagSet 10type FlagSet struct { 1112// 当解析标签出现错误的时候，Usage就会被调用。这个字段是一个函数（不是一个方法），它可以指向 13 // 用户自己定义的错误处理函数。 14\tUsage func() 1516name string // 名字，一般默认是os.Args[0] 17\tparsed bool\t// 是否已经解析过了（是否调用过flag.Parse()） 18\tactual map[string]*Flag // 解析过得flag数组 19\tformal map[string]*Flag // 注册的flag数组 20\targs []string // 解析过后，剩余的non-flag参数 21\terrorHandling ErrorHandling // 解析失败后的处理方式 22\toutput io.Writer // nil means stderr; use out() accessor 23} 源码分析 很多包在提供了底层类型的同时，为了方便我们使用，经常会在包内初始化一个默认对象，然后在开放一些导出函数供我们使用，flag 包也是这样的，标准库的实现者在包内初始化了一个名为CommandLine的FlagSet类型对象，我们经常使用的flag.String(),flag.BoolVal()等方法其实就是对这个对象的操作\n接下来就让我们追踪下最常用的flag.String的调用，看下flag包的内部实现逻辑吧\n注册 flag.String\n1// 可以看到，flag.String 其实是对 CommandLine 对象 String 方法的包装，和我们刚才提到的是吻合的 2func String(name string, value string, usage string) *string { 3return CommandLine.String(name, value, usage) 4} CommandLine.String\n1// 帮我们创建了一个string类型的指针，返回给后续使用， 2// 这里也可以看到，Xxx()这种方法比XxxVar()的方法只是多了一步帮我们创建变量的过程，其实更底层是一样的 3func (f *FlagSet) String(name string, value string, usage string) *string { 4p := new(string) 5f.StringVar(p, name, value, usage) 6return p 7} f.StringVar\n1// FlagSet.StringVar 将我们的string类型的指针包装成了 stringValue 这个实现了 Value 接口的类型 2func (f *FlagSet) StringVar(p *string, name string, value string, usage string) { 3f.Var(newStringValue(value, p), name, usage) 4} f.Var\n1func (f *FlagSet) Var(value Value, name string, usage string) { 2// 创建一个Flag对象 3\tflag := \u0026amp;Flag{name, usage, value, value.String()} 4// 检测是否已经注册过同名的flag 5\t_, alreadythere := f.formal[name] 6if alreadythere { 7var msg string 8if f.name == \u0026#34;\u0026#34; { 9msg = fmt.Sprintf(\u0026#34;flag redefined: %s\u0026#34;, name) 10} else { 11msg = fmt.Sprintf(\u0026#34;%s flag redefined: %s\u0026#34;, f.name, name) 12} 13fmt.Fprintln(f.Output(), msg) 14panic(msg) // Happens only if flags are declared with identical names 15\t} 16// 初始化formal 17\tif f.formal == nil { 18f.formal = make(map[string]*Flag) 19} 20// 放到注册的标记集合中 21\tf.formal[name] = flag 22} 解析 执行到这里，我们的选项注册工作已经完成了，下一步就是命令行参数的解析，从而把用户真正的输入拿到，执行解析，我们调用的方法是flag.Parse\nflag.Parse\n1// 其实是对FlagSet.Parse的封装 2// 同时也看到，flag包对参数的解析默认是从命令行输入的第二个字符串开始的 3func Parse() { 4// Ignore errors; CommandLine is set for ExitOnError. 5\tCommandLine.Parse(os.Args[1:]) 6} CommandLine.Parse\n1func (f *FlagSet) Parse(arguments []string) error { 2// 将解析标记置为true，标记这个FlagSet已经被解析过了 3\tf.parsed = true 4// 将所有参数放到盛放non-flag参数的容器中 5\t// 后续解析过程会一个一个参数从这个容器中往外拿，直到解析结束 6\tf.args = arguments 7for { 8// 逐个解析参数 9\tseen, err := f.parseOne() 10if seen { 11continue 12} 13// 解析完成，退出循环，f.parseOne 返回 false,nil 的时候 14\tif err == nil { 15break 16} 17// 如果有error发生，根据设置定的error处理方式处理error 18\tswitch f.errorHandling { 19case ContinueOnError: 20return err 21case ExitOnError: 22os.Exit(2) 23case PanicOnError: 24panic(err) 25} 26} 27return nil 28} f.parseOne\n1// 这个方法是最主要的一个方法，他解析我们的参数 2// 这个方法是被循环调用的，决定解析是否终止的条件也在这个方法中，在源码中我会标记出来 3func (f *FlagSet) parseOne() (bool, error) { 4// 没有参数，不需要解析 5\tif len(f.args) == 0 { 6return false, nil 7} 8s := f.args[0] 9// 结束条件1：字符串长度小于零或者不是以 - 字符开头的 10\tif len(s) \u0026lt; 2 || s[0] != \u0026#39;-\u0026#39; { 11return false, nil 12} 13numMinuses := 1 14if s[1] == \u0026#39;-\u0026#39; { 15numMinuses++ 16// 结束条件2：字符串是以 -- 开头的 17\tif len(s) == 2 { // \u0026#34;--\u0026#34; terminates the flags 18\tf.args = f.args[1:] 19return false, nil 20} 21} 2223// 取出真正的字符值（去掉前缀 - 或者 -- ） 24\tname := s[numMinuses:] 2526// 字符串合法检测 27\tif len(name) == 0 || name[0] == \u0026#39;-\u0026#39; || name[0] == \u0026#39;=\u0026#39; { 28return false, f.failf(\u0026#34;bad flag syntax: %s\u0026#34;, s) 29} 3031// it\u0026#39;s a flag. does it have an argument? 32\tf.args = f.args[1:] 33hasValue := false 34value := \u0026#34;\u0026#34; 35// 通过等号判断是不是 \u0026#34;name=value\u0026#34; 这种格式类型的flag 36\tfor i := 1; i \u0026lt; len(name); i++ { // equals cannot be first 37\tif name[i] == \u0026#39;=\u0026#39; { 38value = name[i+1:] 39hasValue = true 40name = name[0:i] 41break 42} 43} 44m := f.formal 45// 判断是否注册过指定名称的flag 46\tflag, alreadythere := m[name] // BUG 47\tif !alreadythere { 48// 默认支持解析 help 和 h 选项 49\tif name == \u0026#34;help\u0026#34; || name == \u0026#34;h\u0026#34; { // special case for nice help message. 50\tf.usage() 51return false, ErrHelp 52} 53return false, f.failf(\u0026#34;flag provided but not defined: -%s\u0026#34;, name) 54} 5556// bool类型的flag支持 -flag 形式的写法，传了标记就是true，不传就依赖默认值 57\tif fv, ok := flag.Value.(boolFlag); ok \u0026amp;\u0026amp; fv.IsBoolFlag() { // special case: doesn\u0026#39;t need an arg 58\tif hasValue { 59if err := fv.Set(value); err != nil { 60return false, f.failf(\u0026#34;invalid boolean value %q for -%s: %v\u0026#34;, value, name, err) 61} 62} else { 63if err := fv.Set(\u0026#34;true\u0026#34;); err != nil { 64return false, f.failf(\u0026#34;invalid boolean flag %s: %v\u0026#34;, name, err) 65} 66} 67} else { 68// It must have a value, which might be the next argument. 69\tif !hasValue \u0026amp;\u0026amp; len(f.args) \u0026gt; 0 { 70// value is the next arg 71\thasValue = true 72value, f.args = f.args[0], f.args[1:] 73} 74if !hasValue { 75return false, f.failf(\u0026#34;flag needs an argument: -%s\u0026#34;, name) 76} 77if err := flag.Value.Set(value); err != nil { 78return false, f.failf(\u0026#34;invalid value %q for flag -%s: %v\u0026#34;, value, name, err) 79} 80} 8182// 初始化f.actual 83\tif f.actual == nil { 84f.actual = make(map[string]*Flag) 85} 8687// 放在解析后的容器里面 88\tf.actual[name] = flag 89return true, nil 90} ","date":"2019-12-02","img":"","permalink":"https://wangtingkui.space/posts/go/flag/","series":null,"tags":null,"title":"Go标准库（flag）- 源码分析"},{"categories":["go标准库使用和源码分析"],"content":"本文所讨论内容基于的go版本：go1.13\n在我们编写命令行程序的时候，解析命令行的参数是非常常见的一种需求，Go标准库中的flag包为我们提供了解析命令行参数的功能\n要使用flag包，主要有3个步骤：定义flag、解析flag、使用flag\n定义flag flag包为我们提供了两种定义flag的方式，flag.Xxx()方式和flag.XxxVar()方式,其中Xxx可以是Int,String等类型，其中第一种会返回对应类型的指针，第二种则是将flag绑定到一个变量上\n1// 方式1 2var config *string = flag.String(\u0026#34;config\u0026#34;. \u0026#34;path/to/config\u0026#34;, \u0026#34;配置文件路径\u0026#34;) 34// 方式2 5var intval int 6flag.IntVal(\u0026amp;intval, \u0026#34;intval\u0026#34;, 1, \u0026#34;a intger value\u0026#34;) 除了标准库中提供的基础数据类型的解析，如果我们需要解析自定义的类型，可以使用flag.Val()方法，只要绑定的类型实现了flag.Value接口即可\n解析flag 当定义完了所有的flag之后，我们可以调用flag.Parse()方法解析命令行参数\n使用flag 当使用命令行传递flag的时候，有以下三种语法格式（虽说官方只写了一个-，但其实当flag是bool类型的时候--也是支持的，但最好还是按照官方的来）\n1-flag // 只支持 bool 类型 2-flag value // 只支持非 bool 类型，因为比如有`cmd -x false`这种格式，不能确定false到底是flag的值还是一个参数 3-flag=value 在命令行传递参数时，如果是int类型，可以传递十进制、十六进制、八进制或者是负数；如果是bool类型，可以使用1,0,t,g,true,false,TRUE,FALSE,True,Flase；如果是duration，可以接受任何time.ParseDuration可以解析的类型\nnon-flag 参数 在上面的说明中我们知道，传递参数的时候有固定格式，那不符合这些格式的参数就是non-flag参数\n在代码中，我们可以通过下面的这些方法来获取和使用non-flag参数\n1flag.Arg(i int) // 获取第i个non-flag参数 2flag.Args() // 获取所有的non-flag参数 3flag.NArg() // 获取non-flag参数的个数 一个例子 1package main 23import ( 4\u0026#34;flag\u0026#34; 5\u0026#34;fmt\u0026#34; 6) 78func main() { 9var ( 10s = flag.String(\u0026#34;s\u0026#34;, \u0026#34;defaut string value\u0026#34;, \u0026#34;flag of type string\u0026#34;) 11i = flag.Int(\u0026#34;i\u0026#34;, 0, \u0026#34;flag of type int\u0026#34;) 12) 1314flag.Parse() 1516output := fmt.Sprintf(`value of s flag:%s 17value of i flag:%d 18count of non-flag:%d 19item of non-flag:%v`, *s, *i, flag.NArg(), flag.Args()) 2021fmt.Println(output) 22} 查看下输出：\n1╰─$ ./flag -i 10 -s abc haha hehe 2value of s flag:abc 3value of i flag:10 4count of non-flag:2 5item of non-flag:[haha hehe] ","date":"2019-12-01","img":"","permalink":"https://wangtingkui.space/posts/go/%E4%BD%BF%E7%94%A8flag/","series":null,"tags":["go"],"title":"Go标准库（flag）- 使用"},{"categories":null,"content":"上一篇文章已经让我们简单了解了如何使用hugo，但是我们使用hugo的最终目的还是依靠它去搭建一个我们的个人站点，hugo能解决的是静态站点的生成，那么剩下的一个问题就是如何部署我们生成的站点，供其他人访问\n这篇文章帮助我们了解如何使用github pages的功能来部署我们的个人站点\n使用 github pages 的好处  完全免费 不需要自己购买服务器 不需要自己运行维护 可以方便的使用https  github pages 的限制 当然github pages本身还是有一些限制的\n 网站大小不能超过1GB 网站不能发布的过于频繁（每小时不超过10个版本） 每个月流量上限为1000GB  但是作为个人博客来说，这些限制几乎对我们没什么影响\n如何使用 github pages github pages 官方文档  申请一个github账号，每个github账号可以有一个个人站点和多个项目站点（这个以后有机会在单独写文章说一下） 创建一个\u0026lt;username\u0026gt;.github.io的仓库 当我们执行hugo命令去生成我们的静态站点的文件时，默认会放在当前目录的public目录（当然你也可以通过配置hugo从而指定目录），所以我们直接把创建好的仓库拉取到项目下的public目录即可git clone git@github.com:wangtingkui/wangtingkui.github.io.git ./public 指定hugo命令生成站点文件 进入public文件夹，将生成的文件提交到git，然后推送到远端即可  1cd public 2git add . 3git commit -m \u0026#34;提交信息\u0026#34; 4git push -u origin master 推送之后，访问\u0026lt;username\u0026gt;.github.io你就会惊奇的发现你的个人站点已经可以访问了，如果访问的时候没有效果，也不要着急，那是github还在处理中，去休息一下，过段时间在访问就会生效啦~\n","date":"2019-12-01","img":"","permalink":"https://wangtingkui.space/posts/tool/deploy-on-github-pages/","series":["使用hugo搭建个人网站"],"tags":["go"],"title":"使用hugo搭建个人网站（二）- 使用 Github Pages 部署 Hugo 生成的静态站点"},{"categories":["go三方库使用和源码分析"],"content":"简介 cobra是一个go语言的命令行应用框架，他也是一个用来快速生成命令行应用的脚手架\n一些基础概念 cobra推崇的是The best applications will read like sentences when used. Users will know how to use the application because they will natively understand how to use it.也就是我们的应用应该做到自解释，让使用者可以很容易的上手，使用的时候就像是说话一样的简单和自然\n一个遵循这个理念的命令行应用模式是 APPNAME VERB NOUN -ADJECTIVE 或者换种表达方式 APPNAME COMMADN ARG --FLAG\n APPNAME是我们应用的名称 COMMAND是我们要执行的动作，一般是个动词 ARG是我们动作作用的对象，一般是个名词 --FLAG是用来调整我们动作的行为，一般是个形容词  一个例子：git clone URL --bare\n项目结构 我们可以按照自己的喜好去组织我们的项目代码，但是一般情况下，基于cobra的项目会有以下的项目结构\n1╰─$ tree 2. 3├── LICENSE 4├── cmd 5│ └── root.go 6└── main.go 781 directory, 3 files 快速上手构建项目 上面也提到了，cobra 不仅仅是一个命令行框架，它也能辅助我们快速生成我们的项目文件，接下来就让我们使用 cobra 提供的脚手架帮助我们生成基于 cobra 框架的命令行应用（如果还没有安装cobra脚手架，可以进入github.com/spf13/cobra/cobra然后go install一下）\n1# 创建项目 2cobra init --pkg-name github.com/wangtingkui/testCobra ./testCobra # 创建完成之后，就可以看到我们上面那个默认的目录结构了 34# 给我们的应用添加命令 5cobra add serve # 添加 serve 命令 6cobra add config # 添加 config 命令 7cobra add create -p \u0026#39;configCmd\u0026#39; # 给 config 命令添加 create 子命令，`-p`指定这个命令的父命令，这个没有什么逻辑校验，就是在新命令的文件中init方法里面添加`configCmd.AddCommand(createCmd)`这行代码而已 创建完成之后，再来看下最终生成的目录结构\n1╰─$ tree 2. 3├── LICENSE 4├── cmd 5│ ├── config.go 6│ ├── create.go 7│ ├── root.go 8│ └── serve.go 9└── main.go 10111 directory, 6 files 测试下我们的项目\n主应用\n1╰─$ ./testCobra 2A longer description that spans multiple lines and likely contains 3examples and usage of using your application. For example: 45Cobra is a CLI library for Go that empowers applications. 6This application is a tool to generate the needed files 7to quickly create a Cobra application. 89Usage: 10testCobra [command] 1112Available Commands: 13config A brief description of your command 14help Help about any command 15serve A brief description of your command 1617Flags: 18--config string config file (default is $HOME/.testCobra.yaml) 19-h, --help help for testCobra 20-t, --toggle Help message for toggle 2122Use \u0026#34;testCobra [command] --help\u0026#34; for more information about a command. serve 命令\n1╰─$ ./testCobra serve 2serve called ","date":"2019-12-01","img":"","permalink":"https://wangtingkui.space/posts/go/%E4%BD%BF%E7%94%A8cobra/","series":null,"tags":["go"],"title":"Go Cli 应用框架cobra（一）- 简介"},{"categories":null,"content":"作为一名coder，日常的开发工作中不可避免的会接触一些字符编码相关的东西，之前只是模模糊糊的了解一点，没有明确的，系统性的认知。一个最典型的例子就是当我们的代码遇到了乱码，这时候其他人总会告诉我们要使用utf-8编码就可以解决问题，但这背后蕴含的原理，却一直没有探索过，所以就查了一些资料，将查到的资料提炼汇总，有了这篇文章\n字符编码的发展历程 我们知道，所有的数据在计算机中都是用二进制串来表示的，那么人类世界的语言符号，想要在计算机中表示，就必须有对应的转换规则，这就是字符编码\nASCII 时期 上世纪60年代，美国制定了一套字符编码，它使用一个字节来对英语字符和二进制串进行映射，这就是ASCII码。\nASCII一共规定了128个字符，其中包含32个控制字符，由于ASCII只有128个字符，所以只占用了一个字节的7位，所以规定最前面的1位统一为0\n传统字符编码时期 由于不是所有国家的语言体系都是英文，比如中国使用的汉字，字符数量就远远超过了一个字符所能容纳的极限，所有随着计算机的普及，各个国家都提出了自己的字符编码方案，基本的策略就是使用更多的字节空间，兼容ASCII，然后用剩下的空间来编码其他的字符。比如中国的GB2312、BIG5等，但是这就导致了一个问题，各个国家都只是兼容了ASCII，然后编码了本国语言，对其他语言是不支持的，所以导致当时的计算机只能处理双语言环境，不支持多语言环境。\n假如遇到要在一个文本中同时出现中文、英文、阿拉伯文的时候，就无法进行编码处理了。\nunicode 时期 为了解决传统编码方式带来的问题，unicode出现了，下面就让我们详细看下unicode是如何解决上面的这些问题的\n现代编码模型 在探讨unicode是个什么东西之前，我们先来了解一下现代编码模型，因为要完美解决上面提到的编码问题，以及保证这套字符编码的可扩展性（因为到现在为止，还不断有更多的字符在加入到我们的语言体系之中），已经不能只是用简单规定几个字节，然后将字符和编码一一对应来处理了。\n现代编码模型将字符编码从底向上分为了几个层次：\n 抽象字符表（Abstract Character Repertoire）   就是这个编码系统所包含的所有抽象字符的集合，比如ASCII编码里面就有128个抽象字符。抽象字符表可以是封闭的，比如ASCII，不允许添加新的字符，也可以是开放的，比如unicode，可以添加新的字符进去。要注意的是，抽象字符表是一个集合，集合有一个最大的特点就是无序的。\n  编码字符集（Coded Character Set）   抽象字符表是抽象字符的集合，集合是无序的。无序的抽象字符表其实没什么卵用，因为我们只能判断一个字符在不在这个抽象字符表中，却无法方便的引用这个字符。为了更好的描述和操作字符，我们为抽象字符表中的每个抽象字符关联一个数字编号，这个数字编号叫做Code Point（译为码位），编码字符集就是为所有的字符都分配了码位的字符集。\n  码位一般是非负整数，习惯上使用十六进制表示。码位的分配也不一定是连续的。\n  最常见的编码字符集就是UCS（Universal Character Set），这也是unicode标准下使用的编码字符集\n   - [0x0000,0xD7FF] 和 [0xE000,0x10FFFF] 这两个区间称为unicode标量值(unicode scala value) - [0xD800,0xDBFF] 称为 Hign-surrogate - [0xDC00,0xDFFF] 称为 Low-surrogate   字符编码表（Character Encoding Form）   当我们有了编码字符集之后，是不是所有的问题已经解决了呢，当然不是，上面提到过，字符集可以是开放的，所以理论上UCS需要的码位是无限的，但是就算是计算机中uint32，也只有4个字节，最多只能表示4294967295个码位，这样矛盾就出现了。解决这个矛盾的方案，就是字符编码表\n  字符编码表是一个将Unicode标量值(Unicode scalar value)一一映射为码元序列(Code Unit Sequences)的映射。 之所以必须是一一映射，那是因为我们不光要编码，也要解码。 在Unicode中，指定了三种标准的字符编码表，UTF-8,UTF-16,UTF-32。分别将Unicode标量值映射为比特数为8、16、32的码元的序列。 即，UTF-8的码元为uint8, UTF-16的码元为uint16, UTF-32的码元为uint32。 当然也有一些非标准的CEF，如UCS-2,UCS-4，在此不多介绍。\n  码元 Code unit: The minimal bit combination that can represent a unit of encoded text for processing or interchange. 码元是能用于处理或交换编码文本的最小比特组合。通常计算机处理字符的码元为一字节，即8bit。同时因为计算机中char其实是一种整形，而整形的计算往往以计算机的字长作为一个基础单元，通常来讲，也就是4字节。Unicode定义了三种不同的CEF，分别采用了1字节，2字节，4字节的码元，正好对应了计算机中最常见的三种整形长度。\n  如何将一个无限大的整数，一一映射为指定字宽的码元序列。 这个问题可以通过变长编码来解决。 无论是UTF-8还是UTF-16，本质思想都是通过预留标记位来指示码元序列的长度。从而实现变长编码的。\n  字符编码方案（Character Encoding Schema）   简单说，字符编码方案CES等于字符编码表CEF加上字节序列化的方案。\n  通过CEF，我们已经可以将字符转为码元(Code Unit)。无论是哪种UTF-X的码元，都可以找到计算机中与之对应的整形存放。那么现在我们能说存储处理交换字符这个问题解决了吗？ 还不行。 因为从码元落实到底层的存储，还有一些问题需要解决。 假设一个字符按照UTF16拆成了A，B两个码元，那实际存储的时候究竟应该把A放在前面呢还是B放在前面呢？而另一个程序又如何知道当前这份文件是按照什么样的端序存储码元的呢？ 无论是大端法与小端法的选择，还是用于决定编码字节序的标记，都是CES需要操心的方案。\n  所以Unicode实际上定义了7种字符编码方案CES\n   - UTF-8 - UTF-16LE - UTF-16BE - UTF-16 - UTF-32LE - UTF-32BE - UTF-32   UTF-8因为已经采用字节作为码元了，所以实际上是不存在字节序的问题。其他两种CES嘛，都有一个大端版本一个小端版本，还有一个随机应变大小端带BOM的版本\n  当然，这里也出现一个问题，UTF-X可以同时指代字符编码表CEF或者字符编码方案CES。UTF-8问题还好，因为UTF-8的字节序列化方案太朴素了，以至于CES和CEF都没什么区别。但其他两种：UTF-16,UTF-32，就比较棘手了。当我们说UTF-16时，既可以指代UTF-16字符编码表，又可以指代UTF-16字符编码方案。所以当有人说“这个字符串是UTF-16编码的”时，鬼知道他到底说的到底是一个（UTF-16 encoding form的）码元序列还是(UTF-16 encoding schema 的)带BOM序列化好的一串字节流\n  传输编码语法（Transfer Encoding Syntax）   通过CES，我们已经可以将一个字符表示为一个字节序列。 但是有时候，字节序列表示还不够。比如在HTTP协议中，在URL里，一些字符是不允许出现的。这时候就需要再次对字节流进行编码。\n  著名的Base64编码，就是把字节流映射成了一个由64个安全字符组成字符集所表示的字符流。从而使字节流能够安全地在Web中传输。\n 参考文章  http://vonng.com/blog/character-set/   ","date":"2019-09-22","img":"","permalink":"https://wangtingkui.space/posts/base/unicode/","series":null,"tags":["字符编码","unicode","utf-8"],"title":"详解字符编码"},{"categories":null,"content":"以blog为例，看看hugo是如何使用的\n创建一个网站项目 hugo new site blog， 执行这个命令后，会在当前目录下创建一个blog目录 ，这个目录就是我们的项目目录\n简单了解下目录的结构\n1. 2├── archetypes # 存储 .md 的模板文件 3│ └── default.md 4├── config.toml # 配置文件 5├── content # 存储网站所有的内容 6├── data # 存储数据文件供模板调用 7├── layouts # 存储 .html 模板 8├── static # 存储图片、css、js等静态文件，该目录下的文件会直接拷贝到 /public 9└── themes # 存储主题 10116 directories, 2 files 快速体验 让我们快速体验下hugo的威力\nhugo创建出来的项目默认不带有任何主题，我们直接从github上随便搞一个，放到之前提到的themes文件夹下\ngit clone https://github.com/budparr/gohugo-theme-ananke.git ./themes/ananke\n然后在配置文件中配置应用这个主题\necho 'theme = \u0026quot;ananke\u0026quot;' \u0026gt;\u0026gt; config.toml\n接下来该正常的用markdown写作我们的文章了，使用如下命令新建一个文章\nhugo new post/my-first-post.md\n可以看到在content文件夹下多出了一个post文件夹，里面有一个my-fisrt-post.md的markdown文件，我们看下创建出来的这个文件里面的内容都有什么\n content/post/my-first-post.md 文件内容\n 1--- 2title: \u0026#34;My First Post\u0026#34; 3date: 2019-09-22T14:53:48+08:00 4draft: true 5--- 这些默认生成的内容其实就是文章的一些元信息，比如文章的标题，创建的时间等等，里面的具体属性我们稍后再细讲。那这些内容是根据什么生成的呢，还记得我们上面给出的目录结构么，archetypes目录用来存放 md 文件的模板，让我们进去瞅瞅里面有啥，vim archetypes/default.md\n archetypes/default.md 文件内容\n 1--- 2title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; 3date: {{ .Date }} 4draft: true 5--- 看起来是不是和我们刚才生成的文件结构超像，其实那个文件就是依据这个模板来的\n我们来改动下刚才生成的文件，编辑一些自定义的内容\n content/post/my-first-post.md 文件内容\n 1--- 2title: \u0026#34;My First Post\u0026#34; 3date: 2019-09-22T14:53:48+08:00 4draft: true 5--- 67### 这是我的第一篇文章 8 9内容就是用来测试的啦~ 最重要的一步来了，生成我们的站点，hugo内置了一个server，方便我们在书写文章的过程中快速的预览到站点效果，只需要执行下面的命令即可\nhugo server -D\n其中-D选项是告诉hugo把草稿状态的文章也渲染出来，执行完之后，hugo就提示我们已经可以从http://localhost:1313去访问我们的站点了，赶紧去看一下，是不是很吊呢\n","date":"2019-09-22","img":"","permalink":"https://wangtingkui.space/posts/tool/introduction/","series":["使用hugo搭建个人网站"],"tags":["go"],"title":"使用hugo搭建个人网站（一）- Hugo使用入门"},{"categories":null,"content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/yuin/goldmark  https://github.com/alecthomas/chroma  https://github.com/muesli/smartcrop  https://github.com/spf13/cobra  https://github.com/spf13/viper   Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub .\n","date":"2019-02-28","img":"","permalink":"https://wangtingkui.space/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"","date":"0001-01-01","img":"","permalink":"https://wangtingkui.space/offline/","series":null,"tags":null,"title":"Offline"}]